{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e9b0c815",
      "metadata": {},
      "source": [
        "### Univariate forecasting - horizons greater than 1\n",
        "\n",
        "Utilizes only the closing price to predict as there is no way to predict other feature's values in future as well. For multivariate to occur for horizons greater than 1, we need the values of those features at that time point too. Which is not the case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "b415223d",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import datetime\n",
        "import os\n",
        "\n",
        "from lts import LTSCell\n",
        "from ltc import LTCCell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "231aeb17",
      "metadata": {},
      "outputs": [],
      "source": [
        "BTC_PRICES_DATA = 'D:/Uni/FYP/GitHub/BitForecast/ml/data/BTC_Prices.csv'\n",
        "data = pd.read_csv(BTC_PRICES_DATA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5c1bd49f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>volume</th>\n",
              "      <th>close</th>\n",
              "      <th>open</th>\n",
              "      <th>max</th>\n",
              "      <th>min</th>\n",
              "      <th>change_percent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2014-01-01</td>\n",
              "      <td>10757</td>\n",
              "      <td>815.940002</td>\n",
              "      <td>805.940002</td>\n",
              "      <td>829.929993</td>\n",
              "      <td>770.969971</td>\n",
              "      <td>1.240787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2014-01-02</td>\n",
              "      <td>12812</td>\n",
              "      <td>856.909973</td>\n",
              "      <td>815.940002</td>\n",
              "      <td>886.210022</td>\n",
              "      <td>810.469971</td>\n",
              "      <td>5.021199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2014-01-03</td>\n",
              "      <td>9709</td>\n",
              "      <td>884.260010</td>\n",
              "      <td>856.909973</td>\n",
              "      <td>888.229980</td>\n",
              "      <td>839.440002</td>\n",
              "      <td>3.191705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2014-01-04</td>\n",
              "      <td>14239</td>\n",
              "      <td>924.690002</td>\n",
              "      <td>884.260010</td>\n",
              "      <td>932.159973</td>\n",
              "      <td>848.320007</td>\n",
              "      <td>4.572184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2014-01-05</td>\n",
              "      <td>21374</td>\n",
              "      <td>1014.739990</td>\n",
              "      <td>924.690002</td>\n",
              "      <td>1029.859985</td>\n",
              "      <td>911.359985</td>\n",
              "      <td>9.738397</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         date  volume        close        open          max         min  \\\n",
              "0  2014-01-01   10757   815.940002  805.940002   829.929993  770.969971   \n",
              "1  2014-01-02   12812   856.909973  815.940002   886.210022  810.469971   \n",
              "2  2014-01-03    9709   884.260010  856.909973   888.229980  839.440002   \n",
              "3  2014-01-04   14239   924.690002  884.260010   932.159973  848.320007   \n",
              "4  2014-01-05   21374  1014.739990  924.690002  1029.859985  911.359985   \n",
              "\n",
              "   change_percent  \n",
              "0        1.240787  \n",
              "1        5.021199  \n",
              "2        3.191705  \n",
              "3        4.572184  \n",
              "4        9.738397  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "2670c361",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>close</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2014-01-01</td>\n",
              "      <td>815.940002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2014-01-02</td>\n",
              "      <td>856.909973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2014-01-03</td>\n",
              "      <td>884.260010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2014-01-04</td>\n",
              "      <td>924.690002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2014-01-05</td>\n",
              "      <td>1014.739990</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         date        close\n",
              "0  2014-01-01   815.940002\n",
              "1  2014-01-02   856.909973\n",
              "2  2014-01-03   884.260010\n",
              "3  2014-01-04   924.690002\n",
              "4  2014-01-05  1014.739990"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.drop(['volume', 'open', 'max', 'min', 'change_percent'], axis=1, inplace=True)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42838aa0",
      "metadata": {},
      "source": [
        "### Format data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f62521a8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert date object to datetime\n",
        "data['date'] = pd.to_datetime(data['date'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f39197ad",
      "metadata": {},
      "outputs": [],
      "source": [
        "data.set_index('date', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "7a5b463b",
      "metadata": {},
      "outputs": [],
      "source": [
        "btc_prices = pd.DataFrame(data['close']).rename(columns={ 'close': 'Price' })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "174e3b00",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Price</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2014-01-01</th>\n",
              "      <td>815.940002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-01-02</th>\n",
              "      <td>856.909973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-01-03</th>\n",
              "      <td>884.260010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-01-04</th>\n",
              "      <td>924.690002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-01-05</th>\n",
              "      <td>1014.739990</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Price\n",
              "date                   \n",
              "2014-01-01   815.940002\n",
              "2014-01-02   856.909973\n",
              "2014-01-03   884.260010\n",
              "2014-01-04   924.690002\n",
              "2014-01-05  1014.739990"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "btc_prices.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed0955a5",
      "metadata": {},
      "source": [
        "Filteration of dates till only 2015 above is not required since only this dataset is being used"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "c2636dfe",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Price</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2014-01-01</th>\n",
              "      <td>815.940002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-01-02</th>\n",
              "      <td>856.909973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-01-03</th>\n",
              "      <td>884.260010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-01-04</th>\n",
              "      <td>924.690002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-01-05</th>\n",
              "      <td>1014.739990</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Price\n",
              "date                   \n",
              "2014-01-01   815.940002\n",
              "2014-01-02   856.909973\n",
              "2014-01-03   884.260010\n",
              "2014-01-04   924.690002\n",
              "2014-01-05  1014.739990"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Sort ascending order of dates\n",
        "btc_prices.sort_values('date', inplace=True)\n",
        "btc_prices.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b94352b3",
      "metadata": {},
      "source": [
        "### Visualize data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "fd35bac8",
      "metadata": {},
      "outputs": [],
      "source": [
        "timesteps = btc_prices.index.to_numpy()\n",
        "prices = btc_prices['Price'].to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "c43d887a",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((2648,), (663,), (2648,), (663,))"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create sequential splits at a specified point (80% train, 20% test)\n",
        "split_size = int(.8 * len(prices))\n",
        "\n",
        "X_viz, y_viz = timesteps[:split_size], prices[:split_size]\n",
        "X_viz_, y_viz_ = timesteps[split_size:], prices[split_size:]\n",
        "\n",
        "X_viz.shape, X_viz_.shape, y_viz.shape, X_viz_.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "40611733",
      "metadata": {
        "scrolled": false
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Visualize closing prices\n",
        "btc_prices.plot(figsize=(10, 7))\n",
        "plt.ylabel('BTC Price')\n",
        "plt.title('Price of Bitcoin from 2014 to now', fontsize=16)\n",
        "plt.legend(fontsize=14);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "670fbf22",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a helper plotting function\n",
        "def plot_time_series(\n",
        "    timesteps,\n",
        "    prices,\n",
        "    format='.',\n",
        "    start=0,\n",
        "    end=None,\n",
        "    label=None\n",
        "):\n",
        "    plt.plot(timesteps[start:end], prices[start:end], format, label=label)\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Price')\n",
        "    if label:\n",
        "        plt.legend(fontsize=14)\n",
        "\n",
        "    # Display a grid for easier measurement readings\n",
        "    plt.grid(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "cc0931ab",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEICAYAAACeSMncAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAABNsElEQVR4nO2deXyU1dX4v2cmCzuELSyJCSggCIIEA1TRKBUFqdBq3argUrFvtT99a1vX1q221rp3cUe0FdTXpVoEkSKpoIZAWAQEZJGwyKIxLEEgycz9/fE8k8yeZJg1Od/PZz7zPOe59z5nJvCcuffcc44YY1AURVGUSHAkWgFFURQldVEjoiiKokSMGhFFURQlYtSIKIqiKBGjRkRRFEWJGDUiiqIoSsTEzIiIyAARWen1OiAiN4tIZxGZLyIb7fcsu72IyJMisklEPhOR4V5jTbXbbxSRqV7yAhFZbfd5UkQkVp9HURRFCUTiESciIk5gJzASuAH41hjzoIjcBmQZY24VkQnAL4AJdrsnjDEjRaQzsAwYARigDCgwxlSKSCnw/4AlwBzgSWPM3HC6dO3a1eTn50f0OQ4dOkTbtm0j6hstkkEH1SP5dEgWPZJBh2TRIxl0iJYeZWVl3xhjugW9aIyJ+QsYB3xsH28AetrHPYEN9vEzwGVefTbY1y8DnvGSP2PLegLrveQ+7UK9CgoKTKQsXLgw4r7RIhl0MEb1SDYdjEkOPZJBB2OSQ49k0MGY6OgBLDMhnqnx8olcCsyyj7ONMbvs491Atn3cG9ju1WeHLQsn3xFEriiKosSJtFjfQEQygAuA2/2vGWOMiMR8PU1EpgHTALKzsykuLo5onKqqqoj7Rotk0EH1SD4dkkWPZNAhWfRIBh3iokeoKUq0XsAk4AOvc13OOgaSQQdjVI9k08GY5NAjGXQwJjn0SAYdjGkey1mXUb+UBfAu4NlhNRV4x0s+xd6lNQrYb6xlr3nAOBHJsndyjQPm2dcOiMgoe1fWFK+xFEVRlDgQ0+UsEWkLnANc7yV+EHhdRK4FyoGLbfkcrJ1Zm4DvgKsBjDHfisj9wFK73X3GmG/t458DM4DWwFz7pSiKosSJmBoRY8whoIufrAIYG6Stwdr+G2yc6cD0IPJlwOCoKAu43W527NjBoUOHgl7v2LEj69ati9btIiIZdFA9LNLT0+nevXtC7q0oyULMHeupxDfffIOIMGDAAByOwJW+gwcP0r59+wRollw6qB6WL/Hw4cPs3LkTp9MZ9/srScb2Uti6CPLHQG5horWJK2pEvNi3bx/5+flBDYiieCMitGnTht69e3Pw4MFEq6Mkku2l8NIF4KoGZwZMfbdFGRJ9WnrhcrlIT09PtBpKCtG6dWs0204LZ+siqD0KxmW9b12UaI3iihoRP/SBoDQF/fei0LoL4LZP3PZ5y0GNiKIoyrFwuALEfpSKwzpvQagRUQK46qqrmDhxYpP6FBUVceONN8ZIo/DceOONFBUVJeTeSgtneyns3w6OdBAnODMt53oLQh3rKUxDSylTp05lxowZTR73iSee8GQBaDRvvfVWyviTtm7dSp8+fVi6dCkjRoxItDpKquLtUBeBXsPglCktyqkOakRSml27dtUdz549m+uuu85H1rp1a5/2NTU1jXrQd+zYscm6dO7cucl9FCWl2brIMiDGZRWp2Lkc9nwO2YNalCHR5awUpkePHnWvTp06+ciOHDlCp06dmDVrFmeffTatW7fmmWeeoaKigssuu4ycnBxat27NSSedxIsvvugzrv9yVlFRET//+c+544476Nq1K927d+fOO+/E7Xb7tPFezsrPz+f3v/89119/PR06dCAnJ4c///nPPvf54osvOPPMM2nVqhUDBgxgzpw5tGvXLuzsyeVy8atf/YqsrCyysrK49dZbcblcPm3ef/99xowZQ1ZWFp07d+bcc8/1CUjs06cPAKeeeioiUrcUtnTpUsaNG0fXrl3p0KEDp59+Op9++mnDfwilZZI/xtrSi2dFwOjuLCU6lJVX8reFmygrr0y0Ktx+++38/Oc/5/PPP2fy5MkcOXKE4cOHM3v2bNauXctNN93E9ddfz4IFC8KO88orr5CWlsYnn3zCX//6V/7+97/z2muvhe3z2GOPMWTIEJYvX86tt97Kb37zm7qHstvt5oc//CFpaWmUlJQwY8YM7r33Xo4ePRp2zEceeYTnnnuOZ555hk8//RSXy8Urr7zi0+bQoUPcfPPNlJaWUlxcTMeOHfnBD35AdXU1AKWlpYBlbHbt2sVbb70FWIGLV155JYsWLaK0tJRhw4YxYcIEKipalqNUaSS5hVZMSN5oL6EbjhxImEqJQJezokxZeSU/eb6E6lo3GWkOXvnpKAryshKmzy9+8QsuuugiH9mvf/3ruuNp06bx4YcfMmvWLMaODchGU8egQYO47777AOjfvz9PP/00CxYs4LLLLgvZZ9y4cXWzk1/84hc8+eSTLFiwgNGjRzN//nw2bNjABx98QO/eVhmYxx57jNNOOy3s53n88cf5zW9+w8UXWynXHnroIRYuXOjT5sILL/Q5f/HFF+nQoQOlpaWcfvrpdOtmFWjr0qULPXr0qGt39tln+/T7y1/+wptvvsncuXO54oorwuqltGC+3ep7rjMR5Vgo2VJBda0bt4GaWjclWxL7K9bfcexyuXjggQc4+eST6dKlC+3ateOtt95i27ZtYcc5+eSTfc579OjB3r17m9SnV69edX3Wr19Pr1696gwIWMtL4bIF7N+/n127djF6dP0vP4fDwciRI33abd68mcsvv5zjjz+eDh06kJ2djdvtbvAz7t27l+uvv57+/fvTsWNH2rdvz969exvsp7RQPI71g1/5ytMyE6NPgtCZSJQZ1bcLGWkOamrdpKc5GNU3sYFH/rWVH374YR555BGeeOIJhgwZQrt27bjjjjsaNAj+DnkR8fGJRKtPNJg4cSI5OTk888wz9O7dm7S0NAYNGlS3nBWKqVOnsmfPHh577DHy8/PJzMxk7NixDfZTUpBo5LryONb96Tbg2HRLMdSIRJmCvCxe+ekoSrZUMKpvl4QuZQVj8eLF/OAHP+DKK68ErESCX3zxRZ1jPl6ceOKJfPXVV3z11Vf06tULgGXLloU1Mh07dqRnz56UlJTULT0ZYygtLaVnz54AVFRUsH79ev7+979z1llnAbB8+XJqa2vrxsnIyAAIcMgvXryYJ598kvPPPx+APXv2+Ox2U5oJ20thxvngqgFnOlz1XmSGJH8MOJzg9++IHsOiomaqoEYkBhTkZSWd8fDQv39/XnvtNRYvXkzXrl35y1/+wpdffskpp5wSVz3OOeccBgwYwNSpU3n44Yc5fPgwv/zlL0lLSwsb/3LTTTfxxz/+kf79+zNkyBAef/xxdu3aVWdEsrKy6Nq1K8899xy5ubns3LmTX//616Sl1f9T7969O61bt2bevHnk5+fTqlUrOnbsSP/+/fnnP//JyJEjOXToEL/5zW/qDI7SjFg1s34G4aq2ziOdjbj9DAiiEetK8+auu+6isLCQ8ePHc8YZZ9C2bVt+8pOfxF0Ph8PB22+/zdGjRyksLGTq1KnceeediAitWrUK2e+WW27h6quv5qc//SkjR47E7Xb76O9wOHjttdf47LPPGDx4MDfccAP3338/mZn169RpaWk8+eSTPP/88/Tq1YtJkyYBMH36dKqqqigoKODSSy/lmmuuIT8/P2bfgZIgqr4Of95Yti6yYkS8EVpcxLo0NTI51RkxYoRZtmxZ0Gvr1q1j4MCBIfsmQw2NZNAhVnqsWrWKYcOGsWzZMgoKChKmR1NZsWJF3GdywSguLk54+pdk0KFBPWbfDMu8YqNGXA0TH2/6TbaXwgvn+MryToOr5zSsQxyJhh4iUmaMCZreQZezlITx9ttv07ZtW/r168fWrVv55S9/ydChQxk+fHiiVVOaM0MvhxWv1PtEhl4e2Tjr3wuUDbk4UNbMUSOiJIyDBw9y6623sn37drKysigqKuKxxx7T9OpKbMkttJzpq2ZSH23eRLaXwsdPBMp3rzwWzVISNSJKwpgyZQpTpkxJtBpKC6GsvLJ+16QDWPmq5VhfOavp1QhXzcRKmOXHjuBL5c0ZNSKKojR7/DNJLCgso7cneaKr2nKSN2mHVogZzIGWtyU8pruzRKSTiLwhIutFZJ2IjBaRziIyX0Q22u9ZdlsRkSdFZJOIfCYiw73GmWq33ygiU73kBSKy2u7zpOg6iKIoQfDPJPGpa5CVPFGc1ntTd1T1GBpc3qrDsSubYsR6i+8TwPvGmBOBocA64DZggTGmH7DAPgcYD/SzX9OApwBEpDNwNzASKATu9hgeu811Xv3Oi/HnURQlBfFkknAKpKc5GNy7A5xwtlUD5LwHmx4nEioWpHKr5S9pQcRsOUtEOgJnAFcBGGOqgWoRmQQU2c1eAoqBW4FJwMvG2nNcYs9ietpt5xtjvrXHnQ+cJyLFQAdjTIktfxmYDMyN1WdSFCU18c4kMbbdVk6cc3F9jMfuNU2vAZI/xiqFa/wyLBi35XC/9JXg/ZohsfSJ9AG+Bl4UkaFAGXATkG2M8Swc7gay7ePewHav/jtsWTj5jiDyAERkGtbshuzsbIqLi4Mq3LFjRw4ePBjyA7lcrrDX40Ey6KB6+GKMCflvKp5UVVUlXI9k0CGcHicJdCl5CGNc9VVAXEf58sOX2Zb3XZPu0bPfz+j/xVN4HOxiH5n1c1j5ztNUOXOS+ruIFrE0ImnAcOAXxpglIvIE9UtXABhjjIjEPNrRGPMs8CxYwYahAm/WrVsXNnAtGQLbkkEH1cMX78JWiSQZgtuSQYdwepSVV+Io9U02KiL0PXsKfZuc+qQItv8QPn4c1s8BDAIIhuGdD3HA1S6pv4toEUufyA5ghzFmiX3+BpZR2WMvU2G/e/6iO4Fcr/45tiycPCeIXEkwDz/8sKYLUZKOsvJK/vTcS3Q4VA7Ga4Nun7Os3VmR+DJyC+HSmXDaTV5CA60Tm707nsTMiBhjdgPbRcSTF3ks8DnwLuDZYTUVeMc+fheYYu/SGgXst5e95gHjRCTLdqiPA+bZ1w6IyCh7V9YUr7FaBCIS9nXVVVdFPPY999zD4MGDo6dsA4gIb7zxRtzup7Q83ly+gxHmcxwYRKzlJzfAl/+FBfdbmX2baki2l8KiR6Bik69896ooaZ38xDpO5BfAKyKSAWwBrsYyXK+LyLVAOeDJEzAHmABsAr6z22KM+VZE7geW2u3u8zjZgZ8DM4DWWA71FuVU905TPnv2bK677jofWevWrROhlqIkJQKUuAfiwoHDdqobod7B3tSMvp6iVMFqigQLRGymxHSLrzFmpTFmhDHmZGPMZGNMpTGmwhgz1hjTzxjzfY9BMBY3GGOON8YMMcYs8xpnujHmBPv1opd8mTFmsN3nRtPCskn26NGj7uWpB+It++ijjygoKKBVq1b06dOHO++806fA0ltvvcXJJ59M69at6dy5M2eeeSZ79uypq3e+du3aulnNjBkzQurx0EMP0aNHD9q1a8eUKVOoqqryub506VLGjRtH165d6dChA6effnpdrXWgbunrxz/+MSJSd75582YmTZpEjx49aNu2bV1teEWJhENHrZoyDup3VAU+AJsQauYpSmVcgbu0WlBNEU0FHws8U9wE7hefN28eP/nJT7jxxhtZu3Yt06dP54033uCOO+4AYPfu3Vx66aVMnTqVdevW8dFHH9UVqrrkkku45ZZbGDBgALt27WLXrl1ccsklQe/z+uuvc9ddd3HvvfeyfPlyBgwYwKOPPurT5uDBg1x55ZUsWrSI0tJShg0bxoQJE6iosPbaL11qTTKfe+45du3aVXdeVVXF+PHjmT9/PqtWreLCCy/kRz/6EevXr4/Jd6Y0X2Yu2ca/Vn7FKMe6+uUsf3shThh6WeMH3bveNh5CgPFZ/doxapw6aNqTaOM9xXVmND0nT5R44IEH+PWvf83VV18NwPHHH8+f/vQnrrjiCv785z/z1VdfUVNTw0UXXUReXh6Ajw+kXbt2pKWl0aNHj7D3efzxx5k6dSrXX389AHfeeScLFy5k06b6NWJPFUIPf/nLX3jzzTeZO3cuV1xxBd26dQOgU6dOPvcbOnQoQ4fWRwbfeeed/Pvf/+aNN97grrvuiuRrUVogZeWV/PZfqwFrOcuNIJ5FC+9nv39tkHDMvxtWv15/nt4aary2CJd/SofO66kPiWu+6Ewk2nhPcT05eRJAWVkZDzzwAO3atat7XX755Rw6dIjdu3czdOhQvv/97zN48GAuvPBCnnrqKb7+uunFedatW8fo0aN9ZP7ne/fu5frrr6d///507NiR9u3bs3fvXrZt2xZ2bE91wUGDBpGVlUW7du1YtmxZg/0UxZuSLRW4vBa6XThxE8Jr0dj/r+ve9T2v8Y8xMWTvXth4JVMYnYlEm/wx1gzEMxNJUJUzt9vN3XffzY9//OOAa926dcPpdPLBBx9QUlLCBx98wAsvvMDtt9/Of//7X59f/9Fg6tSp7Nmzh8cee4z8/HwyMzMZO3asj38mGL/61a94//33efjhh+nXrx9t2rRhypQpDfZTFG9G9e1ChlOodhlGOdbhxI1TrJ1ZAR6Qxm7NHXiBFR+iqBGJOrmF1hLW1kWWAUnAUhbA8OHDWb9+PSeccELINiLC6NGjGT16NL/73e846aSTeO211xg6dCgZGRm4XA1P7wcOHEhJSQnXXHNNnaykpMSnzeLFi3nyySc5//zzAdizZ4/PLjKA9PT0gPstXryYKVOmcOGFFwJw5MgRNm/eTP/+/RvUS1G8OXNAd1Zsq6Tk0EBqSANTjTOYD72x9dHPuRcOfAWb5kPPU2DrR+Cu9WlS1b7vsSueAqgRiQW5hQkzHh5+97vfMXHiRPLy8rj44otJS0tjzZo1lJaW8tBDD1FSUsJ//vMfzj33XLKzs1mxYgXbt29n0KBBgLVjqry8nOXLl3PcccfRvn17nzrlHm666SamTJnCqaeeSlFREW+88QZLliyhc+fOdW369+/PP//5T0aOHFm3RJWRkeEzTn5+PgsWLODMM88kMzOTrKws+vfvz9tvv82kSZNIT0/n3nvv5ciRI7H94pRmRVl5JZc9+ynV9nrWN/Tn3por+UP6C9Z6lr8haexMZHsprPu3teKw7VPofx6s9945KKTXJD4tUDxQn0gz5dxzz+W9995j4cKFFBYWUlhYyIMPPshxxx0HWHnCPv74YyZOnEi/fv245ZZb+O1vf8sVV1wBwIUXXsiECRMYO3Ys3bp1Y9asWUHvc8kll3DPPfdw5513csopp7B69Wp++ctf+rSZPn06VVVVFBQUcOmll3LNNdcERLQ/8sgjLFy4kNzc3Lp65Y8++ijdu3dnzJgxjB8/nlGjRjFmTGKWB5XUpGRLBTUuX+9HZ6mylrLE3y8ijZ+JrJoFtUfqfZ/tulnL1x6cGezrFL9g3UQiLSy0ghEjRphly4JXH1u3bh0DBw4M2TcZ8jQlgw6qhy8rVqyoM3yJJBnyViWDDt56+M9EAIbLF7yWcT9puHy3+aa1btxuyu2lVnS7J8jQkQ5Xz7GOPSV3h15G8ebvkuq7OBZEpMwYMyLYNZ2JKIrSbCnIy2LWtNGcMyi7buVquenPb2uuwoX4zkRGXt+4Zeiti8Dl5f9we/nyOuZasSYJXs6OJ+oTURSlWVOQl8Ww3E4sWLcHz8LLq+6xXOIuZphzc33D3Z81bsD8MX5rYW5rp9amD33jw1oIOhNRFKXZk9UmIyAwZKvxC6QdOKlxg+UWwoDxvrKDu5MiPiwRqBFRFKVZU1ZeyX2z1+Kd3epSxwImp31cvzmrVwGMuKrxg55wju95/hhweC3saCp4RVGU5kHJlgqqa30TJI53+uW1+6oMls1o/KD+qd4rNtWnTTEumPsbOuxvGTne1Ij40dJ2qynHhv57SX5G9e1CRpoDp0CaA4bmdKTVyT8MjFZf15RyRH5/94O7fB3srmo67VsTocaphTrWvXA6ndTU1AQEwilKKA4fPqyGJMkpyMvilZ+OomRLBaP6dqEgLws4HRzrfZMoNsYnsr3U8nf0GGanN6oBZzqcMgV2r67f9tuC4kTUiHjRqVMn9uzZQ+/evXE4dJKmhMYYw+HDh9m5cyeHDh1KtDpKA1iGw6pu+NbyHfxoeA4FFz4HeadZM5CBkxr2ifhn6B7/Zys40ZPeKHuQT5zIgc3+SRmbJ2pEvOjatSs7duxgw4YNQa8fOXKEVq1axVmr5NNB9bBIT08nOzubnTt3JuT+SuMoK6/kzeU7eH3ZdmrtoMP/K9vBrOtGUTDiqsY71LcuAtdRq4aI66hlQMbcUn/dP93R5uJofYSkRo2IFw6Hoy4tSDCKi4sTHpmcDDqoHkqqECxiHaCm1s2XKxZSsO3LxidKbd2lvoKhccPO5dbspAUFFgZDjYiiKM2WN5fvCDAgAAXOjUxe9QAY26dx1XsNG4PDFVh7kWxDsv492LQgYYXnkgVd+FcUpdnivwOrfaYTh8AP5SOc7mrAWD6OVTMbHix/DKRleo1qQgcWzr+bwpKfWRUQmzkxNSIislVEVovIShFZZss6i8h8Edlov2fZchGRJ0Vkk4h8JiLDvcaZarffKCJTveQF9vib7L7BKgQoitJC+dHwHDLS6h9zB4+6cJtgVQ0b8ejw1AoacRU4M62a7P6F5+bfDX88Dj5+nNZHdlnpUJq5IYnHTOQsY8wwrwyQtwELjDH9gAX2OcB4oJ/9mgY8BZbRAe4GRgKFwN0ew2O3uc6r33mx/ziKoqQKBXlZzLpuFENzOvrI33KNoQanZUwc6VbSxMaQWwgTH4erZsPZd/ouZc2/2zIaR/cDXmZpxT+P/YMkMYlYzpoEvGQfvwRM9pK/bCxKgE4i0hM4F5hvjPnWGFMJzAfOs691MMaUGGuj/steYymKogCWITmpt68ROaF7O9KcTsTzqF81y3KSh2N7Kcy+GWb/r3U+5hZfX4h/3XUPGW0jUzxFiLURMcAHIlImItNsWbYxxlMbdTeQbR/3BrZ79d1hy8LJdwSRK4qi+NAhM61uZpDhFG46YQ8O4wIMuGtg2XR4cUJoQ7JsBkw/D5a9aLWdMTGw7cALfE7rlsxO9y3S1tyI9e6s040xO0WkOzBfRHySyRhjjIjEPNzXNmDTALKzsykuLo5onKqqqoj7Rotk0EH1SD4dkkWPZNDBX4/X1x9lztb6+h/fz3Wyx92VHuJEjAvBWnoy7hq+eecu1g6+w2esDvvXM2zF7Qjuepe66yiVb/2arfmXcaDjiVa773oyDB+3O9tyf8SXVfmQwO8k1n+TmBoRY8xO+32viLyN5dPYIyI9jTG77CWpvXbznUCuV/ccW7YTKPKTF9vynCDtg+nxLPAsWJUNI63ylQxV25JBB9Uj+XRIFj2SQQdvPcrKK3l/3ic+1744lMnwST+D3q3gg7ug2qqFLkC3zNpA/V99DvBN4ChA532f0Xn1hnq/yGzf3FsGyBv3P+QlePtvrP8mMVvOEpG2ItLecwyMA9YA7wKeHVZTAc83/y4wxd6lNQrYby97zQPGiUiW7VAfB8yzrx0QkVH2rqwpXmMpiqJQsqUCt99ax6avD/HB++/C+7dBdZXvxVOmBA7yzcbggxu33xbfgIrt8J/mvTMLYusTyQYWi8gqoBR4zxjzPvAgcI6IbAS+b58DzAG2AJuA54CfAxhjvgXuB5bar/tsGXab5+0+m4G5Mfw8iqKkGFltgidT3f3Zf+xkiQYQ6NwXJj4RPAVK136hbyCO+i2+Qy8PvF7+acMO+xQnZstZxpgtwNAg8gpgbBC5AW4IMdZ0YHoQ+TKgZaTKVBSlyVR+Vx1UvrNTAVS/Xp9M8YfPhI46P+0mWD87+DV3Dez5vD5vVt5pUP4x4PGNGGum0owj2jXtiaIozZaDh2sCZE4HjDv3AnAMtB7wjcmd5UgDd23wayterp/BDLm4zojYc5zgVQ49KeUbm7criVEjoihKs+XTLRU+553bpvPclFPt1PCFjXuAb10U2oAAtO9pvW8vhTn1WX3rgg03zfddJtteam0Rdh21ot7Pf7RppXmTDM2dpShKsyUzzfcRl92+VV1tkTq2l8KiR0L7Lo4cCHMHh7XcBVb+rWDGZsMc37FXzbIMCFildN/7ZUr7TdSIKIrSbOnk51jfsOcgZeWV9YLtpTDjfFhwv/Ue7GEeLMGih96neM1mQuTfMm7fMar2+l13hb9HkqNGRFGUZklZeSUfrt/jI3MbKz18Hatm1u/SCpXNNy0z9E28twT75d/y2fDr7Rdp1y1wnL3rA2UpghoRRVGaJSVbKnC5A+XfHDzqdeY/e/A7314aeqmpc19fX0ZuIfQqCD7SYS/fTLCtwDuXBb9HCqBGRFGUZsmovl1IdwYuMXVr7zWzGHqZldYdsd79s/mGc6q3zgqUDTw/RFuvmUhuIfQ92/d67xGkKmpEFEVplhTkZTFr2mjOGZRdNytIcwo/Gu6VLSm30ErrPva31rv/bq1wTvVg0e35Y6y4E7yXsxy+MxGAjDa+5zXfNfBpkhc1IoqiNFsK8rI4a0B3HA7LjDiC1a3LLQxM6+5h92ehB6/8MvhYV70HJ56PwWFFtKdl+hauAji4K/x5CqFxIoqiNFvKyiv53TtrcNkJtGpdbkq2VARu8w1Fj5Nh84fBr33yBJx4fqDxyS2ES2ey8p2nGd75UL0BmX0zVH0N7bpDpm99k6CzmhRBjYiiKM0Wy7nutbAkwqi+QSLIQ2FXKQyKCZ/S5EDHE2FMkeWYf3GClSIlGEMuTulgQzUiiqI0W0b17UJmuoPqGjcOh3DfpMGNn4UAYWuvizN4ShObDvvXw6Iy2Lk8tAEB+HZzE/RJPtSIKIrSbCnIy+KVn46iZEsFo/p2CW5AwuWx6uGXQ7bv2eA6Ats+tYII378NsgcF9tteyrCVd4EJky7FQ7g4lBRAjYiiKM2agrys0LOP7aXw0gVQexQcDpjwiO/S0uEKrP1Hbuu9cx4s/4e1lAVWv2BLWqtmISbM7MNHh6WWHimaiFF3ZymK0nLZusgyBLiteJA5t/gGF+aPAWc6VhyJ/e4TN+IOvqRVtSdQFgp3jZVPK0VRI6IoSsslf4w1A/Hgn+dqz+deRsPAt1sDx/CPAQHC+lKC0RSjk2SoEVEUpeWSW2gtYTnSrJgOp1dMhye1u3EBxjImu1YEjuEfAwLWNt6mcHhfUzVPGtSIKIrSshlxFVw9F86+C6a+W++b2LoI3K76duKAE87x6xziEeqfPqUhtpWkbDp4NSKKoijBotZbd8EnF+/oG+HC56DHEK+O7uCZf0ufa9r9jSv4OCmAGhFFUZRgHK6wZh8ASH3gYc6pfg2D+D82zW/6/Zb/MyVnIzE3IiLiFJEVIjLbPu8jIktEZJOIvCYiGbY80z7fZF/P9xrjdlu+QUTO9ZKfZ8s2ichtsf4siqKkBpsqXfxt4SbfAlTh8FQ3XDajvsph/hjLVwKAgRUzLXlmB9++/rEkEGTZqxG4a1OyOFU84kRuAtYBnm/+T8BjxphXReRp4FrgKfu90hhzgohcare7REQGAZcCJwG9gP+ISH97rL8B5wA7gKUi8q4x5vM4fCZFUZKUsvJKHlp6hFqzgYw0B6/8dFT4KHXvWBHc9Q72qe/CKVfAshepc6yvmmnFidQhwXdnXfgcFTu+oGvlyiZoboI76ZOcmM5ERCQHOB943j4X4GzgDbvJS8Bk+3iSfY59fazdfhLwqjHmqDHmS2ATUGi/NhljthhjqoFX7baKorRgSrZUUO22qhhW11gJF8OydZFd3dCuYGXc9UGER6vsRmKneBdwe1W6cjhDPvgPdBpipUbx9G8Me1LvN3Csl7MeB35D3V+HLsA+Y+pyAewAetvHvYHtAPb1/Xb7Orlfn1ByRVFaMFleddXdfudBqasB4v2gd8OXi2H161jOdQPHjbZ2XaVlAg5rqWvCIyEjzfd1GmyNK04v34pNRltIaxPYacXLDX/AJCNmy1kiMhHYa4wpE5GiWN2nkbpMA6YBZGdnU1xcHNE4VVVVEfeNFsmgg+qRfDokix7JoMP8NUexHvyWUZj50Vq++2ojJ2Q5Q/bp2fdq8ra+RmZ1BQIYhJptS7Fj1K09Wls+ZEXHc2HIPXTat4Z9nQZzoCofQnzeKmdOXdsu35TQ4eDG+rGqD9VpWCcDzM4VrHznaSsDcJSI9d8klj6R04ALRGQC0ArLJ/IE0ElE0uzZRg6w026/E8gFdohIGtARqPCSe/DuE0rugzHmWeBZgBEjRpiioqKIPlBxcTGR9o0WyaCD6pF8OiSLHonWoay8kkUffIL3rGJNhZsv9h1l1rTRoRMwLnreXtKyEEcaGcedClusWiKe0YY7N8DExxqlS3FxMcOLfmadLJsBs2/yGct73lMvc1s1SMYUNeoejdUjln+TmC1nGWNuN8bkGGPysRzjHxpjfgIsBC6ym00F3rGP37XPsa9/aIwxtvxSe/dWH6AfUAosBfrZu70y7Hu8G6vPoyhK8mPVDwmUV7sMby7fEbzT1kXg8kuWaNzQOT9IYxNE1gDLZsC6dyCtVePap5hzPRFZfG8FXhWR3wMrgBds+QvAP0RkE/AtllHAGLNWRF4HPgdqgRuMMS4AEbkRmAc4genGmLVx/SSKoiQVo/p2Id0pVLsCH/YhXdv+QYVgGRGM5dPwzFDECUMvb5pCXjOQoDhbWanlvdnzeUpl9I1LsKExptgYM9E+3mKMKTTGnGCM+bEx5qgtP2Kfn2Bf3+LV/wFjzPHGmAHGmLle8jnGmP72tQfi8VkURUleCvKyuOeCwUEfbCf16hhECmz6IIjQQI9hMP7P9g4r8YoZaQINOcoz2wXK1r0TKEtiNGJdUZRmReV31QGLTmLLg3Jwd3D57pVeMSAmsmDAhgpOdegZKBuYWpEKakQURWlWjOrbBaff2pUhzFbfkD4IsZa6ROwAxIym+ytadw5/vdNxfrd0WpUSUwg1IoqiNCs27D6Iv0sk7Ezk6IEQ8iqr/K3bjmI/78Ho+irECe2y8fHW+NczSQHUiCiK0mwoK6/kt/9aHbCcFXYmEmrH1c5l9ZHsxoQoPtUAe0NFoAuc/6gVvOhMrxc70lJud1ajjIiI9BeRBSKyxj4/WUTuiq1qiqIoTaNkS0XALATAIWFmIj2GBZf3HlEfcR7BUlaH/evh2y3BL544wapjklvo67z3j2xPARqr8XPA7UANgDHmM+wtuIqiKMlCMH8IQEaag1F9g9RCh9AzjMy2VhLGs+/0LVbVSDrtWxP8gjMDTrvZ9/7GTq3iqmm2y1ltjDH+ie5rg7ZUFEVJEAV5WfxgaK8A+VWj80Nn8s0f45Uo0Yvl/zimhIj7Og0OHLd3AVz1XpDiV54ISbd9njo01oh8IyLHYy8eishFwK6YaaUoihIhX35zKED23OIvw9cWMUHC3N218N7/wocPWKnim1gw6kDHE+F7v6AuQ5YzI7hzfvfK8OdJTmONyA3AM8CJIrITuBn4n1gppSiKEindOwSmF3G7TeiU8FsXEdK5btxW6VpXdZOXmTrsXw9LnsEKVHRavo+gS2L+62+NTBufJDTKiNhR5t8HugEnGmNON8ZsjalmiqIoEfCzM48PeLClh/OJhFrOqkMicqx32remcbu7hl5mFcFCrPehlzXpPommsbuz/iAinYwxh4wxB0Uky859pSiKklQU5GUxZVAGJ3RrS9f2GZzQvR33/OCk8NUNJcyv/97DI3Ks+9QTCWeEcgth/ENw/FnWewrlzYLGJ2Acb4y5w3NijKm0U7zrNl9FUZKKmUu28fLn1bixtvR+c7Cae/69lgE92gc3JFsXgdsVesCGUpeE4EDHEy3js3WRZUBCGYftpVZQo6sayj+1ItZTyJA01ifiFJG6b1JEWgORfbOKoigxoqy8kt+9swZ/N3l1bZgyufljfAP+/Cn/BGZMbLJjHbCMwZhbwhsFT3neCH0viaaxRuQVYIGIXCsi1wLzqa+HriiKkhRY9USCO8lDRqznFsKon4cf2HUUVs06Ru1C4CnPG2FQY6Jp1HKWMeZPIvIZMNYW3W+MmRc7tRRFUZrOqL5dSE9zUF0buGV37Vf7Q3fc/VkjRo+gIFVjyC1s3LJXktLoBPl2HY+5DTZUFEVJJCb4wz6sCRg4CTZ/GKaBNL0gVVPILUw54+EhrBERkcXGmNNF5CC+fwMBjDGmQ0y1UxRFaQIlWyqoCZI8y+mAC4fnhO444irrfcXLsHM5ASana/+UfcjHmrA+EWPM6fZ7e2NMB69XezUgiqIkGwcP1wSdcfTvHmJnljcjroKeJxN0ztJzaBS0awTLZsA/fmi9pwgNLmeJiBNYa4w5MQ76KIqiRMzaXcFrg4TM4OtP1dfB5Y3ymRwj8++Gjx+3jjd/CJVfwjn3xv6+x0iDu7OMMS5gg4gc11BbRVGURDJ+cJBys8DkYb0bOUIIz8nhMHm3osGyGfDxE76yj5+IbFtxnGnsFt8sYK1dU+RdzytcBxFpJSKlIrJKRNaKyL22vI+ILBGRTSLymohk2PJM+3yTfT3fa6zbbfkGETnXS36eLdskIrc1+dMritKsuHzkcfzhh0MY3MXBsJyOdGqTzuRhvbhtwsDGDdAuO7i8Vaeo6RjA9lKYcwuBBszAqpmxu2+UaKwR+S0wEbgPeMTrFY6jwNnGmKHAMOA8ERkF/Al4zBhzAlAJXGu3vxaotOWP2e0QkUFYtUtOAs4D/i4iTnuZ7W/AeGAQcJndVlGUFszlI49j8gkZfL7rAPu/q2HO6l3hM/h6U5fHyo8B46OrpDdbF1kleIOS/MkYwxoRezZxM/Bj4ETgY2PMfz2vcH2NRZV9mm6/DHA28IYtfwmYbB9Poj6A8Q1grIiILX/VGHPUGPMlsAkotF+b7OSQ1cCrdltFUVo4H++sodplMEC1y/Dm8h2N65hbCFfNhuPPpv4B7oBWMdxHFDK40JESyRgbmom8BIwAVmP94m9o9uGDPWNYCezFinLfDOwzxngKWu0APIuVvYHtAPb1/UAXb7lfn1ByRVFaPBLmrAFyC6HodjsVioAzHnXPg81E3MdUFCteNLQ7a5AxZgiAiLwANMnLYzvlh4lIJ+BtrNlM3BGRacA0gOzsbIqLiyMap6qqKuK+0SIZdFA9kk+HZNEjGXTYVOmiurYGpwguA2kO6MPeJunVYf96hrkNgsG4DSuXL+fA5u+apEdjv4vjyt+gD/WGztjHBjgy/wGWVOU36b6R6hEpDRmRGs+BMaZWwqVLDoMxZp+ILARGA51EJM2ebeQAO+1mO4FcYIeIpAEdgQovuQfvPqHk/vd/FngWYMSIEaaoqCiiz1FcXEykfaNFMuigeiSfDsmiR6J1KCuv5KH/lFBdK6Q5hZ+MyOVHw3MajhHxZ1EZntmB4GZ450MwpqhJQzT6u9jeBl74R92peL23drqP+fuM9d+koeWsoSJywH4dBE72HItI8A3ZNiLSzZ6BeLL+ngOsAxYCF9nNpgLv2Mfv2ufY1z80xhhbfqm9e6sP0A9rRrQU6Gfv9srAcr6H3TGmKErz5q3lO+ryZtXaketNNiCQPEkRjz87MfdtAmFnIsaYcOW+GqIn8JK9i8oBvG6MmS0inwOv2kWtVgAv2O1fAP4hIpuAb7GMAsaYtSLyOvA5UAvcYC+TISI3AvMAJzDdGLP2GPRVFCXF+frg0bDnjSaeSRHDpX7vnvwx3o1OwNhUjDGfAacEkW/B2lnlLz+CtQss2FgPAA8Ekc8B5hyzsoqiNAu6ts8Me94k4pUUMX8M1u/sIM711iFK+iYRjY0TURRFSXouHJ5DhlMQIMMp4ZMuJgu5hTDxMQL3kDlC12VPItSIKIrSbCjIy+KeCwZzUhcH91wwODJ/SCIYcRVc+wGceL7lhxGHVZY3BQpUxWw5S1EUJd6UlVdyz7/XUl3rDl9XPRnJLYRLZ1ppUFKoQJXORBRFaTZ4786qrnXzVmMj1ZWI0ZmIoijNho17Dvqcx6igbezYXgovXQCuamtr8dR3k342ojMRRVGaBTOXbKN0a32ixQarGSYjWxdZBsS4rPdw23+TBDUiiqI0C+au2eVzPrhXx9Txh3hIliDHJqDLWYqiNAvGD+7Joo3f1J1fcmoK1tGLZ5BjlFAjoihKs+DykZbRmLtmF8enH6g7TzniFeQYJdSIKIrSbBjQoz2V31WTua+q4cZKVFAjoihKs6CsvJKfPF9Cda2bNIFThlemnk8kHPPvhnXvwsAL4Jx7E61NHepYVxSlWVCypYKjNW7cBmrc1nmz4c3r4OPH4dst1vv8uxOtUR1qRBRFaRYcPFxTFxdi7PNmwfZSWP26r2zJ04nRJQhqRBRFaRb8Z92esOcpy9vXB8pqq+OvRwjUiCiK0izY7zfz8D9PSebfbS1hBWCsGUpTxnnylJgsg6ljXVGUZkFGujPsecqwvRRWzQQEvng/RCNjxZI0Yitwn80vwfa3rJOPH7feo+iY15mIoijNgl4dW4U9Twm2l8KM82HZi7BsOhz4Kng7ccL+HY2ajfTY/R9fwcpXoqBoPWpEFEVpFvTPbh/2PCXYughcDSzDOTOteiPLXoQZExs0JC6HX3XHtNbHqKQvakQURWkW/Gh4DhlpDgRIc1jnKUf+GMtAhMO4wV0DGHAdhVWzwjbfnudXdXzMLcemox/qE1EUpdlwUUEOAvRhb2oGGuYWwvmPwuybgly067C7/WYqVXut92UzYN07MHCSVSnR5lDbPOgxBCq3Qv/xPteigRoRRVFSHu9o9Yw0B78anpFolWKAO/SlN6+rjyXZ/KH1PuIq2F7KsBW31/dd/TrknRZVQxKz5SwRyRWRhSLyuYisFZGbbHlnEZkvIhvt9yxbLiLypIhsEpHPRGS411hT7fYbRWSql7xARFbbfZ4UEf9K94qitABKtlRQXWtHq9e6Wf+tK9EqRc6Kl5vW/vC3gcGInjE+fgLxNz7r3olctyDE0idSC9xijBkEjAJuEJFBwG3AAmNMP2CBfQ4wHuhnv6YBT4FldIC7gZFAIXC3x/DYba7z6ndeDD+PoihJyqi+XchIc+AUSE9zcGLnFN3eC3BgV8NtvNm2JFCWZu9MOxhkrB4nN12nMMRsOcsYswvYZR8fFJF1QG9gElBkN3sJKAZuteUvG2MMUCIinUSkp912vjHmWwARmQ+cJyLFQAdjTIktfxmYDMyN1WdSFCV5+dFwyx/yo+E5HPxyVaLViZyjBxtu440JNuuyE8CcMgV2lvleatUhIrVCERefiIjkA6cAS4Bs28AA7Aay7ePewHavbjtsWTj5jiByRVFaEGXllVz27KdUuwwCtM9MY1SbRGt1DOScCls+DJS3zoLDlYHyYNQetd6zB+HGgdOzpOXMjHq1xJgbERFpB7wJ3GyMOeDttjDGGBExITtHT4dpWEtkZGdnU1xcHNE4VVVVEfeNFsmgg+phUbythmV7ahncyYU1oU4syfA3SYQOT5YdodplPUYM8PRHW9h3vCHRf5NIv4vjTG/6AN4OXgMcdqfROohcqJt31PFF25HsKi7muPI3yLdlboRd3c9i4+bvYHPT9QpFTI2IiKRjGZBXjDF23D17RKSnMWaXvVxl709jJ5Dr1T3Hlu2kfvnLIy+25TlB2gdgjHkWeBZgxIgRpqioKFizBikuLibSvtEiGXRQPWDmkm3M+Hw1AGsqhJNP7pvwSnrJ8DeJtw5l5ZUsf/+TAPl/dgoPXhc/PYIR8XexvQ288E+8TYMAbXr0g/KvfZqK3zsAPYYw4PI/MsAeyz39VTAGhzOD3hNuoXeUqybGcneWAC8A64wxj3pdehfw7LCaCrzjJZ9i79IaBey3l73mAeNEJMt2qI8D5tnXDojIKPteU7zGUpSY8trSbWHPlfjwzH83B5V/l/K5F4Ms0HQbgJ+5CI5fhl/jkyA/+sRyd9ZpwJXA2SKy0n5NAB4EzhGRjcD37XOAOcAWYBPwHPBzANuhfj+w1H7d53Gy222et/tsRp3qSpzI7tAq7LkSH9Z+tT+ovEubFN7tv3VRoMyRBkMvh7zvNdz/2y31qVC2LsJh3IABtyv42MdILHdnLSa02RwbpL0Bbggx1nRgehD5MmDwMaipKBFx/ZnHs3DDXmpcBqdY50r8aZ0R4hEWc09rDMkfY+W3qj1snWcPgYmPWtHs378HXhwP7trQ/Y3bytZbcxh6nIwRJ2KMZYii7FQHjVhXlIgoyMvi2tP68P7a3QxqX52aKTaaAb06tmLT3qoAeVVNCluR3EKY+q41a8gf45vuPbcQrp5rpYpf9hLgtjL6nv8ozP11ffLG9e9Z75s/xFpwMpZxiQFqRBQlAh6cs46nP7KKBW2tgGkvL+P6M49XYxJntn37XVD56J4p/mjLLQxdK8Rzbejl9YYGwBgsY+EbN1IXse6usZI1popjXVGaK2XllTzzkW+1uQ8+38Nlz5VQVt7IffxKVDjvpB4BsmE5Hbn4xMwgrZsZuYVWRt7cQmtm4p+YMRhfb4i6GmpEFKWJPPPfzUGX3Ktr3by1fEeQK0o8ad86PdEqxJ+qrxtuA1YhqyijRkRRmkioHUGQ2v7cVGPmkm11S4rejB/cMwHaJJh23UNe8tndlBb9XYRqRBSliYTbPDq4V8e46dHSmbsmMLngGf26JjzoMyEMvaxx7Ub9POq3ViOiKE1kYAhDIUDld9VBrynR56SegYkEdSYYSN130qsg6gWpQI2IojSZn515fMjZyKi+XeKqS0vm/bW7A2QtcikLQgcRdu5LrbMNDLkYpgVJ6hgF1IgoSgQ4gvzPMcCG3U1M461EzFf7DvucO4WWuZQF1jZfp1c1R3HAxCfg/63g4zGz4MLnYnZrNSKK0kTeWr4DV4i4Lc2hFT8G+S1nDendgv1RuYVw1Xsw4moYcQ1cMy8mS1fBSPGIHEWJP+HW3TPT9HdZvDipd0dW7qjfKXdOkJiRFkW4AMUYov/iFaWJXDg8B0cIp0i/7PbxVaaFUlZeyStLfGd9WW0yQrRWYokaEUWJABNiOnLoaJjEeErUuOX1lQEy3RmXGNSIKEoTKdlSEXJJq2RLRVx1iRZl5ZX8beGmlEnbUl4RmDNLd8YlBvWJKEoTGdW3C04BVxBLkopLKmXllfzk+RKO1rhxOoT7Jg1O6l1OM5dsCzDi6Q40+WWC0JmIojSRgrwsXv/Z98jr3Cbg2uZvDqXMr3kPJVsqOFLjxgC1bsNv31nDzCXbkmJmEmyGFGwHXPtWLTBfVpKgMxFFiYCCvCwuPjWXh+dt8PlV7HK5KdlSkVK/iv1nTy634c63V2OANKfw2rTRCfk8ZeWVXPzMJ3XbqccNyub6M4+ne4dWgG/+sotH5MZdP8VCZyKKEgEzl2zjg7W7SXOKT/S6IfWWtNYESSjpMYy1LhOyjnmsufrFJT7xOB98voeLn/mUthlOn3Zn9OvKbRMGxlk7xYPORBSliXgXpALIbS9sP2g9dt0G7nh7NY/O34DbwMUFOUn/gPvm4NGw19fuOhAnTeqZ8sISDhxxBchdbsO/Vn7lI8sNsqyoxA+diShKEwhWkGrnwUAP+zdV1Xx7qJqnP9rCg3PWxUu9iGgoaeH+Q/HfOrt40zeNbvv+6sBsvkr8iJkREZHpIrJXRNZ4yTqLyHwR2Wi/Z9lyEZEnRWSTiHwmIsO9+ky1228Ukale8gIRWW33eVJEwmXoVpSoEKwgVUOVq18vS+5CVTtClJj1UFXt4uZXV8RJG2up0N2EdLz7Djeiop8SM2I5E5kBnOcnuw1YYIzpByywzwHGA/3s1zTgKbCMDnA3MBIoBO72GB67zXVe/fzvpShRZ8+BIz7nvTu1Ir2B/0WhotuThS0Vhxps86+VX5F/23tNMiZTXlhC/zvnUPTnhWF3efnvwApWJyQcLTpnVhIQMyNijPkI+NZPPAl4yT5+CZjsJX/ZWJQAnUSkJ3AuMN8Y860xphKYD5xnX+tgjCkxxhjgZa+xFCVmXHKqb/zEDWf145zjwrsWhx9Xv7Mp2YL6ysorOVrT0Fyqnn+t/KpRhmTKC0v4aOM3VLsMWyu+46KnPgn4zDOXbGPSXxdz6bOf8vC8DVzyzKfMXLKtyenc/3Xj6U1qr0SXeDvWs40xnp8Zu4Fs+7g3sN2r3Q5bFk6+I4hcUWLKNr9f7dsqDnHxiZl8ti+NHfuOBO1TNMAqXXrzqyvqnMIZTmFWgrbOehNJhP2c1bvol92eUX27hNT/o42+Pg0DvLl8R137mUu2ccfbq33a1LoNd7y9mmE5vjMLIbTfxr+tEn/EhEoCFI3BRfKB2caYwfb5PmNMJ6/rlcaYLBGZDTxojFlsyxcAtwJFQCtjzO9t+W+Bw0Cx3f77tnwMcKsxZmIIPaZhLZORnZ1d8Oqrr0b0eaqqqmjXrl1EfaNFMujQkvX434XfUXm0/v9MVqZw/6luln2byYzPgzug+3cSTujkZM5W37xaZ+U4mTo4ejWvI/kuirfVhNS7MXRMhyfGtvXRIdR30cYJfz/HanvfJ9+x5UDjnj2hjEjXTHj4rLZBriTHv89k0CFaepx11lllxpgRwa7FeyayR0R6GmN22UtSe235TsA7WijHlu3EMiTe8mJbnhOkfVCMMc8CzwKMGDHCFBUVhWoaluLiYiLtGy2SQYeWrEePlR9R6VV4qkdWO9q1c9O/W1/4fHXQPl/sM3yxLzAx4+7aNhQVnRE13SL5Lma+vAzYE/E999fAzf89ysq7zwXg+bcX8NLnwWdk37mgfZ+hFORlcdsn/wHCby0ORftMJ7dPGBQ2NUsy/PtMBh3ioUe8t/i+C3h2WE0F3vGST7F3aY0C9tvLXvOAcSKSZTvUxwHz7GsHRGSUvStritdYihIzTvFbvvGcR1KMakdl+F1RsWbKC0v44PPIDYiHfYdrmblkG2XllfxhyZGwW4bvens1M5dsY/eBxhsQpwP+8MMhjOnXlT/8cAir7z0vqXN7tTRiNhMRkVlYs4iuIrIDa5fVg8DrInItUA5cbDefA0wANgHfAVcDGGO+FZH7gaV2u/uMMR5n/c+xdoC1BubaL0WJKf7bYQf36giHK8gOkoqjIQ4edVFWXlnnJ5j818Ws+eoAg3t1iLmz+JxHitn4dfhdWWf06wpYfpPqYNkmvfjT++uYdsbxDW533rDnINM//rIpqjLx5F5cPvI4NRxJSsyMiDHmshCXxgZpa4AbQowzHZgeRL4MGHwsOipKU3hwzroAh/Har/bTK8tynkfyq/6ut1cz9+YzmPzXxXVV+lbu2M/kvy6OmSGZuWRbSAPSo30mV34v38dpft3Ly5jfwGc7cLiWJY1w0rsNoYuxBGHysF48fukpjW6vxB9Ne6IojeQfJeUBsq8PHoWsyAsirdt9kAfnrOOznb6zGO+yr9HmsfkbQl5r1yqNG846wUf25TcNx5EYYNHGxkWZt8sM/thJc8D3ju/KZzv3U9S/mxqPFEGNiKI0grLySg5VB+Zy6to+E6g6pqSLT/ulUfEw6LdzaZWRFvX8W1Vhqi/26Ra4i6dv17Zs2lvV4LjB5heF+VmUbvWND/E3kO0znfys6ISwW4aV5EVzZylKIwhWjhWseusQm9Ks39W46/JvRTPtSE6n1iGv/ezM4wNk1595fERR9zmdWnHr+IE4G+h7uMbNDWedoAYkRdGZiKI0gvIg+aXOGZRNQV4WxV8Gpn93OiCnU5uAfuEC58Lxr5VfBWSvzenUisW3BbgYG+RgiJnIz87oG/RBXpCXxf/97Hs8/d/NLPria47UNi7CvU+3dnUFvO56ezXrvLZGe9M7jFFTkh+diShKA5SVVwb1BR/ftT7QrfK76rq6IoKVHuVobeDyVzRDe3fsO8LpDy5ocj9/g9c2w8kffjgk7JJZQV4Wz00Zwfrfj6/bbts+0xmyPVCXvqShGcajlwxrnOJKUqJGRFEaINRSlnedjVF9u5CZ7sApkJnu4MLhOUweFpiJp32mkzf/53tR021niFQroSgrrwyYEdx5fvjAPX8uH3kc/7h2JDOuGUmolaqfndG3bsxg9/TQPtOpy1gpji5nKUoYHpyzjq0VwYMCT+rZoe64IC+LV346ipItFXUO4oK8LHYfOOKzDDXjmpEU5GWR1zlwqSsSWqU17Xfg1S+WBsgi9ecU5GXxxv98jzeX7+D/lm2nxmVwCPx+8hAfoxQuP9eMa0ZGdG8leVAjoihhCBcY1751us+5x3B48/ilp3Dl6Hwf4wLWEs6FT31yzPodrnUzc8m2BmcSZeWVXPz0JwSLGRzVt0vE9/d85guH51CypYLMfeUBugTbuZbmEF67PvEJKJVjR5ezFMWPmUu2ceULS5i5ZFvISO1W6Y5GP3wL8rICdh8V5GXx5v98j85tfA1Rt3YZZNjbmTxLRRlOoV+3tnRqkx505tFQ/Y2y8koufCq4AUlzNOyzaAyez3hCVqCfJFiN9vsmDVYD0kzQmYii2JSVV/rsIgoVPPeTkcfxo+E5x/wQLMjLYvnvxlFWXhkwUwmn40VPfeLjoPdeVgvGb/8VPDEkQH6X4Flwo8nOfYd9zh2gKUyaEWpEFIXgD+dgDM3pyAM/HBLVewdbBgvX9jg/f8oLi7ewdtcBjk+v8Ul57TFOG/YEd2oDXHN63wi1bjy9O7X20Te3c5uY31OJH2pEFAX409x1jdp+61/ZMBHsPei7I6vGbc2aFgH/uP097p88hIfnrefb70LXHk9zCPdNGhyXGcGjlwyrM9CCbultbqgRURRoVFoPhyTHMkzrdCeHQ5S0dRkCKgb64xTY9IcJsVAtKJ5dXI1dslNSCzUiigIcqQkMDPRn2pjYL/00howmbuv1Z0jv+JeUbcqSnZJaqBFRWhynP7igrh66p0b3dyF+2XtIcxDVJIjHwuRhvUMmbWyINAcxr1WitCzUiCgtioF3zeWwV+6nxqZcv29SdJ3px8JtEwZSsqWiyeniI821pSjhUCOitBjOeaTYx4CEIyPNQU2tGxFrGSsZfCHe/OvG0wOqEzogoLLgGf268vK1GhWuxA41IkqLYPJfFzdYDtZDplOYed2opHcEz7+liJtfXUHxF19T1L8bk3vsp6ioKNFqKS0MNSJKs2Lmkm3MXbOL8YN71s0eGlNP3GeMaaNTxhHsXf2vuLg4cYooLRY1Io3kwTnreO6jQ7jefw8Ap0O47vQ+SeNsbWnc/OoK/r3qK9wGTigrZvPXh3yWchZt/KbBra7BGNijfUoYD0VJFlLeiIjIecATgBN43hjzYLTv8eCcdQG7YVxuw9MfbfGR+68/l5VXcvmzn3I0RP6l/C5teOTiYS3qoRVqVtAqzcEr141i6gtLqApShjYcTZlleHAKbP7j+cxcso07316NwSok9fsoR6MrSnMnpY2IiDiBvwHnADuApSLyrjHm82jeZ8anWxvV7qON35B/23uNHndrxXeRZXJ9/z1apzno36M92R1aUfplBfsO11era5vh5MpReUFnSd7bW73p1i6DpXedU3d+6u/n83VVAynC32/8Z22II7XuqGS1bQwOLAMCVvDggB7tk97/oSjJSkobEaAQ2GSM2QIgIq8Ck4CoGpGaRu7oiSeHa92s2rEfCNzmeajaFTBLaoivq6qbZABTFc8MxJtU8X8oSjKS6qngewPbvc532LKoctoJXaM9pJIA+nVrG2BAFEU5NsQEKx6dIojIRcB5xpif2udXAiONMTf6tZsGTAPIzs4uePXVV5t8r4dLD7PmWxeELAgaLzxp7BJN8unRMR2eGBv71Ob+VFVV0a5du7jfNxn1SAYdkkWPZNAhWnqcddZZZcaYEcGupfpy1k4g1+s8x5b5YIx5FngWYMSIESaSvfRFRdYWyqKioqCO9nBkOIU0h+AyMH5wD7Z+c6jJ0cb1JMODG45Vj0E923P/5CEU5GUx7N55Pj6ddhlO1tx3XqPG8fxNEkky6JAseiSDDsmiRzLoEA89Ut2ILAX6iUgfLONxKXB5rG9624SBHNelLdMXbwERrjmtT9wimp9/ewF/WnoE/1RPaQ4hq016w85wrMf/9Wf05bYJAykrr+TSZz4JGA8s/8H9fvWyPUTzH+bKu8+NyjiKosSflDYixphaEbkRmIe1xXe6MWZtPO59+cjjEpIK44QsJxv/EL11/YK8rKiOpyhKyyKljQiAMWYOMCfReiiKorREUn13lqIoipJA1IgoiqIoEaNGRFEURYkYNSKKoihKxKgRURRFUSImpSPWI0FEvgbKI+zeFfgmiuqkqg6geiSbDpAceiSDDpAceiSDDhAdPfKMMd2CXWhxRuRYEJFloUL/W5IOqkfy6ZAseiSDDsmiRzLoEA89dDlLURRFiRg1IoqiKErEqBFpGs8mWgGSQwdQPbxJBh0gOfRIBh0gOfRIBh0gxnqoT0RRFEWJGJ2JKIqiKBHToo2IiOSKyEIR+VxE1orITba8s4jMF5GN9nuWLT9RRD4VkaMi8qsg4zlFZIWIzE6EDiKyVURWi8hKEVmWqO9CRDqJyBsisl5E1onI6HjrISID7O/B8zogIjcn4Lv4X3uMNSIyS0Raxfu7sK/dZOuwtrHfQ4Q6/EREPrP/HX4iIkO9xjpPRDaIyCYRua2xOsRAj+kisldE1jRFh2jqEWqcOOvQSkRKRWSVPc69Tf0+ADDGtNgX0BMYbh+3B74ABgEPAbfZ8tuAP9nH3YFTgQeAXwUZ75fATGB2InQAtgJdE/1dAC8BP7WPM4BOifqb2G2cwG6sve5x0wGrVPOXQGv7/HXgqnh/F8BgYA3QBitz93+AE2Kkw/eALPt4PLDE62+wGehr/5tYBQyK4XcRVA/7/AxgOLAmDv9PQn0fQceJsw4CtLOP04ElwKgmfydN7dCcX8A7wDnABqCn1x9sg1+7ewh8cOYAC4CzaYIRibIOW4nQiERLD6Aj1oNTEv038bo2Dvg4Ad9Fb2A70Bnr4T0bGJcAPX4MvOB1/lvgN7HUwZZnATvt49HAPK9rtwO3x/q78NfDS5ZPBEYk2nr4j5MoHbB+YCzHKi/epPu36OUsb0QkHzgFyxpnG2N22Zd2A9mNGOJx4DdAkBqBcdPBAB+ISJlYdeUToUcf4GvgRbGW9p4XkYgKn0fh+/BwKTAr3joYY3YCDwPbgF3AfmPMB/HWA2sWMkZEuohIG2ACvmWlY6XDtcBc+9hjUD3ssGVN5hj1iBrR0sNvnLjqINYS/EpgLzDfGNNkHdSIACLSDngTuNkYc8D7mrHMdNgtbCIyEdhrjClLlA42pxtjhmNNWW8QkTMSoEca1lLBU8aYU4BDWFPreOvhGScDuAD4v3jrYK9JT8IyrL2AtiJyRbz1MMasA/4EfAC8D6wEXLHUQUTOwnpg3dqU+7Q0PcKNEw8djDEuY8wwrJWUQhEZ3BQdQI0IIpKO9Yd4xRjzli3eIyI97es9sax0OE4DLhCRrcCrwNki8s846+D55YsxZi/wNlDYWB2iqMcOYIfXL5o3sIxKvPXwMB5YbozZkwAdvg98aYz52hhTA7yFtT4dbz0wxrxgjCkwxpwBVGKto8dEBxE5GXgemGSMqbDFO/Gd/eTYskYTJT2OmWjpEWKcuOrgwRizD1gInNcUPaCFGxEREeAFYJ0x5lGvS+8CU+3jqVhrjiExxtxujMkxxuRjLZ18aIxp1C/OaOkgIm1FpL3nGMsP0OjdJ1H8LnYD20VkgC0aC3webz28uIwmLmVFUYdtwCgRaWOPORZYlwA9EJHu9vtxwI+wNoBEXQd7/LeAK40x3oZqKdBPRPrYs8NL7TEaRRT1OCaipUeYceKpQzcR6WQft8byq6xvii5Ay3asA6djTfk+w5rir8RaL+6C5STfiLWTpbPdvgfWL+0DwD77uIPfmEU0bXdWVHTA2vWyyn6tBe5M1HcBDAOW2WP9C3tnSAL0aAtUAB0T+F3ci/Ufcw3wDyAzQXoswjLmq4CxMdTheayZjqftMq+xJmDNgDYT+3+f4fSYheWjqrG/o2vjrUeoceKsw8nACnucNcDvmvoMNcZoxLqiKIoSOS16OUtRFEU5NtSIKIqiKBGjRkRRFEWJGDUiiqIoSsSoEVEURVEiRo2IosQQEXGJlUV4rZ0t9RYRCfv/TkTyReTyeOmoKMeCGhFFiS2HjTHDjDEnYQVzjQfubqBPPqBGREkJNE5EUWKIiFQZY9p5nffFit7uCuRhBSB6ElTeaIz5RERKgIFY2ZBfAp4EHsQKZM0E/maMeSZuH0JRwqBGRFFiiL8RsWX7gAHAQcBtjDkiIv2AWcaYESJShJXKfaLdfhrQ3RjzexHJBD4GfmyM+TKOH0VRgpKWaAUUpQWTDvxVRIZhZdXtH6LdOOBkEbnIPu8I9MOaqShKQlEjoihxxF7OcmFlWL0b2AMMxfJPHgnVDfiFMWZeXJRUlCagjnVFiRMi0g14GvirsdaROwK7jDFu4EqsErJgLXO19+o6D/gfO/03ItJfIiz0pSjRRmciihJbWtuV49KBWixHuid999+BN0VkClaxqEO2/DPAJSKrgBnAE1g7tpbbacC/BibHR31FCY861hVFUZSI0eUsRVEUJWLUiCiKoigRo0ZEURRFiRg1IoqiKErEqBFRFEVRIkaNiKIoihIxakQURVGUiFEjoiiKokTM/wcC50uQ4AyRoQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_time_series(X_viz, y_viz, label='Training data')\n",
        "plot_time_series(X_viz_, y_viz_, label='Test data')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b0a42e9",
      "metadata": {},
      "source": [
        "### Create windowed datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "db2f8daf",
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "Upon experimentation conducted in the\n",
        "https://github.com/Ammar-Raneez/FYP_Algorithm/blob/main/experiments/experiments.ipynb\n",
        "The below were the optimal window and horizon values\n",
        "'''\n",
        "\n",
        "HORIZON = 1\n",
        "WINDOW_SIZE = 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "1b531611",
      "metadata": {},
      "outputs": [],
      "source": [
        "btc_prices_windowed = btc_prices.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "dfe99dea",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Price</th>\n",
              "      <th>Price+1</th>\n",
              "      <th>Price+2</th>\n",
              "      <th>Price+3</th>\n",
              "      <th>Price+4</th>\n",
              "      <th>Price+5</th>\n",
              "      <th>Price+6</th>\n",
              "      <th>Price+7</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2014-01-01</th>\n",
              "      <td>815.940002</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-01-02</th>\n",
              "      <td>856.909973</td>\n",
              "      <td>815.940002</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-01-03</th>\n",
              "      <td>884.260010</td>\n",
              "      <td>856.909973</td>\n",
              "      <td>815.940002</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-01-04</th>\n",
              "      <td>924.690002</td>\n",
              "      <td>884.260010</td>\n",
              "      <td>856.909973</td>\n",
              "      <td>815.940002</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-01-05</th>\n",
              "      <td>1014.739990</td>\n",
              "      <td>924.690002</td>\n",
              "      <td>884.260010</td>\n",
              "      <td>856.909973</td>\n",
              "      <td>815.940002</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-01-06</th>\n",
              "      <td>1012.650024</td>\n",
              "      <td>1014.739990</td>\n",
              "      <td>924.690002</td>\n",
              "      <td>884.260010</td>\n",
              "      <td>856.909973</td>\n",
              "      <td>815.940002</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-01-07</th>\n",
              "      <td>879.900024</td>\n",
              "      <td>1012.650024</td>\n",
              "      <td>1014.739990</td>\n",
              "      <td>924.690002</td>\n",
              "      <td>884.260010</td>\n",
              "      <td>856.909973</td>\n",
              "      <td>815.940002</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-01-08</th>\n",
              "      <td>938.840027</td>\n",
              "      <td>879.900024</td>\n",
              "      <td>1012.650024</td>\n",
              "      <td>1014.739990</td>\n",
              "      <td>924.690002</td>\n",
              "      <td>884.260010</td>\n",
              "      <td>856.909973</td>\n",
              "      <td>815.940002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-01-09</th>\n",
              "      <td>936.950012</td>\n",
              "      <td>938.840027</td>\n",
              "      <td>879.900024</td>\n",
              "      <td>1012.650024</td>\n",
              "      <td>1014.739990</td>\n",
              "      <td>924.690002</td>\n",
              "      <td>884.260010</td>\n",
              "      <td>856.909973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-01-10</th>\n",
              "      <td>957.760010</td>\n",
              "      <td>936.950012</td>\n",
              "      <td>938.840027</td>\n",
              "      <td>879.900024</td>\n",
              "      <td>1012.650024</td>\n",
              "      <td>1014.739990</td>\n",
              "      <td>924.690002</td>\n",
              "      <td>884.260010</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Price      Price+1      Price+2      Price+3      Price+4  \\\n",
              "date                                                                          \n",
              "2014-01-01   815.940002          NaN          NaN          NaN          NaN   \n",
              "2014-01-02   856.909973   815.940002          NaN          NaN          NaN   \n",
              "2014-01-03   884.260010   856.909973   815.940002          NaN          NaN   \n",
              "2014-01-04   924.690002   884.260010   856.909973   815.940002          NaN   \n",
              "2014-01-05  1014.739990   924.690002   884.260010   856.909973   815.940002   \n",
              "2014-01-06  1012.650024  1014.739990   924.690002   884.260010   856.909973   \n",
              "2014-01-07   879.900024  1012.650024  1014.739990   924.690002   884.260010   \n",
              "2014-01-08   938.840027   879.900024  1012.650024  1014.739990   924.690002   \n",
              "2014-01-09   936.950012   938.840027   879.900024  1012.650024  1014.739990   \n",
              "2014-01-10   957.760010   936.950012   938.840027   879.900024  1012.650024   \n",
              "\n",
              "                Price+5     Price+6     Price+7  \n",
              "date                                             \n",
              "2014-01-01          NaN         NaN         NaN  \n",
              "2014-01-02          NaN         NaN         NaN  \n",
              "2014-01-03          NaN         NaN         NaN  \n",
              "2014-01-04          NaN         NaN         NaN  \n",
              "2014-01-05          NaN         NaN         NaN  \n",
              "2014-01-06   815.940002         NaN         NaN  \n",
              "2014-01-07   856.909973  815.940002         NaN  \n",
              "2014-01-08   884.260010  856.909973  815.940002  \n",
              "2014-01-09   924.690002  884.260010  856.909973  \n",
              "2014-01-10  1014.739990  924.690002  884.260010  "
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "for i in range(WINDOW_SIZE):\n",
        "    btc_prices_windowed[f'Price+{i+1}'] = btc_prices_windowed['Price'].shift(periods=i+1)\n",
        "\n",
        "btc_prices_windowed.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "6d547e2f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create X (windows) and y (horizon)\n",
        "X = btc_prices_windowed.dropna().drop('Price', axis=1).astype(np.float32)\n",
        "y = btc_prices_windowed.dropna()['Price'].astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "a064ba70",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Price+1</th>\n",
              "      <th>Price+2</th>\n",
              "      <th>Price+3</th>\n",
              "      <th>Price+4</th>\n",
              "      <th>Price+5</th>\n",
              "      <th>Price+6</th>\n",
              "      <th>Price+7</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2014-01-08</th>\n",
              "      <td>879.900024</td>\n",
              "      <td>1012.650024</td>\n",
              "      <td>1014.739990</td>\n",
              "      <td>924.690002</td>\n",
              "      <td>884.260010</td>\n",
              "      <td>856.909973</td>\n",
              "      <td>815.940002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-01-09</th>\n",
              "      <td>938.840027</td>\n",
              "      <td>879.900024</td>\n",
              "      <td>1012.650024</td>\n",
              "      <td>1014.739990</td>\n",
              "      <td>924.690002</td>\n",
              "      <td>884.260010</td>\n",
              "      <td>856.909973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-01-10</th>\n",
              "      <td>936.950012</td>\n",
              "      <td>938.840027</td>\n",
              "      <td>879.900024</td>\n",
              "      <td>1012.650024</td>\n",
              "      <td>1014.739990</td>\n",
              "      <td>924.690002</td>\n",
              "      <td>884.260010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-01-11</th>\n",
              "      <td>957.760010</td>\n",
              "      <td>936.950012</td>\n",
              "      <td>938.840027</td>\n",
              "      <td>879.900024</td>\n",
              "      <td>1012.650024</td>\n",
              "      <td>1014.739990</td>\n",
              "      <td>924.690002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-01-12</th>\n",
              "      <td>1005.320007</td>\n",
              "      <td>957.760010</td>\n",
              "      <td>936.950012</td>\n",
              "      <td>938.840027</td>\n",
              "      <td>879.900024</td>\n",
              "      <td>1012.650024</td>\n",
              "      <td>1014.739990</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Price+1      Price+2      Price+3      Price+4      Price+5  \\\n",
              "date                                                                          \n",
              "2014-01-08   879.900024  1012.650024  1014.739990   924.690002   884.260010   \n",
              "2014-01-09   938.840027   879.900024  1012.650024  1014.739990   924.690002   \n",
              "2014-01-10   936.950012   938.840027   879.900024  1012.650024  1014.739990   \n",
              "2014-01-11   957.760010   936.950012   938.840027   879.900024  1012.650024   \n",
              "2014-01-12  1005.320007   957.760010   936.950012   938.840027   879.900024   \n",
              "\n",
              "                Price+6      Price+7  \n",
              "date                                  \n",
              "2014-01-08   856.909973   815.940002  \n",
              "2014-01-09   884.260010   856.909973  \n",
              "2014-01-10   924.690002   884.260010  \n",
              "2014-01-11  1014.739990   924.690002  \n",
              "2014-01-12  1012.650024  1014.739990  "
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "8054dc42",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "date\n",
              "2014-01-08     938.840027\n",
              "2014-01-09     936.950012\n",
              "2014-01-10     957.760010\n",
              "2014-01-11    1005.320007\n",
              "2014-01-12     939.789978\n",
              "Name: Price, dtype: float32"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "a98b44d2",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2643, 2643, 661, 661)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "split_size = int(len(X) * .8)\n",
        "\n",
        "X_train, y_train = X[:split_size], y[:split_size]\n",
        "X_test, y_test = X[split_size:], y[split_size:]\n",
        "len(X_train), len(y_train), len(X_test), len(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18c790e8",
      "metadata": {},
      "source": [
        "### Create performant tensorflow datasets\n",
        "\n",
        "`tf.data` API creates more optimized datasets that can make the model run faster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "b58ec4f8",
      "metadata": {
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<PrefetchDataset element_spec=(TensorSpec(shape=(None, 7), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.float32, name=None))>,\n",
              " <PrefetchDataset element_spec=(TensorSpec(shape=(None, 7), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.float32, name=None))>)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# create tensorflow Datasets\n",
        "train_features_dataset = tf.data.Dataset.from_tensor_slices(X_train)\n",
        "train_labels_dataset = tf.data.Dataset.from_tensor_slices(y_train)\n",
        "\n",
        "test_features_dataset = tf.data.Dataset.from_tensor_slices(X_test)\n",
        "test_labels_dataset = tf.data.Dataset.from_tensor_slices(y_test)\n",
        "\n",
        "# Combine features and labels\n",
        "train_dataset = tf.data.Dataset.zip((train_features_dataset, train_labels_dataset))\n",
        "test_dataset = tf.data.Dataset.zip((test_features_dataset, test_labels_dataset))\n",
        "\n",
        "# batch and prefetch for optimal performance\n",
        "BATCH_SIZE = 1024\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_dataset, test_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed4b07b2",
      "metadata": {},
      "source": [
        "### Create callback functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "69080afd",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model checkpoint with a specific filename\n",
        "def create_model_checkpoint(model_name, save_path='model_checkpoints', monitor_dataset_loss=False):\n",
        "    return tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath=os.path.join(save_path, model_name),\n",
        "        verbose=0,\n",
        "        save_best_only=True,\n",
        "        monitor='loss' if monitor_dataset_loss else 'val_loss',\n",
        "    )\n",
        "\n",
        "# Create a tensorboard callback\n",
        "def create_tensorboard_callback(dir_name, experiment_name):\n",
        "    log_dir = dir_name + '/' + experiment_name + '/' + datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
        "    tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "      log_dir=log_dir\n",
        "    )\n",
        "\n",
        "    print(f'Saving TensorBoard log files to: {log_dir}')\n",
        "    return tensorboard_callback\n",
        "\n",
        "# Create early stopping callback\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    patience=200,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "# create reduce lr on plateau callback\n",
        "reduce_lr_plateau = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    patience=100,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5be3a6c",
      "metadata": {},
      "source": [
        "### Create model architecture\n",
        "\n",
        "The below architecture was also the best performing from experimentation conducted in [FYP_Algorithm](https://github.com/Ammar-Raneez/FYP_Algorithm/blob/main/experiments/experiments.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "bc854c0f",
      "metadata": {},
      "outputs": [],
      "source": [
        "model_univariate = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(WINDOW_SIZE)),\n",
        "    tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=1)),\n",
        "    tf.keras.layers.RNN(LTSCell(32), time_major=True, return_sequences=True),\n",
        "    tf.keras.layers.LSTM(32, activation='relu'),\n",
        "    \n",
        "    # Number forecasts therefore no need an activation\n",
        "    tf.keras.layers.Dense(HORIZON, activation='linear')\n",
        "], name='model_univariate')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "92ae5ac5",
      "metadata": {},
      "outputs": [],
      "source": [
        "#LTC architectures requirer higher learning rate\n",
        "model_univariate.compile(\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate = .01),\n",
        "    loss = tf.keras.losses.MAE,\n",
        "    metrics = ['mae', 'mse']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "ad07cb89",
      "metadata": {
        "collapsed": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: tensorboard_logs/model_univariate/20230129-125617\n",
            "Epoch 1/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 6317.9624 - mae: 6317.9624 - mse: 112391288.0000INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate\\assets\n",
            "3/3 [==============================] - 71s 15s/step - loss: 6317.9624 - mae: 6317.9624 - mse: 112391288.0000 - val_loss: 34769.8477 - val_mae: 34769.8477 - val_mse: 1425050240.0000 - lr: 0.0100\n",
            "Epoch 2/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 5458.4390 - mae: 5458.4390 - mse: 101007488.0000INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate\\assets\n",
            "3/3 [==============================] - 33s 12s/step - loss: 5458.4390 - mae: 5458.4390 - mse: 101007488.0000 - val_loss: 34552.0586 - val_mae: 34552.0586 - val_mse: 1412947584.0000 - lr: 0.0100\n",
            "Epoch 3/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 5186.0259 - mae: 5186.0259 - mse: 92155976.0000INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate\\assets\n",
            "3/3 [==============================] - 33s 12s/step - loss: 5186.0259 - mae: 5186.0259 - mse: 92155976.0000 - val_loss: 33523.0430 - val_mae: 33523.0430 - val_mse: 1357497984.0000 - lr: 0.0100\n",
            "Epoch 4/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 5404.5132 - mae: 5404.5132 - mse: 91064808.0000INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate\\assets\n",
            "3/3 [==============================] - 33s 12s/step - loss: 5404.5132 - mae: 5404.5132 - mse: 91064808.0000 - val_loss: 33068.9297 - val_mae: 33068.9297 - val_mse: 1333928448.0000 - lr: 0.0100\n",
            "Epoch 5/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 5519.6309 - mae: 5519.6309 - mse: 90845000.0000INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate\\assets\n",
            "3/3 [==============================] - 34s 12s/step - loss: 5519.6309 - mae: 5519.6309 - mse: 90845000.0000 - val_loss: 33023.1055 - val_mae: 33023.1055 - val_mse: 1331571200.0000 - lr: 0.0100\n",
            "Epoch 6/5000\n",
            "3/3 [==============================] - 27s 9s/step - loss: 5541.7593 - mae: 5541.7593 - mse: 91112264.0000 - val_loss: 33059.7695 - val_mae: 33059.7695 - val_mse: 1333446784.0000 - lr: 0.0100\n",
            "Epoch 7/5000\n",
            "3/3 [==============================] - 26s 8s/step - loss: 5540.2158 - mae: 5540.2158 - mse: 91362600.0000 - val_loss: 33141.6211 - val_mae: 33141.6211 - val_mse: 1337651072.0000 - lr: 0.0100\n",
            "Epoch 8/5000\n",
            "3/3 [==============================] - 27s 8s/step - loss: 5524.4517 - mae: 5524.4517 - mse: 91522912.0000 - val_loss: 33230.9688 - val_mae: 33230.9688 - val_mse: 1342259584.0000 - lr: 0.0100\n",
            "Epoch 9/5000\n",
            "3/3 [==============================] - 25s 8s/step - loss: 5505.2661 - mae: 5505.2661 - mse: 91639760.0000 - val_loss: 33310.8359 - val_mae: 33310.8359 - val_mse: 1346398336.0000 - lr: 0.0100\n",
            "Epoch 10/5000\n",
            "3/3 [==============================] - 24s 8s/step - loss: 5471.6074 - mae: 5471.6074 - mse: 91141552.0000 - val_loss: 33227.0117 - val_mae: 33227.0117 - val_mse: 1342054400.0000 - lr: 0.0100\n",
            "Epoch 11/5000\n",
            "3/3 [==============================] - 26s 8s/step - loss: 5514.4985 - mae: 5514.4985 - mse: 91802200.0000 - val_loss: 33296.9258 - val_mae: 33296.9258 - val_mse: 1345674624.0000 - lr: 0.0100\n",
            "Epoch 12/5000\n",
            "3/3 [==============================] - 31s 10s/step - loss: 5497.6758 - mae: 5497.6758 - mse: 91871176.0000 - val_loss: 33361.3242 - val_mae: 33361.3242 - val_mse: 1349021056.0000 - lr: 0.0100\n",
            "Epoch 13/5000\n",
            "3/3 [==============================] - 29s 9s/step - loss: 5483.3184 - mae: 5483.3184 - mse: 91965784.0000 - val_loss: 33416.1953 - val_mae: 33416.1953 - val_mse: 1351881216.0000 - lr: 0.0100\n",
            "Epoch 14/5000\n",
            "3/3 [==============================] - 30s 9s/step - loss: 5471.1494 - mae: 5471.1494 - mse: 92056704.0000 - val_loss: 33461.3750 - val_mae: 33461.3750 - val_mse: 1354241920.0000 - lr: 0.0100\n",
            "Epoch 15/5000\n",
            "3/3 [==============================] - 30s 9s/step - loss: 5461.1807 - mae: 5461.1807 - mse: 92136440.0000 - val_loss: 33496.2852 - val_mae: 33496.2852 - val_mse: 1356069376.0000 - lr: 0.0100\n",
            "Epoch 16/5000\n",
            "3/3 [==============================] - 30s 9s/step - loss: 5453.1909 - mae: 5453.1909 - mse: 92194568.0000 - val_loss: 33522.1133 - val_mae: 33522.1133 - val_mse: 1357422208.0000 - lr: 0.0100\n",
            "Epoch 17/5000\n",
            "3/3 [==============================] - 29s 9s/step - loss: 5447.1421 - mae: 5447.1421 - mse: 92237792.0000 - val_loss: 33540.7500 - val_mae: 33540.7500 - val_mse: 1358398976.0000 - lr: 0.0100\n",
            "Epoch 18/5000\n",
            "3/3 [==============================] - 29s 9s/step - loss: 5442.5850 - mae: 5442.5850 - mse: 92263752.0000 - val_loss: 33552.9844 - val_mae: 33552.9844 - val_mse: 1359040128.0000 - lr: 0.0100\n",
            "Epoch 19/5000\n",
            "3/3 [==============================] - 29s 9s/step - loss: 5439.1694 - mae: 5439.1694 - mse: 92273000.0000 - val_loss: 33560.1172 - val_mae: 33560.1172 - val_mse: 1359414016.0000 - lr: 0.0100\n",
            "Epoch 20/5000\n",
            "3/3 [==============================] - 30s 10s/step - loss: 5436.9429 - mae: 5436.9429 - mse: 92272032.0000 - val_loss: 33563.1406 - val_mae: 33563.1406 - val_mse: 1359570304.0000 - lr: 0.0100\n",
            "Epoch 21/5000\n",
            "3/3 [==============================] - 32s 10s/step - loss: 5435.3955 - mae: 5435.3955 - mse: 92257528.0000 - val_loss: 33562.7578 - val_mae: 33562.7578 - val_mse: 1359547520.0000 - lr: 0.0100\n",
            "Epoch 22/5000\n",
            "3/3 [==============================] - 29s 9s/step - loss: 5434.6069 - mae: 5434.6069 - mse: 92237000.0000 - val_loss: 33560.3438 - val_mae: 33560.3438 - val_mse: 1359416960.0000 - lr: 0.0100\n",
            "Epoch 23/5000\n",
            "3/3 [==============================] - 29s 9s/step - loss: 5434.3755 - mae: 5434.3755 - mse: 92215040.0000 - val_loss: 33556.8789 - val_mae: 33556.8789 - val_mse: 1359232000.0000 - lr: 0.0100\n",
            "Epoch 24/5000\n",
            "3/3 [==============================] - 29s 9s/step - loss: 5434.4556 - mae: 5434.4556 - mse: 92192840.0000 - val_loss: 33552.8945 - val_mae: 33552.8945 - val_mse: 1359018112.0000 - lr: 0.0100\n",
            "Epoch 25/5000\n",
            "3/3 [==============================] - 29s 9s/step - loss: 5434.6924 - mae: 5434.6929 - mse: 92170656.0000 - val_loss: 33548.5156 - val_mae: 33548.5156 - val_mse: 1358784512.0000 - lr: 0.0100\n",
            "Epoch 26/5000\n",
            "3/3 [==============================] - 31s 10s/step - loss: 5435.0542 - mae: 5435.0542 - mse: 92149592.0000 - val_loss: 33544.4922 - val_mae: 33544.4922 - val_mse: 1358568448.0000 - lr: 0.0100\n",
            "Epoch 27/5000\n",
            "3/3 [==============================] - 32s 10s/step - loss: 5435.4746 - mae: 5435.4741 - mse: 92132320.0000 - val_loss: 33541.0391 - val_mae: 33541.0391 - val_mse: 1358382208.0000 - lr: 0.0100\n",
            "Epoch 28/5000\n",
            "3/3 [==============================] - 29s 9s/step - loss: 5435.8359 - mae: 5435.8359 - mse: 92118016.0000 - val_loss: 33538.0742 - val_mae: 33538.0742 - val_mse: 1358222208.0000 - lr: 0.0100\n",
            "Epoch 29/5000\n",
            "3/3 [==============================] - 29s 9s/step - loss: 5436.1328 - mae: 5436.1328 - mse: 92105800.0000 - val_loss: 33535.7930 - val_mae: 33535.7930 - val_mse: 1358096640.0000 - lr: 0.0100\n",
            "Epoch 30/5000\n",
            "3/3 [==============================] - 29s 9s/step - loss: 5436.3691 - mae: 5436.3691 - mse: 92097336.0000 - val_loss: 33534.2734 - val_mae: 33534.2734 - val_mse: 1358012544.0000 - lr: 0.0100\n",
            "Epoch 31/5000\n",
            "3/3 [==============================] - 30s 9s/step - loss: 5436.5273 - mae: 5436.5273 - mse: 92092160.0000 - val_loss: 33533.3828 - val_mae: 33533.3828 - val_mse: 1357960192.0000 - lr: 0.0100\n",
            "Epoch 32/5000\n",
            "3/3 [==============================] - 29s 9s/step - loss: 5436.5132 - mae: 5436.5132 - mse: 92087992.0000 - val_loss: 33532.9141 - val_mae: 33532.9141 - val_mse: 1357930112.0000 - lr: 0.0100\n",
            "Epoch 33/5000\n",
            "3/3 [==============================] - 28s 9s/step - loss: 5436.3838 - mae: 5436.3838 - mse: 92084320.0000 - val_loss: 33532.7031 - val_mae: 33532.7031 - val_mse: 1357913856.0000 - lr: 0.0100\n",
            "Epoch 34/5000\n",
            "3/3 [==============================] - 28s 9s/step - loss: 5436.1982 - mae: 5436.1982 - mse: 92080752.0000 - val_loss: 33532.6875 - val_mae: 33532.6875 - val_mse: 1357907456.0000 - lr: 0.0100\n",
            "Epoch 35/5000\n",
            "3/3 [==============================] - 28s 9s/step - loss: 5435.9629 - mae: 5435.9629 - mse: 92077896.0000 - val_loss: 33532.8320 - val_mae: 33532.8320 - val_mse: 1357909632.0000 - lr: 0.0100\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 36/5000\n",
            "3/3 [==============================] - 27s 9s/step - loss: 5435.7144 - mae: 5435.7144 - mse: 92075776.0000 - val_loss: 33533.1055 - val_mae: 33533.1055 - val_mse: 1357917952.0000 - lr: 0.0100\n",
            "Epoch 37/5000\n",
            "3/3 [==============================] - 28s 9s/step - loss: 5435.4258 - mae: 5435.4258 - mse: 92073800.0000 - val_loss: 33533.4844 - val_mae: 33533.4844 - val_mse: 1357931264.0000 - lr: 0.0100\n",
            "Epoch 38/5000\n",
            "3/3 [==============================] - 27s 9s/step - loss: 5435.1138 - mae: 5435.1138 - mse: 92072168.0000 - val_loss: 33533.9141 - val_mae: 33533.9141 - val_mse: 1357946880.0000 - lr: 0.0100\n",
            "Epoch 39/5000\n",
            "3/3 [==============================] - 27s 9s/step - loss: 5434.7637 - mae: 5434.7637 - mse: 92070360.0000 - val_loss: 33534.3477 - val_mae: 33534.3477 - val_mse: 1357962624.0000 - lr: 0.0100\n",
            "Epoch 40/5000\n",
            "3/3 [==============================] - 28s 9s/step - loss: 5434.4365 - mae: 5434.4365 - mse: 92069136.0000 - val_loss: 33534.8242 - val_mae: 33534.8242 - val_mse: 1357980032.0000 - lr: 0.0100\n",
            "Epoch 41/5000\n",
            "3/3 [==============================] - 28s 9s/step - loss: 5434.0801 - mae: 5434.0801 - mse: 92067912.0000 - val_loss: 33535.3945 - val_mae: 33535.3945 - val_mse: 1358001920.0000 - lr: 0.0100\n",
            "Epoch 42/5000\n",
            "3/3 [==============================] - 28s 9s/step - loss: 5433.7202 - mae: 5433.7202 - mse: 92067328.0000 - val_loss: 33536.1094 - val_mae: 33536.1094 - val_mse: 1358030464.0000 - lr: 0.0100\n",
            "Epoch 43/5000\n",
            "3/3 [==============================] - 28s 9s/step - loss: 5433.3037 - mae: 5433.3037 - mse: 92066760.0000 - val_loss: 33536.8516 - val_mae: 33536.8516 - val_mse: 1358060544.0000 - lr: 0.0100\n",
            "Epoch 44/5000\n",
            "3/3 [==============================] - 27s 9s/step - loss: 5432.9082 - mae: 5432.9082 - mse: 92066760.0000 - val_loss: 33537.6562 - val_mae: 33537.6562 - val_mse: 1358093440.0000 - lr: 0.0100\n",
            "Epoch 45/5000\n",
            "3/3 [==============================] - 27s 9s/step - loss: 5432.4727 - mae: 5432.4727 - mse: 92066912.0000 - val_loss: 33538.5039 - val_mae: 33538.5039 - val_mse: 1358127360.0000 - lr: 0.0100\n",
            "Epoch 46/5000\n",
            "3/3 [==============================] - 28s 9s/step - loss: 5431.9961 - mae: 5431.9961 - mse: 92066528.0000 - val_loss: 33539.3750 - val_mae: 33539.3750 - val_mse: 1358161920.0000 - lr: 0.0100\n",
            "Epoch 47/5000\n",
            "3/3 [==============================] - 27s 9s/step - loss: 5431.4868 - mae: 5431.4868 - mse: 92066104.0000 - val_loss: 33540.2070 - val_mae: 33540.2070 - val_mse: 1358193408.0000 - lr: 0.0100\n",
            "Epoch 48/5000\n",
            "3/3 [==============================] - 28s 9s/step - loss: 5430.9438 - mae: 5430.9438 - mse: 92064880.0000 - val_loss: 33540.9766 - val_mae: 33540.9766 - val_mse: 1358221440.0000 - lr: 0.0100\n",
            "Epoch 49/5000\n",
            "3/3 [==============================] - 27s 8s/step - loss: 5430.3955 - mae: 5430.3955 - mse: 92063616.0000 - val_loss: 33541.6680 - val_mae: 33541.6680 - val_mse: 1358244352.0000 - lr: 0.0100\n",
            "Epoch 50/5000\n",
            "3/3 [==============================] - 28s 9s/step - loss: 5429.8647 - mae: 5429.8647 - mse: 92062344.0000 - val_loss: 33542.3555 - val_mae: 33542.3555 - val_mse: 1358266112.0000 - lr: 0.0100\n",
            "Epoch 51/5000\n",
            "3/3 [==============================] - 28s 9s/step - loss: 5429.2866 - mae: 5429.2866 - mse: 92060504.0000 - val_loss: 33542.9453 - val_mae: 33542.9453 - val_mse: 1358281344.0000 - lr: 0.0100\n",
            "Epoch 52/5000\n",
            "3/3 [==============================] - 29s 9s/step - loss: 5428.7183 - mae: 5428.7183 - mse: 92058664.0000 - val_loss: 33543.5078 - val_mae: 33543.5078 - val_mse: 1358293632.0000 - lr: 0.0100\n",
            "Epoch 53/5000\n",
            "3/3 [==============================] - 28s 9s/step - loss: 5428.0938 - mae: 5428.0938 - mse: 92055672.0000 - val_loss: 33543.9414 - val_mae: 33543.9414 - val_mse: 1358297984.0000 - lr: 0.0100\n",
            "Epoch 54/5000\n",
            "3/3 [==============================] - 29s 9s/step - loss: 5427.4585 - mae: 5427.4585 - mse: 92052240.0000 - val_loss: 33544.2656 - val_mae: 33544.2656 - val_mse: 1358296448.0000 - lr: 0.0100\n",
            "Epoch 55/5000\n",
            "3/3 [==============================] - 27s 9s/step - loss: 5426.8218 - mae: 5426.8218 - mse: 92048416.0000 - val_loss: 33544.4883 - val_mae: 33544.4883 - val_mse: 1358287104.0000 - lr: 0.0100\n",
            "Epoch 56/5000\n",
            "3/3 [==============================] - 27s 9s/step - loss: 5426.1255 - mae: 5426.1255 - mse: 92043008.0000 - val_loss: 33544.5312 - val_mae: 33544.5312 - val_mse: 1358267264.0000 - lr: 0.0100\n",
            "Epoch 57/5000\n",
            "3/3 [==============================] - 27s 9s/step - loss: 5425.4370 - mae: 5425.4370 - mse: 92037384.0000 - val_loss: 33544.4648 - val_mae: 33544.4648 - val_mse: 1358238848.0000 - lr: 0.0100\n",
            "Epoch 58/5000\n",
            "3/3 [==============================] - 28s 9s/step - loss: 5424.7085 - mae: 5424.7085 - mse: 92030992.0000 - val_loss: 33544.2383 - val_mae: 33544.2383 - val_mse: 1358200576.0000 - lr: 0.0100\n",
            "Epoch 59/5000\n",
            "3/3 [==============================] - 27s 9s/step - loss: 5423.9287 - mae: 5423.9287 - mse: 92023240.0000 - val_loss: 33543.8359 - val_mae: 33543.8359 - val_mse: 1358151296.0000 - lr: 0.0100\n",
            "Epoch 60/5000\n",
            "3/3 [==============================] - 27s 9s/step - loss: 5423.1353 - mae: 5423.1353 - mse: 92014496.0000 - val_loss: 33543.1758 - val_mae: 33543.1758 - val_mse: 1358086016.0000 - lr: 0.0100\n",
            "Epoch 61/5000\n",
            "3/3 [==============================] - 27s 9s/step - loss: 5422.3125 - mae: 5422.3125 - mse: 92004624.0000 - val_loss: 33542.3594 - val_mae: 33542.3594 - val_mse: 1358009472.0000 - lr: 0.0100\n",
            "Epoch 62/5000\n",
            "3/3 [==============================] - 28s 9s/step - loss: 5421.4575 - mae: 5421.4575 - mse: 91994080.0000 - val_loss: 33541.3945 - val_mae: 33541.3945 - val_mse: 1357921152.0000 - lr: 0.0100\n",
            "Epoch 63/5000\n",
            "3/3 [==============================] - 27s 8s/step - loss: 5420.5063 - mae: 5420.5063 - mse: 91981776.0000 - val_loss: 33540.0859 - val_mae: 33540.0859 - val_mse: 1357812224.0000 - lr: 0.0100\n",
            "Epoch 64/5000\n",
            "3/3 [==============================] - 29s 9s/step - loss: 5419.4575 - mae: 5419.4580 - mse: 91966792.0000 - val_loss: 33538.6719 - val_mae: 33538.6719 - val_mse: 1357693184.0000 - lr: 0.0100\n",
            "Epoch 65/5000\n",
            "3/3 [==============================] - 28s 9s/step - loss: 5418.6528 - mae: 5418.6528 - mse: 91951640.0000 - val_loss: 33536.1992 - val_mae: 33536.1992 - val_mse: 1357518080.0000 - lr: 0.0100\n",
            "Epoch 66/5000\n",
            "3/3 [==============================] - 28s 9s/step - loss: 5417.1069 - mae: 5417.1069 - mse: 91923280.0000 - val_loss: 33533.0469 - val_mae: 33533.0469 - val_mse: 1357303168.0000 - lr: 0.0100\n",
            "Epoch 67/5000\n",
            "3/3 [==============================] - 28s 9s/step - loss: 5416.1846 - mae: 5416.1846 - mse: 91902248.0000 - val_loss: 33529.8438 - val_mae: 33529.8438 - val_mse: 1357075456.0000 - lr: 0.0100\n",
            "Epoch 68/5000\n",
            "3/3 [==============================] - 28s 9s/step - loss: 5414.9609 - mae: 5414.9609 - mse: 91877912.0000 - val_loss: 33526.4023 - val_mae: 33526.4023 - val_mse: 1356824960.0000 - lr: 0.0100\n",
            "Epoch 69/5000\n",
            "3/3 [==============================] - 28s 9s/step - loss: 5413.4854 - mae: 5413.4854 - mse: 91850760.0000 - val_loss: 33522.6641 - val_mae: 33522.6641 - val_mse: 1356548992.0000 - lr: 0.0100\n",
            "Epoch 70/5000\n",
            "3/3 [==============================] - 27s 9s/step - loss: 5411.7896 - mae: 5411.7896 - mse: 91821120.0000 - val_loss: 33518.5508 - val_mae: 33518.5508 - val_mse: 1356241408.0000 - lr: 0.0100\n",
            "Epoch 71/5000\n",
            "3/3 [==============================] - 27s 9s/step - loss: 5409.8584 - mae: 5409.8584 - mse: 91789160.0000 - val_loss: 33514.1211 - val_mae: 33514.1211 - val_mse: 1355901440.0000 - lr: 0.0100\n",
            "Epoch 72/5000\n",
            "3/3 [==============================] - 28s 9s/step - loss: 5407.6367 - mae: 5407.6367 - mse: 91754736.0000 - val_loss: 33509.2734 - val_mae: 33509.2734 - val_mse: 1355522304.0000 - lr: 0.0100\n",
            "Epoch 73/5000\n",
            "3/3 [==============================] - 27s 9s/step - loss: 5405.1250 - mae: 5405.1250 - mse: 91719024.0000 - val_loss: 33504.2070 - val_mae: 33504.2070 - val_mse: 1355109120.0000 - lr: 0.0100\n",
            "Epoch 74/5000\n",
            "3/3 [==============================] - 31s 11s/step - loss: 5402.3706 - mae: 5402.3706 - mse: 91685736.0000 - val_loss: 33498.3008 - val_mae: 33498.3008 - val_mse: 1354635392.0000 - lr: 0.0100\n",
            "Epoch 75/5000\n",
            "3/3 [==============================] - 30s 10s/step - loss: 5398.8809 - mae: 5398.8809 - mse: 91633568.0000 - val_loss: 33490.4961 - val_mae: 33490.4961 - val_mse: 1354059264.0000 - lr: 0.0100\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 76/5000\n",
            "3/3 [==============================] - 29s 9s/step - loss: 5395.3394 - mae: 5395.3394 - mse: 91567552.0000 - val_loss: 33481.1406 - val_mae: 33481.1406 - val_mse: 1353394304.0000 - lr: 0.0100\n",
            "Epoch 77/5000\n",
            "3/3 [==============================] - 28s 9s/step - loss: 5392.1748 - mae: 5392.1748 - mse: 91504600.0000 - val_loss: 33470.8359 - val_mae: 33470.8359 - val_mse: 1352657536.0000 - lr: 0.0100\n",
            "Epoch 78/5000\n",
            "3/3 [==============================] - 27s 9s/step - loss: 5388.6797 - mae: 5388.6797 - mse: 91434768.0000 - val_loss: 33458.9883 - val_mae: 33458.9883 - val_mse: 1351828480.0000 - lr: 0.0100\n",
            "Epoch 79/5000\n",
            "3/3 [==============================] - 28s 9s/step - loss: 5384.7114 - mae: 5384.7119 - mse: 91346600.0000 - val_loss: 33443.8477 - val_mae: 33443.8477 - val_mse: 1350825600.0000 - lr: 0.0100\n",
            "Epoch 80/5000\n",
            "3/3 [==============================] - 28s 9s/step - loss: 5380.5312 - mae: 5380.5312 - mse: 91233688.0000 - val_loss: 33424.8711 - val_mae: 33424.8711 - val_mse: 1349622912.0000 - lr: 0.0100\n",
            "Epoch 81/5000\n",
            "3/3 [==============================] - 27s 9s/step - loss: 5376.5669 - mae: 5376.5669 - mse: 91105344.0000 - val_loss: 33402.9102 - val_mae: 33402.9102 - val_mse: 1348259072.0000 - lr: 0.0100\n",
            "Epoch 82/5000\n",
            "3/3 [==============================] - 27s 9s/step - loss: 5372.7202 - mae: 5372.7202 - mse: 90969320.0000 - val_loss: 33378.8789 - val_mae: 33378.8789 - val_mse: 1346768128.0000 - lr: 0.0100\n",
            "Epoch 83/5000\n",
            "3/3 [==============================] - 28s 9s/step - loss: 5368.7500 - mae: 5368.7500 - mse: 90832520.0000 - val_loss: 33354.0820 - val_mae: 33354.0820 - val_mse: 1345196544.0000 - lr: 0.0100\n",
            "Epoch 84/5000\n",
            "3/3 [==============================] - 28s 9s/step - loss: 5363.8579 - mae: 5363.8579 - mse: 90685048.0000 - val_loss: 33326.1406 - val_mae: 33326.1406 - val_mse: 1343419136.0000 - lr: 0.0100\n",
            "Epoch 85/5000\n",
            "3/3 [==============================] - 28s 9s/step - loss: 5357.8789 - mae: 5357.8789 - mse: 90505504.0000 - val_loss: 33292.8047 - val_mae: 33292.8047 - val_mse: 1341327360.0000 - lr: 0.0100\n",
            "Epoch 86/5000\n",
            "3/3 [==============================] - 28s 9s/step - loss: 5352.5024 - mae: 5352.5020 - mse: 90327704.0000 - val_loss: 33258.9219 - val_mae: 33258.9219 - val_mse: 1339153792.0000 - lr: 0.0100\n",
            "Epoch 87/5000\n",
            "3/3 [==============================] - 28s 9s/step - loss: 5346.7734 - mae: 5346.7734 - mse: 90163128.0000 - val_loss: 33226.0195 - val_mae: 33226.0195 - val_mse: 1336964224.0000 - lr: 0.0100\n",
            "Epoch 88/5000\n",
            "3/3 [==============================] - 28s 9s/step - loss: 5339.8198 - mae: 5339.8198 - mse: 90019424.0000 - val_loss: 33199.3398 - val_mae: 33199.3398 - val_mse: 1335023488.0000 - lr: 0.0100\n",
            "Epoch 89/5000\n",
            "3/3 [==============================] - 28s 9s/step - loss: 5328.9746 - mae: 5328.9746 - mse: 89851496.0000 - val_loss: 33167.8789 - val_mae: 33167.8789 - val_mse: 1332872704.0000 - lr: 0.0100\n",
            "Epoch 90/5000\n",
            "3/3 [==============================] - 28s 9s/step - loss: 5313.0073 - mae: 5313.0073 - mse: 89494216.0000 - val_loss: 33106.3125 - val_mae: 33106.3125 - val_mse: 1329324160.0000 - lr: 0.0100\n",
            "Epoch 91/5000\n",
            "3/3 [==============================] - 29s 10s/step - loss: 5302.3989 - mae: 5302.3989 - mse: 89111728.0000 - val_loss: 33041.5508 - val_mae: 33041.5508 - val_mse: 1325552000.0000 - lr: 0.0100\n",
            "Epoch 92/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 5296.6265 - mae: 5296.6265 - mse: 88869384.0000 INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate\\assets\n",
            "3/3 [==============================] - 36s 13s/step - loss: 5296.6265 - mae: 5296.6265 - mse: 88869384.0000 - val_loss: 32990.9180 - val_mae: 32990.9180 - val_mse: 1322292864.0000 - lr: 0.0100\n",
            "Epoch 93/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 5283.8032 - mae: 5283.8032 - mse: 88616472.0000 INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate\\assets\n",
            "3/3 [==============================] - 40s 15s/step - loss: 5283.8032 - mae: 5283.8032 - mse: 88616472.0000 - val_loss: 32939.8477 - val_mae: 32939.8477 - val_mse: 1318918144.0000 - lr: 0.0100\n",
            "Epoch 94/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 5265.9839 - mae: 5265.9839 - mse: 88262024.0000 INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate\\assets\n",
            "3/3 [==============================] - 43s 15s/step - loss: 5265.9839 - mae: 5265.9839 - mse: 88262024.0000 - val_loss: 32874.0312 - val_mae: 32874.0312 - val_mse: 1314876800.0000 - lr: 0.0100\n",
            "Epoch 95/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 5247.9062 - mae: 5247.9062 - mse: 87795280.0000 INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate\\assets\n",
            "3/3 [==============================] - 42s 15s/step - loss: 5247.9062 - mae: 5247.9062 - mse: 87795280.0000 - val_loss: 32788.6289 - val_mae: 32788.6289 - val_mse: 1310001024.0000 - lr: 0.0100\n",
            "Epoch 96/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 5232.2310 - mae: 5232.2310 - mse: 87216552.0000 INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate\\assets\n",
            "3/3 [==============================] - 40s 14s/step - loss: 5232.2310 - mae: 5232.2310 - mse: 87216552.0000 - val_loss: 32680.7930 - val_mae: 32680.7930 - val_mse: 1304128128.0000 - lr: 0.0100\n",
            "Epoch 97/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 5218.5352 - mae: 5218.5352 - mse: 86544464.0000 INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate\\assets\n",
            "3/3 [==============================] - 43s 16s/step - loss: 5218.5352 - mae: 5218.5352 - mse: 86544464.0000 - val_loss: 32556.8691 - val_mae: 32556.8691 - val_mse: 1297461632.0000 - lr: 0.0100\n",
            "Epoch 98/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 5206.4111 - mae: 5206.4111 - mse: 85838680.0000 INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate\\assets\n",
            "3/3 [==============================] - 38s 14s/step - loss: 5206.4111 - mae: 5206.4111 - mse: 85838680.0000 - val_loss: 32423.0352 - val_mae: 32423.0352 - val_mse: 1290280448.0000 - lr: 0.0100\n",
            "Epoch 99/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 5194.0361 - mae: 5194.0361 - mse: 85074744.0000 INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate\\assets\n",
            "3/3 [==============================] - 38s 13s/step - loss: 5194.0361 - mae: 5194.0361 - mse: 85074744.0000 - val_loss: 32273.0176 - val_mae: 32273.0176 - val_mse: 1282380928.0000 - lr: 0.0100\n",
            "Epoch 100/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 5182.5522 - mae: 5182.5522 - mse: 84266152.0000 INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate\\assets\n",
            "3/3 [==============================] - 39s 14s/step - loss: 5182.5522 - mae: 5182.5522 - mse: 84266152.0000 - val_loss: 32108.1035 - val_mae: 32108.1035 - val_mse: 1273752960.0000 - lr: 0.0100\n",
            "Epoch 101/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 5175.0171 - mae: 5175.0171 - mse: 83534672.0000 INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate\\assets\n",
            "3/3 [==============================] - 38s 13s/step - loss: 5175.0171 - mae: 5175.0171 - mse: 83534672.0000 - val_loss: 31943.7910 - val_mae: 31943.7910 - val_mse: 1265020544.0000 - lr: 0.0100\n",
            "Epoch 102/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 5167.1909 - mae: 5167.1909 - mse: 82902960.0000 INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate\\assets\n",
            "3/3 [==============================] - 38s 13s/step - loss: 5167.1909 - mae: 5167.1909 - mse: 82902960.0000 - val_loss: 31784.8164 - val_mae: 31784.8164 - val_mse: 1256371584.0000 - lr: 0.0100\n",
            "Epoch 103/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 5156.8057 - mae: 5156.8057 - mse: 82384192.0000 INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate\\assets\n",
            "3/3 [==============================] - 39s 14s/step - loss: 5156.8057 - mae: 5156.8057 - mse: 82384192.0000 - val_loss: 31640.5742 - val_mae: 31640.5742 - val_mse: 1248160896.0000 - lr: 0.0100\n",
            "Epoch 104/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 5138.3823 - mae: 5138.3823 - mse: 81829664.0000 INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate\\assets\n",
            "3/3 [==============================] - 38s 13s/step - loss: 5138.3823 - mae: 5138.3823 - mse: 81829664.0000 - val_loss: 31481.4609 - val_mae: 31481.4609 - val_mse: 1239516160.0000 - lr: 0.0100\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 105/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 5098.2363 - mae: 5098.2368 - mse: 80379976.0000 INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate\\assets\n",
            "3/3 [==============================] - 39s 14s/step - loss: 5098.2363 - mae: 5098.2368 - mse: 80379976.0000 - val_loss: 31186.7773 - val_mae: 31186.7773 - val_mse: 1226470016.0000 - lr: 0.0100\n",
            "Epoch 106/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 5089.0010 - mae: 5089.0010 - mse: 79190624.0000 INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate\\assets\n",
            "3/3 [==============================] - 39s 14s/step - loss: 5089.0010 - mae: 5089.0010 - mse: 79190624.0000 - val_loss: 30945.9570 - val_mae: 30945.9570 - val_mse: 1215113472.0000 - lr: 0.0100\n",
            "Epoch 107/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 5116.5840 - mae: 5116.5840 - mse: 79229208.0000INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate\\assets\n",
            "3/3 [==============================] - 35s 12s/step - loss: 5116.5840 - mae: 5116.5840 - mse: 79229208.0000 - val_loss: 30821.6523 - val_mae: 30821.6523 - val_mse: 1207415808.0000 - lr: 0.0100\n",
            "Epoch 108/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 5094.0015 - mae: 5094.0015 - mse: 78182216.0000 INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate\\assets\n",
            "3/3 [==============================] - 40s 14s/step - loss: 5094.0015 - mae: 5094.0015 - mse: 78182216.0000 - val_loss: 30535.3105 - val_mae: 30535.3105 - val_mse: 1195134080.0000 - lr: 0.0100\n",
            "Epoch 109/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 5090.9531 - mae: 5090.9531 - mse: 77526016.0000 INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate\\assets\n",
            "3/3 [==============================] - 39s 14s/step - loss: 5090.9531 - mae: 5090.9531 - mse: 77526016.0000 - val_loss: 30377.1738 - val_mae: 30377.1738 - val_mse: 1186193920.0000 - lr: 0.0100\n",
            "Epoch 110/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 5119.2471 - mae: 5119.2471 - mse: 77736840.0000 INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate\\assets\n",
            "3/3 [==============================] - 41s 14s/step - loss: 5119.2471 - mae: 5119.2471 - mse: 77736840.0000 - val_loss: 30186.4863 - val_mae: 30186.4863 - val_mse: 1176247168.0000 - lr: 0.0100\n",
            "Epoch 111/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 5099.2666 - mae: 5099.2666 - mse: 76946296.0000 INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate\\assets\n",
            "3/3 [==============================] - 40s 14s/step - loss: 5099.2666 - mae: 5099.2666 - mse: 76946296.0000 - val_loss: 29988.0820 - val_mae: 29988.0820 - val_mse: 1166505984.0000 - lr: 0.0100\n",
            "Epoch 112/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 5130.8052 - mae: 5130.8052 - mse: 77283408.0000 INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate\\assets\n",
            "3/3 [==============================] - 40s 14s/step - loss: 5130.8052 - mae: 5130.8052 - mse: 77283408.0000 - val_loss: 29878.1777 - val_mae: 29878.1777 - val_mse: 1159234304.0000 - lr: 0.0100\n",
            "Epoch 113/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 5134.4531 - mae: 5134.4531 - mse: 77147000.0000 INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate\\assets\n",
            "3/3 [==============================] - 40s 14s/step - loss: 5134.4531 - mae: 5134.4531 - mse: 77147000.0000 - val_loss: 29720.6289 - val_mae: 29720.6289 - val_mse: 1151238144.0000 - lr: 0.0100\n",
            "Epoch 114/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 5138.4512 - mae: 5138.4512 - mse: 76904280.0000 INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate\\assets\n",
            "3/3 [==============================] - 40s 14s/step - loss: 5138.4512 - mae: 5138.4512 - mse: 76904280.0000 - val_loss: 29582.8711 - val_mae: 29582.8711 - val_mse: 1144129664.0000 - lr: 0.0100\n",
            "Epoch 115/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 5162.6841 - mae: 5162.6841 - mse: 77326328.0000 INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate\\assets\n",
            "3/3 [==============================] - 40s 14s/step - loss: 5162.6841 - mae: 5162.6841 - mse: 77326328.0000 - val_loss: 29547.2676 - val_mae: 29547.2676 - val_mse: 1140193792.0000 - lr: 0.0100\n",
            "Epoch 116/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 5166.5933 - mae: 5166.5933 - mse: 77595520.0000 INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate\\assets\n",
            "3/3 [==============================] - 38s 14s/step - loss: 5166.5933 - mae: 5166.5933 - mse: 77595520.0000 - val_loss: 29512.1055 - val_mae: 29512.1055 - val_mse: 1136873088.0000 - lr: 0.0100\n",
            "Epoch 117/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 5153.6353 - mae: 5153.6353 - mse: 77340112.0000 INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate\\assets\n",
            "3/3 [==============================] - 39s 14s/step - loss: 5153.6353 - mae: 5153.6353 - mse: 77340112.0000 - val_loss: 29423.2344 - val_mae: 29423.2344 - val_mse: 1132401536.0000 - lr: 0.0100\n",
            "Epoch 118/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 5156.2847 - mae: 5156.2847 - mse: 77220512.0000 INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate\\assets\n",
            "3/3 [==============================] - 40s 14s/step - loss: 5156.2847 - mae: 5156.2847 - mse: 77220512.0000 - val_loss: 29351.9785 - val_mae: 29351.9785 - val_mse: 1128645760.0000 - lr: 0.0100\n",
            "Epoch 119/5000\n",
            "3/3 [==============================] - 31s 10s/step - loss: 5172.8232 - mae: 5172.8232 - mse: 77594512.0000 - val_loss: 29358.1211 - val_mae: 29358.1211 - val_mse: 1127224576.0000 - lr: 0.0100\n",
            "Epoch 120/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 5171.3022 - mae: 5171.3022 - mse: 77760000.0000 INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate\\assets\n",
            "3/3 [==============================] - 42s 15s/step - loss: 5171.3022 - mae: 5171.3022 - mse: 77760000.0000 - val_loss: 29338.9199 - val_mae: 29338.9199 - val_mse: 1125388288.0000 - lr: 0.0100\n",
            "Epoch 121/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 5159.0010 - mae: 5159.0010 - mse: 77466112.0000 INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate\\assets\n",
            "3/3 [==============================] - 40s 14s/step - loss: 5159.0010 - mae: 5159.0010 - mse: 77466112.0000 - val_loss: 29276.0273 - val_mae: 29276.0273 - val_mse: 1122707968.0000 - lr: 0.0100\n",
            "Epoch 122/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 5165.8105 - mae: 5165.8105 - mse: 77486080.0000 INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate\\assets\n",
            "3/3 [==============================] - 40s 14s/step - loss: 5165.8105 - mae: 5165.8105 - mse: 77486080.0000 - val_loss: 29255.5410 - val_mae: 29255.5410 - val_mse: 1121326464.0000 - lr: 0.0100\n",
            "Epoch 123/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 5171.0239 - mae: 5171.0239 - mse: 77634824.0000 INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate\\assets\n",
            "3/3 [==============================] - 41s 14s/step - loss: 5171.0239 - mae: 5171.0239 - mse: 77634824.0000 - val_loss: 29253.2578 - val_mae: 29253.2578 - val_mse: 1120618496.0000 - lr: 0.0100\n",
            "Epoch 124/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 5165.0361 - mae: 5165.0356 - mse: 77534144.0000 INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate\\assets\n",
            "3/3 [==============================] - 40s 14s/step - loss: 5165.0361 - mae: 5165.0356 - mse: 77534144.0000 - val_loss: 29224.0938 - val_mae: 29224.0938 - val_mse: 1119324672.0000 - lr: 0.0100\n",
            "Epoch 125/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 5165.7505 - mae: 5165.7505 - mse: 77546128.0000 INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate\\assets\n",
            "3/3 [==============================] - 40s 14s/step - loss: 5165.7505 - mae: 5165.7505 - mse: 77546128.0000 - val_loss: 29220.2793 - val_mae: 29220.2793 - val_mse: 1118619008.0000 - lr: 0.0100\n",
            "Epoch 126/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 5166.2368 - mae: 5166.2368 - mse: 77631048.0000 INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate\\assets\n",
            "3/3 [==============================] - 41s 15s/step - loss: 5166.2368 - mae: 5166.2368 - mse: 77631048.0000 - val_loss: 29213.2773 - val_mae: 29213.2773 - val_mse: 1117955200.0000 - lr: 0.0100\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 127/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 5161.0630 - mae: 5161.0630 - mse: 77515000.0000 INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate\\assets\n",
            "3/3 [==============================] - 41s 15s/step - loss: 5161.0630 - mae: 5161.0630 - mse: 77515000.0000 - val_loss: 29186.5879 - val_mae: 29186.5879 - val_mse: 1116872320.0000 - lr: 0.0100\n",
            "Epoch 128/5000\n",
            "3/3 [==============================] - 32s 10s/step - loss: 5162.2632 - mae: 5162.2632 - mse: 77507816.0000 - val_loss: 29194.5176 - val_mae: 29194.5176 - val_mse: 1116863104.0000 - lr: 0.0100\n",
            "Epoch 129/5000\n",
            "3/3 [==============================] - 31s 10s/step - loss: 5164.6562 - mae: 5164.6562 - mse: 77676968.0000 - val_loss: 29207.5410 - val_mae: 29207.5410 - val_mse: 1117012736.0000 - lr: 0.0100\n",
            "Epoch 130/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 5154.0190 - mae: 5154.0190 - mse: 77465416.0000 INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate\\assets\n",
            "3/3 [==============================] - 39s 14s/step - loss: 5154.0190 - mae: 5154.0190 - mse: 77465416.0000 - val_loss: 29182.1328 - val_mae: 29182.1328 - val_mse: 1116377216.0000 - lr: 0.0100\n",
            "Epoch 131/5000\n",
            "3/3 [==============================] - 32s 10s/step - loss: 5155.6128 - mae: 5155.6128 - mse: 77414264.0000 - val_loss: 29184.5938 - val_mae: 29184.5938 - val_mse: 1116381184.0000 - lr: 0.0100\n",
            "Epoch 132/5000\n",
            "3/3 [==============================] - 31s 10s/step - loss: 5159.4785 - mae: 5159.4785 - mse: 77630576.0000 - val_loss: 29211.2988 - val_mae: 29211.2988 - val_mse: 1116863872.0000 - lr: 0.0100\n",
            "Epoch 133/5000\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16428\\4064045490.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m         ),\n\u001b[0;32m     11\u001b[0m         \u001b[0mearly_stopping\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mreduce_lr_plateau\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     ]\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1562\u001b[0m                         ):\n\u001b[0;32m   1563\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1564\u001b[1;33m                             \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1565\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1566\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2495\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2496\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2497\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2499\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1861\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1862\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1863\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1864\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 504\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    505\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 55\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "history_model_univariate = model_univariate.fit(\n",
        "    train_dataset,\n",
        "    epochs=5000,\n",
        "    validation_data=test_dataset,\n",
        "    callbacks=[\n",
        "        create_model_checkpoint(model_name=model_univariate.name),\n",
        "        create_tensorboard_callback(\n",
        "            dir_name='tensorboard_logs',\n",
        "            experiment_name=model_univariate.name\n",
        "        ),\n",
        "        early_stopping,\n",
        "        reduce_lr_plateau,\n",
        "        \n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "817eb5c0",
      "metadata": {},
      "source": [
        "No sign of improvement. Attempt a simple basic model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "43716841",
      "metadata": {},
      "outputs": [],
      "source": [
        "model_univariate_2 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(WINDOW_SIZE)),\n",
        "    tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=1)),\n",
        "    tf.keras.layers.RNN(LTSCell(16), time_major=True, return_sequences=True),\n",
        "    tf.keras.layers.LSTM(16, activation='relu'),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(HORIZON, activation='linear')\n",
        "], name='model_univariate_2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "90bb23a2",
      "metadata": {},
      "outputs": [],
      "source": [
        "model_univariate_2.compile(\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate = .01),\n",
        "    loss = tf.keras.losses.MAE,\n",
        "    metrics = ['mae', 'mse']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "66820280",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: tensorboard_logs/model_univariate_2/20230129-162946\n",
            "Epoch 1/5000\n",
            "1/3 [=========>....................] - ETA: 2s - loss: 423.5605 - mae: 423.5605 - mse: 206962.5625INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 4s 1s/step - loss: 4260.2227 - mae: 4260.2227 - mse: 54770080.0000 - val_loss: 17985.7402 - val_mae: 17985.7402 - val_mse: 376103776.0000 - lr: 0.0010\n",
            "Epoch 2/5000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 1195.2158 - mae: 1195.2158 - mse: 3512463.0000INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 1886.4775 - mae: 1886.4775 - mse: 10423141.0000 - val_loss: 4110.4941 - val_mae: 4110.4941 - val_mse: 22907902.0000 - lr: 0.0010\n",
            "Epoch 3/5000\n",
            "3/3 [==============================] - 0s 168ms/step - loss: 472.2631 - mae: 472.2631 - mse: 1197199.5000 - val_loss: 5189.1548 - val_mae: 5189.1548 - val_mse: 35542916.0000 - lr: 0.0010\n",
            "Epoch 4/5000\n",
            "3/3 [==============================] - 0s 143ms/step - loss: 913.8632 - mae: 913.8632 - mse: 3093886.7500 - val_loss: 5122.5601 - val_mae: 5122.5601 - val_mse: 34723392.0000 - lr: 0.0010\n",
            "Epoch 5/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 473.5496 - mae: 473.5496 - mse: 869483.3125INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 3s 1s/step - loss: 473.5496 - mae: 473.5496 - mse: 869483.3125 - val_loss: 1493.3358 - val_mae: 1493.3358 - val_mse: 4536822.0000 - lr: 0.0010\n",
            "Epoch 6/5000\n",
            "3/3 [==============================] - 0s 141ms/step - loss: 510.1746 - mae: 510.1746 - mse: 1498990.3750 - val_loss: 2934.4385 - val_mae: 2934.4385 - val_mse: 12752696.0000 - lr: 0.0010\n",
            "Epoch 7/5000\n",
            "3/3 [==============================] - 0s 135ms/step - loss: 554.5396 - mae: 554.5396 - mse: 1447472.3750 - val_loss: 1777.0989 - val_mae: 1777.0989 - val_mse: 5593928.5000 - lr: 0.0010\n",
            "Epoch 8/5000\n",
            "3/3 [==============================] - 0s 165ms/step - loss: 287.1004 - mae: 287.1004 - mse: 486667.9062 - val_loss: 2248.0759 - val_mae: 2248.0759 - val_mse: 8655545.0000 - lr: 0.0010\n",
            "Epoch 9/5000\n",
            "3/3 [==============================] - 0s 132ms/step - loss: 432.8961 - mae: 432.8961 - mse: 870593.9375 - val_loss: 2558.2769 - val_mae: 2558.2769 - val_mse: 10627984.0000 - lr: 0.0010\n",
            "Epoch 10/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 306.7448 - mae: 306.7448 - mse: 500860.1250INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 3s 1s/step - loss: 306.7448 - mae: 306.7448 - mse: 500860.1250 - val_loss: 1391.0946 - val_mae: 1391.0946 - val_mse: 3919360.5000 - lr: 0.0010\n",
            "Epoch 11/5000\n",
            "3/3 [==============================] - 1s 215ms/step - loss: 358.4265 - mae: 358.4265 - mse: 781313.8125 - val_loss: 1572.8805 - val_mae: 1572.8805 - val_mse: 4529990.5000 - lr: 0.0010\n",
            "Epoch 12/5000\n",
            "3/3 [==============================] - 0s 174ms/step - loss: 287.8113 - mae: 287.8113 - mse: 506143.0312 - val_loss: 1506.7014 - val_mae: 1506.7014 - val_mse: 4529115.5000 - lr: 0.0010\n",
            "Epoch 13/5000\n",
            "3/3 [==============================] - 1s 642ms/step - loss: 324.8630 - mae: 324.8630 - mse: 567802.1250 - val_loss: 2045.6034 - val_mae: 2045.6034 - val_mse: 7357319.0000 - lr: 0.0010\n",
            "Epoch 14/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 281.1255 - mae: 281.1255 - mse: 439433.8750INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 3s 1s/step - loss: 281.1255 - mae: 281.1255 - mse: 439433.8750 - val_loss: 1343.4286 - val_mae: 1343.4286 - val_mse: 3695489.2500 - lr: 0.0010\n",
            "Epoch 15/5000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 15.1822 - mae: 15.1822 - mse: 991.0377INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 284.9824 - mae: 284.9824 - mse: 516857.3750 - val_loss: 1288.3888 - val_mae: 1288.3888 - val_mse: 3331821.5000 - lr: 0.0010\n",
            "Epoch 16/5000\n",
            "3/3 [==============================] - 0s 204ms/step - loss: 246.4840 - mae: 246.4840 - mse: 382426.6562 - val_loss: 1460.0060 - val_mae: 1460.0060 - val_mse: 4215016.0000 - lr: 0.0010\n",
            "Epoch 17/5000\n",
            "3/3 [==============================] - 0s 85ms/step - loss: 262.3122 - mae: 262.3122 - mse: 397612.7188 - val_loss: 1373.8583 - val_mae: 1373.8583 - val_mse: 3772012.0000 - lr: 0.0010\n",
            "Epoch 18/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 249.9928 - mae: 249.9928 - mse: 408879.1562INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 249.9928 - mae: 249.9928 - mse: 408879.1562 - val_loss: 1220.1503 - val_mae: 1220.1503 - val_mse: 3013417.0000 - lr: 0.0010\n",
            "Epoch 19/5000\n",
            "3/3 [==============================] - 0s 90ms/step - loss: 231.6311 - mae: 231.6311 - mse: 348848.7812 - val_loss: 1275.2354 - val_mae: 1275.2354 - val_mse: 3301946.7500 - lr: 0.0010\n",
            "Epoch 20/5000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 14.8884 - mae: 14.8884 - mse: 839.4272INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 232.9307 - mae: 232.9307 - mse: 331183.7188 - val_loss: 1197.4358 - val_mae: 1197.4358 - val_mse: 2943512.0000 - lr: 0.0010\n",
            "Epoch 21/5000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 13.8206 - mae: 13.8206 - mse: 766.1170INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 225.6108 - mae: 225.6108 - mse: 345403.3125 - val_loss: 1143.0436 - val_mae: 1143.0436 - val_mse: 2708314.2500 - lr: 0.0010\n",
            "Epoch 22/5000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 13.0278 - mae: 13.0278 - mse: 710.8199INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 230.8966 - mae: 230.8966 - mse: 320121.1875 - val_loss: 1127.7815 - val_mae: 1127.7815 - val_mse: 2638837.2500 - lr: 0.0010\n",
            "Epoch 23/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 234.1068 - mae: 234.1068 - mse: 363645.7812INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 234.1068 - mae: 234.1068 - mse: 363645.7812 - val_loss: 1090.3932 - val_mae: 1090.3932 - val_mse: 2480191.2500 - lr: 0.0010\n",
            "Epoch 24/5000\n",
            "3/3 [==============================] - 0s 122ms/step - loss: 246.4622 - mae: 246.4622 - mse: 348845.5312 - val_loss: 1188.4779 - val_mae: 1188.4779 - val_mse: 2879907.2500 - lr: 0.0010\n",
            "Epoch 25/5000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 14.1839 - mae: 14.1839 - mse: 702.4341INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 224.6696 - mae: 224.6696 - mse: 340832.1875 - val_loss: 1062.8282 - val_mae: 1062.8282 - val_mse: 2341301.7500 - lr: 0.0010\n",
            "Epoch 26/5000\n",
            "3/3 [==============================] - 0s 139ms/step - loss: 212.6105 - mae: 212.6105 - mse: 288279.6875 - val_loss: 1099.0505 - val_mae: 1099.0505 - val_mse: 2524879.5000 - lr: 0.0010\n",
            "Epoch 27/5000\n",
            "3/3 [==============================] - 0s 129ms/step - loss: 205.7572 - mae: 205.7572 - mse: 293607.1562 - val_loss: 1064.0692 - val_mae: 1064.0692 - val_mse: 2387642.0000 - lr: 0.0010\n",
            "Epoch 28/5000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 11.9692 - mae: 11.9692 - mse: 611.9069INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 225.4238 - mae: 225.4238 - mse: 310828.8125 - val_loss: 1046.1915 - val_mae: 1046.1915 - val_mse: 2311268.7500 - lr: 0.0010\n",
            "Epoch 29/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 250.8868 - mae: 250.8868 - mse: 380953.5000INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 250.8868 - mae: 250.8868 - mse: 380953.5000 - val_loss: 1043.6566 - val_mae: 1043.6566 - val_mse: 2270176.7500 - lr: 0.0010\n",
            "Epoch 30/5000\n",
            "3/3 [==============================] - 0s 97ms/step - loss: 247.6501 - mae: 247.6501 - mse: 363676.7500 - val_loss: 1200.2582 - val_mae: 1200.2582 - val_mse: 2872216.5000 - lr: 0.0010\n",
            "Epoch 31/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 211.7737 - mae: 211.7737 - mse: 304646.5938INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 7s 3s/step - loss: 211.7737 - mae: 211.7737 - mse: 304646.5938 - val_loss: 1043.0841 - val_mae: 1043.0841 - val_mse: 2268682.0000 - lr: 0.0010\n",
            "Epoch 32/5000\n",
            "3/3 [==============================] - 0s 126ms/step - loss: 203.9622 - mae: 203.9622 - mse: 276122.2812 - val_loss: 1064.6886 - val_mae: 1064.6886 - val_mse: 2381216.0000 - lr: 0.0010\n",
            "Epoch 33/5000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 11.8747 - mae: 11.8747 - mse: 589.0494INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 3s 1s/step - loss: 199.1349 - mae: 199.1349 - mse: 276186.6562 - val_loss: 1034.9113 - val_mae: 1034.9113 - val_mse: 2273392.5000 - lr: 0.0010\n",
            "Epoch 34/5000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 11.4472 - mae: 11.4472 - mse: 569.2115INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 208.0225 - mae: 208.0225 - mse: 279349.5312 - val_loss: 1025.0726 - val_mae: 1025.0726 - val_mse: 2226942.0000 - lr: 0.0010\n",
            "Epoch 35/5000\n",
            "3/3 [==============================] - 0s 134ms/step - loss: 227.8385 - mae: 227.8385 - mse: 327368.8125 - val_loss: 1029.7771 - val_mae: 1029.7771 - val_mse: 2247960.2500 - lr: 0.0010\n",
            "Epoch 36/5000\n",
            "3/3 [==============================] - 0s 101ms/step - loss: 250.1104 - mae: 250.1104 - mse: 363793.2812 - val_loss: 1136.2485 - val_mae: 1136.2485 - val_mse: 2624966.0000 - lr: 0.0010\n",
            "Epoch 37/5000\n",
            "3/3 [==============================] - 0s 115ms/step - loss: 221.6693 - mae: 221.6693 - mse: 322397.7188 - val_loss: 1030.6766 - val_mae: 1030.6766 - val_mse: 2208787.2500 - lr: 0.0010\n",
            "Epoch 38/5000\n",
            "3/3 [==============================] - 0s 108ms/step - loss: 205.9937 - mae: 205.9937 - mse: 278168.9062 - val_loss: 1064.1606 - val_mae: 1064.1606 - val_mse: 2381807.2500 - lr: 0.0010\n",
            "Epoch 39/5000\n",
            "3/3 [==============================] - 1s 219ms/step - loss: 199.7125 - mae: 199.7125 - mse: 278260.8750 - val_loss: 1029.8228 - val_mae: 1029.8228 - val_mse: 2256981.2500 - lr: 0.0010\n",
            "Epoch 40/5000\n",
            "3/3 [==============================] - 1s 307ms/step - loss: 210.5433 - mae: 210.5433 - mse: 283059.9062 - val_loss: 1025.8352 - val_mae: 1025.8352 - val_mse: 2238908.7500 - lr: 0.0010\n",
            "Epoch 41/5000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 11.2569 - mae: 11.2569 - mse: 548.8260INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 228.1197 - mae: 228.1197 - mse: 329283.8750 - val_loss: 1019.8034 - val_mae: 1019.8034 - val_mse: 2210676.2500 - lr: 0.0010\n",
            "Epoch 42/5000\n",
            "3/3 [==============================] - 0s 93ms/step - loss: 237.3823 - mae: 237.3823 - mse: 336367.8750 - val_loss: 1118.3931 - val_mae: 1118.3931 - val_mse: 2567186.5000 - lr: 0.0010\n",
            "Epoch 43/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 214.3002 - mae: 214.3002 - mse: 307037.8750INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 214.3002 - mae: 214.3002 - mse: 307037.8750 - val_loss: 1018.1193 - val_mae: 1018.1193 - val_mse: 2188991.5000 - lr: 0.0010\n",
            "Epoch 44/5000\n",
            "3/3 [==============================] - 0s 138ms/step - loss: 208.6654 - mae: 208.6654 - mse: 281260.0938 - val_loss: 1045.2329 - val_mae: 1045.2329 - val_mse: 2316205.2500 - lr: 0.0010\n",
            "Epoch 45/5000\n",
            "3/3 [==============================] - 0s 156ms/step - loss: 208.3709 - mae: 208.3709 - mse: 293114.7812 - val_loss: 1021.0588 - val_mae: 1021.0588 - val_mse: 2225352.7500 - lr: 0.0010\n",
            "Epoch 46/5000\n",
            "3/3 [==============================] - 0s 112ms/step - loss: 222.2560 - mae: 222.2560 - mse: 303369.3125 - val_loss: 1052.4800 - val_mae: 1052.4800 - val_mse: 2342180.7500 - lr: 0.0010\n",
            "Epoch 47/5000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 11.6699 - mae: 11.6699 - mse: 551.5857INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 219.5688 - mae: 219.5688 - mse: 314739.3750 - val_loss: 1012.1833 - val_mae: 1012.1833 - val_mse: 2182771.7500 - lr: 0.0010\n",
            "Epoch 48/5000\n",
            "3/3 [==============================] - 0s 132ms/step - loss: 221.4254 - mae: 221.4254 - mse: 303146.6562 - val_loss: 1071.8744 - val_mae: 1071.8744 - val_mse: 2409877.0000 - lr: 0.0010\n",
            "Epoch 49/5000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 11.9738 - mae: 11.9738 - mse: 559.6141INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 3s 1s/step - loss: 210.7159 - mae: 210.7159 - mse: 298273.9375 - val_loss: 1011.3759 - val_mae: 1011.3759 - val_mse: 2182458.0000 - lr: 0.0010\n",
            "Epoch 50/5000\n",
            "3/3 [==============================] - 0s 121ms/step - loss: 211.6404 - mae: 211.6404 - mse: 284868.5625 - val_loss: 1037.6232 - val_mae: 1037.6232 - val_mse: 2292356.0000 - lr: 0.0010\n",
            "Epoch 51/5000\n",
            "3/3 [==============================] - 0s 102ms/step - loss: 213.7395 - mae: 213.7395 - mse: 302322.9375 - val_loss: 1016.2360 - val_mae: 1016.2360 - val_mse: 2210174.7500 - lr: 0.0010\n",
            "Epoch 52/5000\n",
            "3/3 [==============================] - 0s 208ms/step - loss: 228.8310 - mae: 228.8310 - mse: 316047.0000 - val_loss: 1074.6176 - val_mae: 1074.6176 - val_mse: 2418722.7500 - lr: 0.0010\n",
            "Epoch 53/5000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 11.9574 - mae: 11.9574 - mse: 555.8551INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 217.2240 - mae: 217.2240 - mse: 310900.6250 - val_loss: 1010.8958 - val_mae: 1010.8958 - val_mse: 2170632.7500 - lr: 0.0010\n",
            "Epoch 54/5000\n",
            "3/3 [==============================] - 0s 125ms/step - loss: 212.1812 - mae: 212.1812 - mse: 286633.5625 - val_loss: 1054.3268 - val_mae: 1054.3268 - val_mse: 2351353.2500 - lr: 0.0010\n",
            "Epoch 55/5000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 11.6058 - mae: 11.6058 - mse: 544.4120INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 206.4764 - mae: 206.4764 - mse: 289126.1250 - val_loss: 1010.5270 - val_mae: 1010.5270 - val_mse: 2186190.7500 - lr: 0.0010\n",
            "Epoch 56/5000\n",
            "3/3 [==============================] - 0s 103ms/step - loss: 211.2062 - mae: 211.2062 - mse: 283590.6562 - val_loss: 1033.7616 - val_mae: 1033.7616 - val_mse: 2279445.0000 - lr: 0.0010\n",
            "Epoch 57/5000\n",
            "3/3 [==============================] - 0s 112ms/step - loss: 213.4980 - mae: 213.4980 - mse: 301278.0000 - val_loss: 1011.0231 - val_mae: 1011.0231 - val_mse: 2189493.7500 - lr: 0.0010\n",
            "Epoch 58/5000\n",
            "3/3 [==============================] - 0s 164ms/step - loss: 224.8066 - mae: 224.8066 - mse: 308479.0625 - val_loss: 1067.9840 - val_mae: 1067.9840 - val_mse: 2393423.7500 - lr: 0.0010\n",
            "Epoch 59/5000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 11.8023 - mae: 11.8023 - mse: 544.8264INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 213.9018 - mae: 213.9018 - mse: 303572.9062 - val_loss: 1006.6482 - val_mae: 1006.6482 - val_mse: 2166709.2500 - lr: 0.0010\n",
            "Epoch 60/5000\n",
            "3/3 [==============================] - 0s 98ms/step - loss: 214.7952 - mae: 214.7952 - mse: 290647.8750 - val_loss: 1049.2645 - val_mae: 1049.2645 - val_mse: 2331219.0000 - lr: 0.0010\n",
            "Epoch 61/5000\n",
            "3/3 [==============================] - 0s 104ms/step - loss: 210.4475 - mae: 210.4475 - mse: 296082.3125 - val_loss: 1007.2587 - val_mae: 1007.2587 - val_mse: 2173434.2500 - lr: 0.0010\n",
            "Epoch 62/5000\n",
            "3/3 [==============================] - 0s 92ms/step - loss: 215.1942 - mae: 215.1942 - mse: 290977.6875 - val_loss: 1042.6907 - val_mae: 1042.6907 - val_mse: 2310387.7500 - lr: 0.0010\n",
            "Epoch 63/5000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 11.3674 - mae: 11.3674 - mse: 525.5549INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 213.3638 - mae: 213.3638 - mse: 301286.9062 - val_loss: 1006.1872 - val_mae: 1006.1872 - val_mse: 2170309.2500 - lr: 0.0010\n",
            "Epoch 64/5000\n",
            "3/3 [==============================] - 0s 108ms/step - loss: 218.1887 - mae: 218.1887 - mse: 296234.1562 - val_loss: 1055.7366 - val_mae: 1055.7366 - val_mse: 2353452.5000 - lr: 0.0010\n",
            "Epoch 65/5000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 11.5432 - mae: 11.5432 - mse: 526.3890INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 991ms/step - loss: 211.0762 - mae: 211.0762 - mse: 297553.4688 - val_loss: 1004.9836 - val_mae: 1004.9836 - val_mse: 2167344.5000 - lr: 0.0010\n",
            "Epoch 66/5000\n",
            "3/3 [==============================] - 0s 120ms/step - loss: 214.8364 - mae: 214.8364 - mse: 289769.8438 - val_loss: 1047.3846 - val_mae: 1047.3846 - val_mse: 2327007.0000 - lr: 0.0010\n",
            "Epoch 67/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 210.5955 - mae: 210.5955 - mse: 296355.1250INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 210.5955 - mae: 210.5955 - mse: 296355.1250 - val_loss: 1004.2266 - val_mae: 1004.2266 - val_mse: 2167533.0000 - lr: 0.0010\n",
            "Epoch 68/5000\n",
            "3/3 [==============================] - 0s 97ms/step - loss: 215.6070 - mae: 215.6070 - mse: 291039.4688 - val_loss: 1047.6715 - val_mae: 1047.6715 - val_mse: 2328288.5000 - lr: 0.0010\n",
            "Epoch 69/5000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 11.3767 - mae: 11.3767 - mse: 514.8567INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 210.9533 - mae: 210.9533 - mse: 297015.2500 - val_loss: 1003.3655 - val_mae: 1003.3655 - val_mse: 2165288.2500 - lr: 0.0010\n",
            "Epoch 70/5000\n",
            "3/3 [==============================] - 0s 90ms/step - loss: 216.4184 - mae: 216.4184 - mse: 292082.2812 - val_loss: 1047.0737 - val_mae: 1047.0737 - val_mse: 2326481.2500 - lr: 0.0010\n",
            "Epoch 71/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 211.9186 - mae: 211.9186 - mse: 298776.0312INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 211.9186 - mae: 211.9186 - mse: 298776.0312 - val_loss: 1002.2388 - val_mae: 1002.2388 - val_mse: 2159534.2500 - lr: 0.0010\n",
            "Epoch 72/5000\n",
            "3/3 [==============================] - 0s 104ms/step - loss: 214.9779 - mae: 214.9779 - mse: 289553.3750 - val_loss: 1049.7262 - val_mae: 1049.7262 - val_mse: 2335295.5000 - lr: 0.0010\n",
            "Epoch 73/5000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 11.3989 - mae: 11.3989 - mse: 512.5824INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 209.0403 - mae: 209.0403 - mse: 293392.0625 - val_loss: 1001.5802 - val_mae: 1001.5802 - val_mse: 2157836.7500 - lr: 0.0010\n",
            "Epoch 74/5000\n",
            "3/3 [==============================] - 1s 282ms/step - loss: 211.2138 - mae: 211.2138 - mse: 282667.9688 - val_loss: 1045.4515 - val_mae: 1045.4515 - val_mse: 2320938.0000 - lr: 0.0010\n",
            "Epoch 75/5000\n",
            "3/3 [==============================] - 0s 128ms/step - loss: 205.4007 - mae: 205.4007 - mse: 286145.8125 - val_loss: 1002.1425 - val_mae: 1002.1425 - val_mse: 2164875.5000 - lr: 0.0010\n",
            "Epoch 76/5000\n",
            "3/3 [==============================] - 0s 159ms/step - loss: 211.6817 - mae: 211.6817 - mse: 283000.2812 - val_loss: 1034.8832 - val_mae: 1034.8832 - val_mse: 2285762.0000 - lr: 0.0010\n",
            "Epoch 77/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 209.9329 - mae: 209.9329 - mse: 293921.1875INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 209.9329 - mae: 209.9329 - mse: 293921.1875 - val_loss: 1001.1264 - val_mae: 1001.1264 - val_mse: 2160504.5000 - lr: 0.0010\n",
            "Epoch 78/5000\n",
            "3/3 [==============================] - 0s 121ms/step - loss: 217.9234 - mae: 217.9235 - mse: 294350.9062 - val_loss: 1051.2036 - val_mae: 1051.2036 - val_mse: 2335726.7500 - lr: 0.0010\n",
            "Epoch 79/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 210.5457 - mae: 210.5457 - mse: 295434.6875INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 210.5457 - mae: 210.5457 - mse: 295434.6875 - val_loss: 998.9116 - val_mae: 998.9116 - val_mse: 2146424.0000 - lr: 0.0010\n",
            "Epoch 80/5000\n",
            "3/3 [==============================] - 0s 144ms/step - loss: 212.2738 - mae: 212.2738 - mse: 285019.2500 - val_loss: 1039.3646 - val_mae: 1039.3646 - val_mse: 2297207.0000 - lr: 0.0010\n",
            "Epoch 81/5000\n",
            "3/3 [==============================] - 0s 104ms/step - loss: 209.6908 - mae: 209.6908 - mse: 293221.9375 - val_loss: 999.9138 - val_mae: 999.9138 - val_mse: 2153124.7500 - lr: 0.0010\n",
            "Epoch 82/5000\n",
            "3/3 [==============================] - 0s 100ms/step - loss: 214.9795 - mae: 214.9795 - mse: 289135.2812 - val_loss: 1044.5978 - val_mae: 1044.5978 - val_mse: 2313705.0000 - lr: 0.0010\n",
            "Epoch 83/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 209.8522 - mae: 209.8522 - mse: 293802.5312INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 3s 1s/step - loss: 209.8522 - mae: 209.8522 - mse: 293802.5312 - val_loss: 997.9575 - val_mae: 997.9575 - val_mse: 2146103.5000 - lr: 0.0010\n",
            "Epoch 84/5000\n",
            "3/3 [==============================] - 0s 92ms/step - loss: 213.4469 - mae: 213.4469 - mse: 286360.2812 - val_loss: 1041.9159 - val_mae: 1041.9159 - val_mse: 2306356.2500 - lr: 0.0010\n",
            "Epoch 85/5000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 11.2315 - mae: 11.2315 - mse: 493.6959INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 208.8825 - mae: 208.8825 - mse: 291866.3125 - val_loss: 997.3480 - val_mae: 997.3480 - val_mse: 2148452.5000 - lr: 0.0010\n",
            "Epoch 86/5000\n",
            "3/3 [==============================] - 0s 165ms/step - loss: 214.1985 - mae: 214.1985 - mse: 287221.2500 - val_loss: 1041.1609 - val_mae: 1041.1609 - val_mse: 2304845.0000 - lr: 0.0010\n",
            "Epoch 87/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 209.7522 - mae: 209.7522 - mse: 293665.8750INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 209.7522 - mae: 209.7522 - mse: 293665.8750 - val_loss: 995.8185 - val_mae: 995.8185 - val_mse: 2141417.5000 - lr: 0.0010\n",
            "Epoch 88/5000\n",
            "3/3 [==============================] - 1s 341ms/step - loss: 212.8532 - mae: 212.8532 - mse: 285146.7188 - val_loss: 1042.4327 - val_mae: 1042.4327 - val_mse: 2308923.2500 - lr: 0.0010\n",
            "Epoch 89/5000\n",
            "3/3 [==============================] - 0s 154ms/step - loss: 207.6584 - mae: 207.6584 - mse: 289649.9062 - val_loss: 996.3843 - val_mae: 996.3843 - val_mse: 2146844.5000 - lr: 0.0010\n",
            "Epoch 90/5000\n",
            "3/3 [==============================] - 0s 110ms/step - loss: 213.4441 - mae: 213.4441 - mse: 285752.7188 - val_loss: 1038.7100 - val_mae: 1038.7100 - val_mse: 2298062.0000 - lr: 0.0010\n",
            "Epoch 91/5000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 11.1724 - mae: 11.1724 - mse: 491.9558INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 209.5153 - mae: 209.5153 - mse: 292894.0625 - val_loss: 994.7021 - val_mae: 994.7021 - val_mse: 2138575.5000 - lr: 0.0010\n",
            "Epoch 92/5000\n",
            "3/3 [==============================] - 0s 123ms/step - loss: 212.5621 - mae: 212.5621 - mse: 284521.9062 - val_loss: 1044.1481 - val_mae: 1044.1481 - val_mse: 2314992.0000 - lr: 0.0010\n",
            "Epoch 93/5000\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 205.7449 - mae: 205.7449 - mse: 286052.0000 - val_loss: 994.8441 - val_mae: 994.8441 - val_mse: 2142415.7500 - lr: 0.0010\n",
            "Epoch 94/5000\n",
            "3/3 [==============================] - 0s 191ms/step - loss: 210.6342 - mae: 210.6342 - mse: 280654.9688 - val_loss: 1044.0460 - val_mae: 1044.0460 - val_mse: 2314951.7500 - lr: 0.0010\n",
            "Epoch 95/5000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 11.2326 - mae: 11.2326 - mse: 493.5099INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 202.5807 - mae: 202.5807 - mse: 280123.6250 - val_loss: 994.6550 - val_mae: 994.6550 - val_mse: 2143431.2500 - lr: 0.0010\n",
            "Epoch 96/5000\n",
            "3/3 [==============================] - 0s 98ms/step - loss: 207.6011 - mae: 207.6011 - mse: 275003.2188 - val_loss: 1034.2567 - val_mae: 1034.2567 - val_mse: 2282465.5000 - lr: 0.0010\n",
            "Epoch 97/5000\n",
            "3/3 [==============================] - 0s 121ms/step - loss: 202.3168 - mae: 202.3168 - mse: 279350.7500 - val_loss: 997.8011 - val_mae: 997.8011 - val_mse: 2156234.2500 - lr: 0.0010\n",
            "Epoch 98/5000\n",
            "3/3 [==============================] - 0s 104ms/step - loss: 212.9756 - mae: 212.9756 - mse: 283876.3125 - val_loss: 1026.2679 - val_mae: 1026.2679 - val_mse: 2257027.0000 - lr: 0.0010\n",
            "Epoch 99/5000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 10.9491 - mae: 10.9491 - mse: 480.3234INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 213.2985 - mae: 213.2985 - mse: 299169.5625 - val_loss: 992.4239 - val_mae: 992.4239 - val_mse: 2130460.5000 - lr: 0.0010\n",
            "Epoch 100/5000\n",
            "3/3 [==============================] - 1s 254ms/step - loss: 215.5560 - mae: 215.5560 - mse: 289981.2500 - val_loss: 1057.8059 - val_mae: 1057.8059 - val_mse: 2358983.5000 - lr: 0.0010\n",
            "Epoch 101/5000\n",
            "3/3 [==============================] - 0s 119ms/step - loss: 203.6502 - mae: 203.6502 - mse: 282153.1562 - val_loss: 992.7548 - val_mae: 992.7548 - val_mse: 2133937.5000 - lr: 0.0010\n",
            "Epoch 102/5000\n",
            "3/3 [==============================] - 0s 93ms/step - loss: 205.0837 - mae: 205.0837 - mse: 271212.2500 - val_loss: 1034.3625 - val_mae: 1034.3625 - val_mse: 2285869.0000 - lr: 0.0010\n",
            "Epoch 103/5000\n",
            "3/3 [==============================] - 0s 109ms/step - loss: 198.8234 - mae: 198.8234 - mse: 272730.5625 - val_loss: 998.4922 - val_mae: 998.4922 - val_mse: 2163829.0000 - lr: 0.0010\n",
            "Epoch 104/5000\n",
            "3/3 [==============================] - 0s 121ms/step - loss: 210.4124 - mae: 210.4124 - mse: 279294.9688 - val_loss: 1026.1459 - val_mae: 1026.1459 - val_mse: 2257715.0000 - lr: 0.0010\n",
            "Epoch 105/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 208.3949 - mae: 208.3949 - mse: 289206.5000INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 208.3949 - mae: 208.3949 - mse: 289206.5000 - val_loss: 992.2615 - val_mae: 992.2615 - val_mse: 2135290.0000 - lr: 0.0010\n",
            "Epoch 106/5000\n",
            "3/3 [==============================] - 0s 94ms/step - loss: 215.5023 - mae: 215.5023 - mse: 289130.8750 - val_loss: 1047.2186 - val_mae: 1047.2186 - val_mse: 2318904.2500 - lr: 0.0010\n",
            "Epoch 107/5000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 11.2120 - mae: 11.2120 - mse: 475.9570INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 207.0473 - mae: 207.0473 - mse: 288037.4688 - val_loss: 990.8345 - val_mae: 990.8345 - val_mse: 2124560.0000 - lr: 0.0010\n",
            "Epoch 108/5000\n",
            "3/3 [==============================] - 0s 90ms/step - loss: 209.5533 - mae: 209.5533 - mse: 278819.2188 - val_loss: 1041.8469 - val_mae: 1041.8469 - val_mse: 2301393.0000 - lr: 0.0010\n",
            "Epoch 109/5000\n",
            "3/3 [==============================] - 0s 92ms/step - loss: 201.4512 - mae: 201.4512 - mse: 277518.0312 - val_loss: 992.8132 - val_mae: 992.8132 - val_mse: 2138950.7500 - lr: 0.0010\n",
            "Epoch 110/5000\n",
            "3/3 [==============================] - 0s 169ms/step - loss: 208.8807 - mae: 208.8807 - mse: 276835.0000 - val_loss: 1031.7906 - val_mae: 1031.7906 - val_mse: 2272940.2500 - lr: 0.0010\n",
            "Epoch 111/5000\n",
            "3/3 [==============================] - 0s 95ms/step - loss: 203.9167 - mae: 203.9167 - mse: 281421.9688 - val_loss: 991.1396 - val_mae: 991.1396 - val_mse: 2135267.0000 - lr: 0.0010\n",
            "Epoch 112/5000\n",
            "3/3 [==============================] - 0s 151ms/step - loss: 211.1241 - mae: 211.1241 - mse: 280898.7812 - val_loss: 1029.7041 - val_mae: 1029.7041 - val_mse: 2269862.2500 - lr: 0.0010\n",
            "Epoch 113/5000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 10.9192 - mae: 10.9192 - mse: 460.3031INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 207.6891 - mae: 207.6891 - mse: 288200.4062 - val_loss: 989.0579 - val_mae: 989.0579 - val_mse: 2126607.5000 - lr: 0.0010\n",
            "Epoch 114/5000\n",
            "3/3 [==============================] - 0s 178ms/step - loss: 212.5554 - mae: 212.5554 - mse: 283994.6250 - val_loss: 1037.8735 - val_mae: 1037.8735 - val_mse: 2296022.2500 - lr: 0.0010\n",
            "Epoch 115/5000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 11.0108 - mae: 11.0108 - mse: 460.3342INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 206.3095 - mae: 206.3095 - mse: 285951.2500 - val_loss: 988.7169 - val_mae: 988.7169 - val_mse: 2124775.5000 - lr: 0.0010\n",
            "Epoch 116/5000\n",
            "3/3 [==============================] - 0s 100ms/step - loss: 210.2844 - mae: 210.2844 - mse: 280019.8750 - val_loss: 1044.9646 - val_mae: 1044.9646 - val_mse: 2318182.0000 - lr: 0.0010\n",
            "Epoch 117/5000\n",
            "3/3 [==============================] - 0s 94ms/step - loss: 199.7500 - mae: 199.7500 - mse: 274306.0938 - val_loss: 989.0718 - val_mae: 989.0718 - val_mse: 2130611.5000 - lr: 0.0010\n",
            "Epoch 118/5000\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 205.0488 - mae: 205.0488 - mse: 269934.9375 - val_loss: 1027.0389 - val_mae: 1027.0389 - val_mse: 2259794.2500 - lr: 0.0010\n",
            "Epoch 119/5000\n",
            "3/3 [==============================] - 0s 91ms/step - loss: 200.0462 - mae: 200.0462 - mse: 274234.2812 - val_loss: 993.8600 - val_mae: 993.8600 - val_mse: 2148881.7500 - lr: 0.0010\n",
            "Epoch 120/5000\n",
            "3/3 [==============================] - 0s 121ms/step - loss: 213.0022 - mae: 213.0022 - mse: 283400.3750 - val_loss: 1027.9991 - val_mae: 1027.9991 - val_mse: 2261162.5000 - lr: 0.0010\n",
            "Epoch 121/5000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 10.8891 - mae: 10.8891 - mse: 460.6162INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 979ms/step - loss: 209.8222 - mae: 209.8222 - mse: 291408.1875 - val_loss: 987.2578 - val_mae: 987.2578 - val_mse: 2117111.7500 - lr: 0.0010\n",
            "Epoch 122/5000\n",
            "3/3 [==============================] - 0s 92ms/step - loss: 213.4623 - mae: 213.4623 - mse: 285660.4062 - val_loss: 1046.8849 - val_mae: 1046.8849 - val_mse: 2323221.0000 - lr: 0.0010\n",
            "Epoch 123/5000\n",
            "3/3 [==============================] - 0s 101ms/step - loss: 203.2808 - mae: 203.2808 - mse: 280237.2812 - val_loss: 987.5020 - val_mae: 987.5020 - val_mse: 2122514.5000 - lr: 0.0010\n",
            "Epoch 124/5000\n",
            "3/3 [==============================] - 0s 167ms/step - loss: 207.4968 - mae: 207.4968 - mse: 274586.5938 - val_loss: 1035.5278 - val_mae: 1035.5278 - val_mse: 2287532.2500 - lr: 0.0010\n",
            "Epoch 125/5000\n",
            "3/3 [==============================] - 0s 96ms/step - loss: 199.3446 - mae: 199.3446 - mse: 272811.9688 - val_loss: 988.7796 - val_mae: 988.7796 - val_mse: 2133202.7500 - lr: 0.0010\n",
            "Epoch 126/5000\n",
            "3/3 [==============================] - 0s 97ms/step - loss: 207.0898 - mae: 207.0898 - mse: 273152.0625 - val_loss: 1024.4888 - val_mae: 1024.4888 - val_mse: 2252508.5000 - lr: 0.0010\n",
            "Epoch 127/5000\n",
            "3/3 [==============================] - 0s 90ms/step - loss: 202.8261 - mae: 202.8261 - mse: 278426.8125 - val_loss: 989.8657 - val_mae: 989.8657 - val_mse: 2137247.7500 - lr: 0.0010\n",
            "Epoch 128/5000\n",
            "3/3 [==============================] - 0s 206ms/step - loss: 214.8982 - mae: 214.8982 - mse: 287085.9375 - val_loss: 1038.9894 - val_mae: 1038.9894 - val_mse: 2293642.5000 - lr: 0.0010\n",
            "Epoch 129/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 207.2841 - mae: 207.2841 - mse: 287275.2500INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 207.2841 - mae: 207.2841 - mse: 287275.2500 - val_loss: 985.9232 - val_mae: 985.9232 - val_mse: 2111631.5000 - lr: 0.0010\n",
            "Epoch 130/5000\n",
            "3/3 [==============================] - 0s 172ms/step - loss: 210.0770 - mae: 210.0770 - mse: 279820.0312 - val_loss: 1040.9390 - val_mae: 1040.9390 - val_mse: 2301652.2500 - lr: 0.0010\n",
            "Epoch 131/5000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 11.0321 - mae: 11.0321 - mse: 456.1933INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 200.7411 - mae: 200.7411 - mse: 275134.6250 - val_loss: 985.4533 - val_mae: 985.4533 - val_mse: 2114721.0000 - lr: 0.0010\n",
            "Epoch 132/5000\n",
            "3/3 [==============================] - 0s 97ms/step - loss: 204.1415 - mae: 204.1415 - mse: 268472.3750 - val_loss: 1024.2087 - val_mae: 1024.2087 - val_mse: 2250655.2500 - lr: 0.0010\n",
            "Epoch 133/5000\n",
            "3/3 [==============================] - 0s 216ms/step - loss: 198.8114 - mae: 198.8114 - mse: 271226.5625 - val_loss: 988.3655 - val_mae: 988.3655 - val_mse: 2132309.0000 - lr: 0.0010\n",
            "Epoch 134/5000\n",
            "3/3 [==============================] - 0s 92ms/step - loss: 208.4927 - mae: 208.4927 - mse: 275339.1875 - val_loss: 1023.5821 - val_mae: 1023.5821 - val_mse: 2245760.5000 - lr: 0.0010\n",
            "Epoch 135/5000\n",
            "3/3 [==============================] - 0s 98ms/step - loss: 204.8479 - mae: 204.8479 - mse: 282002.1875 - val_loss: 986.0456 - val_mae: 986.0456 - val_mse: 2119222.7500 - lr: 0.0010\n",
            "Epoch 136/5000\n",
            "3/3 [==============================] - 0s 154ms/step - loss: 212.6529 - mae: 212.6529 - mse: 283206.8438 - val_loss: 1040.0803 - val_mae: 1040.0803 - val_mse: 2296631.2500 - lr: 0.0010\n",
            "Epoch 137/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 203.4288 - mae: 203.4288 - mse: 279635.2500INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 203.4288 - mae: 203.4288 - mse: 279635.2500 - val_loss: 984.6062 - val_mae: 984.6062 - val_mse: 2113426.7500 - lr: 0.0010\n",
            "Epoch 138/5000\n",
            "3/3 [==============================] - 0s 120ms/step - loss: 208.1429 - mae: 208.1429 - mse: 274848.9375 - val_loss: 1034.7755 - val_mae: 1034.7755 - val_mse: 2283979.0000 - lr: 0.0010\n",
            "Epoch 139/5000\n",
            "3/3 [==============================] - 0s 160ms/step - loss: 200.4864 - mae: 200.4864 - mse: 274503.4375 - val_loss: 984.9832 - val_mae: 984.9832 - val_mse: 2118861.2500 - lr: 0.0010\n",
            "Epoch 140/5000\n",
            "3/3 [==============================] - 0s 95ms/step - loss: 207.0345 - mae: 207.0345 - mse: 273455.5938 - val_loss: 1031.8691 - val_mae: 1031.8691 - val_mse: 2274555.0000 - lr: 0.0010\n",
            "Epoch 141/5000\n",
            "3/3 [==============================] - 0s 121ms/step - loss: 199.0290 - mae: 199.0290 - mse: 271561.4375 - val_loss: 985.2040 - val_mae: 985.2040 - val_mse: 2120149.5000 - lr: 0.0010\n",
            "Epoch 142/5000\n",
            "3/3 [==============================] - 0s 91ms/step - loss: 205.5228 - mae: 205.5228 - mse: 270178.0312 - val_loss: 1029.6553 - val_mae: 1029.6553 - val_mse: 2264770.5000 - lr: 0.0010\n",
            "Epoch 143/5000\n",
            "3/3 [==============================] - 0s 102ms/step - loss: 198.3515 - mae: 198.3515 - mse: 270333.9062 - val_loss: 989.1913 - val_mae: 989.1913 - val_mse: 2134151.0000 - lr: 0.0010\n",
            "Epoch 144/5000\n",
            "3/3 [==============================] - 0s 92ms/step - loss: 209.7902 - mae: 209.7902 - mse: 277120.0312 - val_loss: 1023.2234 - val_mae: 1023.2234 - val_mse: 2243425.7500 - lr: 0.0010\n",
            "Epoch 145/5000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 10.6975 - mae: 10.6975 - mse: 429.0250INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 206.2893 - mae: 206.2893 - mse: 283221.5312 - val_loss: 983.7171 - val_mae: 983.7171 - val_mse: 2111393.0000 - lr: 0.0010\n",
            "Epoch 146/5000\n",
            "3/3 [==============================] - 0s 98ms/step - loss: 213.9554 - mae: 213.9554 - mse: 285801.0000 - val_loss: 1052.0359 - val_mae: 1052.0359 - val_mse: 2335012.5000 - lr: 0.0010\n",
            "Epoch 147/5000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 11.1039 - mae: 11.1039 - mse: 441.6053INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 199.8927 - mae: 199.8927 - mse: 272985.7500 - val_loss: 982.5851 - val_mae: 982.5851 - val_mse: 2108055.0000 - lr: 0.0010\n",
            "Epoch 148/5000\n",
            "3/3 [==============================] - 0s 106ms/step - loss: 204.1262 - mae: 204.1262 - mse: 267494.0312 - val_loss: 1026.6592 - val_mae: 1026.6592 - val_mse: 2257758.7500 - lr: 0.0010\n",
            "Epoch 149/5000\n",
            "3/3 [==============================] - 1s 344ms/step - loss: 197.0052 - mae: 197.0052 - mse: 267377.2500 - val_loss: 986.1255 - val_mae: 986.1255 - val_mse: 2127834.5000 - lr: 0.0010\n",
            "Epoch 150/5000\n",
            "3/3 [==============================] - 0s 138ms/step - loss: 207.6224 - mae: 207.6224 - mse: 272980.5312 - val_loss: 1011.7896 - val_mae: 1011.7896 - val_mse: 2207325.7500 - lr: 0.0010\n",
            "Epoch 151/5000\n",
            "3/3 [==============================] - 0s 134ms/step - loss: 206.6680 - mae: 206.6680 - mse: 282956.8125 - val_loss: 985.2219 - val_mae: 985.2219 - val_mse: 2123741.2500 - lr: 0.0010\n",
            "Epoch 152/5000\n",
            "3/3 [==============================] - 1s 205ms/step - loss: 219.9463 - mae: 219.9463 - mse: 296107.5625 - val_loss: 1060.7158 - val_mae: 1060.7158 - val_mse: 2361319.5000 - lr: 0.0010\n",
            "Epoch 153/5000\n",
            "3/3 [==============================] - 0s 160ms/step - loss: 203.7739 - mae: 203.7739 - mse: 279925.1875 - val_loss: 983.0161 - val_mae: 983.0161 - val_mse: 2099216.7500 - lr: 0.0010\n",
            "Epoch 154/5000\n",
            "3/3 [==============================] - 0s 92ms/step - loss: 202.5344 - mae: 202.5344 - mse: 265771.0000 - val_loss: 1035.0220 - val_mae: 1035.0220 - val_mse: 2283297.5000 - lr: 0.0010\n",
            "Epoch 155/5000\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 193.1829 - mae: 193.1829 - mse: 260475.6094 - val_loss: 984.9409 - val_mae: 984.9409 - val_mse: 2123195.5000 - lr: 0.0010\n",
            "Epoch 156/5000\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 199.8975 - mae: 199.8975 - mse: 260137.8438 - val_loss: 1006.1252 - val_mae: 1006.1252 - val_mse: 2192722.7500 - lr: 0.0010\n",
            "Epoch 157/5000\n",
            "3/3 [==============================] - 0s 94ms/step - loss: 200.2125 - mae: 200.2125 - mse: 271288.8438 - val_loss: 1019.1053 - val_mae: 1019.1053 - val_mse: 2214347.0000 - lr: 0.0010\n",
            "Epoch 158/5000\n",
            "3/3 [==============================] - 0s 94ms/step - loss: 227.6276 - mae: 227.6276 - mse: 304869.2812 - val_loss: 997.1081 - val_mae: 997.1081 - val_mse: 2165119.2500 - lr: 0.0010\n",
            "Epoch 159/5000\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 223.4042 - mae: 223.4042 - mse: 313285.3438 - val_loss: 984.0645 - val_mae: 984.0645 - val_mse: 2090579.6250 - lr: 0.0010\n",
            "Epoch 160/5000\n",
            "3/3 [==============================] - 0s 97ms/step - loss: 216.0679 - mae: 216.0679 - mse: 291432.5938 - val_loss: 1096.3773 - val_mae: 1096.3773 - val_mse: 2475161.2500 - lr: 0.0010\n",
            "Epoch 161/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 191.9039 - mae: 191.9039 - mse: 259461.8125INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 191.9039 - mae: 191.9039 - mse: 259461.8125 - val_loss: 980.8688 - val_mae: 980.8688 - val_mse: 2099346.7500 - lr: 0.0010\n",
            "Epoch 162/5000\n",
            "3/3 [==============================] - 0s 93ms/step - loss: 191.4355 - mae: 191.4355 - mse: 247122.5312 - val_loss: 997.6612 - val_mae: 997.6612 - val_mse: 2171088.5000 - lr: 0.0010\n",
            "Epoch 163/5000\n",
            "3/3 [==============================] - 0s 94ms/step - loss: 191.1499 - mae: 191.1499 - mse: 255816.9062 - val_loss: 988.2797 - val_mae: 988.2797 - val_mse: 2139138.2500 - lr: 0.0010\n",
            "Epoch 164/5000\n",
            "3/3 [==============================] - 0s 152ms/step - loss: 203.3781 - mae: 203.3781 - mse: 265368.0625 - val_loss: 1007.1200 - val_mae: 1007.1200 - val_mse: 2194727.5000 - lr: 0.0010\n",
            "Epoch 165/5000\n",
            "3/3 [==============================] - 0s 95ms/step - loss: 203.1720 - mae: 203.1720 - mse: 276349.1562 - val_loss: 984.8349 - val_mae: 984.8349 - val_mse: 2121121.5000 - lr: 0.0010\n",
            "Epoch 166/5000\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 216.8355 - mae: 216.8355 - mse: 290354.2812 - val_loss: 1050.2023 - val_mae: 1050.2023 - val_mse: 2326234.7500 - lr: 0.0010\n",
            "Epoch 167/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 202.6722 - mae: 202.6722 - mse: 276622.3750INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 202.6722 - mae: 202.6722 - mse: 276622.3750 - val_loss: 979.8735 - val_mae: 979.8735 - val_mse: 2094319.0000 - lr: 0.0010\n",
            "Epoch 168/5000\n",
            "3/3 [==============================] - 0s 211ms/step - loss: 203.5490 - mae: 203.5490 - mse: 267146.0000 - val_loss: 1033.7983 - val_mae: 1033.7983 - val_mse: 2279234.0000 - lr: 0.0010\n",
            "Epoch 169/5000\n",
            "3/3 [==============================] - 0s 93ms/step - loss: 193.9139 - mae: 193.9139 - mse: 261111.9062 - val_loss: 981.3494 - val_mae: 981.3494 - val_mse: 2109881.2500 - lr: 0.0010\n",
            "Epoch 170/5000\n",
            "3/3 [==============================] - 0s 124ms/step - loss: 199.1381 - mae: 199.1381 - mse: 259062.5000 - val_loss: 1007.8477 - val_mae: 1007.8477 - val_mse: 2199562.7500 - lr: 0.0010\n",
            "Epoch 171/5000\n",
            "3/3 [==============================] - 0s 203ms/step - loss: 197.3305 - mae: 197.3305 - mse: 265796.0312 - val_loss: 983.5959 - val_mae: 983.5959 - val_mse: 2120095.5000 - lr: 0.0010\n",
            "Epoch 172/5000\n",
            "3/3 [==============================] - 0s 97ms/step - loss: 208.1822 - mae: 208.1822 - mse: 274380.5000 - val_loss: 1016.5745 - val_mae: 1016.5745 - val_mse: 2222406.7500 - lr: 0.0010\n",
            "Epoch 173/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 206.2556 - mae: 206.2556 - mse: 281869.1875INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 206.2556 - mae: 206.2556 - mse: 281869.1875 - val_loss: 978.7609 - val_mae: 978.7609 - val_mse: 2093934.6250 - lr: 0.0010\n",
            "Epoch 174/5000\n",
            "3/3 [==============================] - 0s 100ms/step - loss: 211.0638 - mae: 211.0638 - mse: 280609.5625 - val_loss: 1041.3113 - val_mae: 1041.3113 - val_mse: 2298363.2500 - lr: 0.0010\n",
            "Epoch 175/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 199.0495 - mae: 199.0495 - mse: 269664.0000INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 199.0495 - mae: 199.0495 - mse: 269664.0000 - val_loss: 977.5169 - val_mae: 977.5169 - val_mse: 2095916.3750 - lr: 0.0010\n",
            "Epoch 176/5000\n",
            "3/3 [==============================] - 0s 96ms/step - loss: 204.4963 - mae: 204.4963 - mse: 268239.4688 - val_loss: 1027.3983 - val_mae: 1027.3983 - val_mse: 2258567.7500 - lr: 0.0010\n",
            "Epoch 177/5000\n",
            "3/3 [==============================] - 0s 103ms/step - loss: 195.5035 - mae: 195.5035 - mse: 263500.8438 - val_loss: 978.0656 - val_mae: 978.0656 - val_mse: 2101136.0000 - lr: 0.0010\n",
            "Epoch 178/5000\n",
            "3/3 [==============================] - 0s 93ms/step - loss: 202.0765 - mae: 202.0765 - mse: 263864.6562 - val_loss: 1015.8845 - val_mae: 1015.8845 - val_mse: 2223028.7500 - lr: 0.0010\n",
            "Epoch 179/5000\n",
            "3/3 [==============================] - 0s 116ms/step - loss: 196.0575 - mae: 196.0575 - mse: 263771.9688 - val_loss: 980.5065 - val_mae: 980.5065 - val_mse: 2111487.0000 - lr: 0.0010\n",
            "Epoch 180/5000\n",
            "3/3 [==============================] - 0s 191ms/step - loss: 207.0168 - mae: 207.0168 - mse: 271901.4375 - val_loss: 1018.6938 - val_mae: 1018.6938 - val_mse: 2231130.5000 - lr: 0.0010\n",
            "Epoch 181/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 202.2017 - mae: 202.2017 - mse: 274323.3125INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 202.2017 - mae: 202.2017 - mse: 274323.3125 - val_loss: 976.9932 - val_mae: 976.9932 - val_mse: 2094033.0000 - lr: 0.0010\n",
            "Epoch 182/5000\n",
            "3/3 [==============================] - 0s 130ms/step - loss: 208.0987 - mae: 208.0987 - mse: 274650.2812 - val_loss: 1027.2325 - val_mae: 1027.2325 - val_mse: 2256531.0000 - lr: 0.0010\n",
            "Epoch 183/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 200.5908 - mae: 200.5908 - mse: 271569.0938INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 200.5908 - mae: 200.5908 - mse: 271569.0938 - val_loss: 976.6478 - val_mae: 976.6478 - val_mse: 2093884.0000 - lr: 0.0010\n",
            "Epoch 184/5000\n",
            "3/3 [==============================] - 0s 99ms/step - loss: 206.8288 - mae: 206.8288 - mse: 272326.6250 - val_loss: 1028.1848 - val_mae: 1028.1848 - val_mse: 2259704.0000 - lr: 0.0010\n",
            "Epoch 185/5000\n",
            "3/3 [==============================] - 0s 96ms/step - loss: 198.0589 - mae: 198.0589 - mse: 267341.6562 - val_loss: 978.5253 - val_mae: 978.5253 - val_mse: 2103696.5000 - lr: 0.0010\n",
            "Epoch 186/5000\n",
            "3/3 [==============================] - 0s 161ms/step - loss: 208.0365 - mae: 208.0365 - mse: 273978.3438 - val_loss: 1023.6037 - val_mae: 1023.6037 - val_mse: 2246408.7500 - lr: 0.0010\n",
            "Epoch 187/5000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 10.6390 - mae: 10.6390 - mse: 408.8889INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 200.8931 - mae: 200.8931 - mse: 271815.0625 - val_loss: 975.7941 - val_mae: 975.7941 - val_mse: 2092403.2500 - lr: 0.0010\n",
            "Epoch 188/5000\n",
            "3/3 [==============================] - 0s 131ms/step - loss: 207.6166 - mae: 207.6166 - mse: 273888.6875 - val_loss: 1032.5221 - val_mae: 1032.5221 - val_mse: 2273166.0000 - lr: 0.0010\n",
            "Epoch 189/5000\n",
            "3/3 [==============================] - 0s 96ms/step - loss: 197.1247 - mae: 197.1247 - mse: 265639.8438 - val_loss: 977.8490 - val_mae: 977.8490 - val_mse: 2102514.0000 - lr: 0.0010\n",
            "Epoch 190/5000\n",
            "3/3 [==============================] - 0s 91ms/step - loss: 206.9364 - mae: 206.9364 - mse: 271858.2812 - val_loss: 1021.0007 - val_mae: 1021.0007 - val_mse: 2238674.0000 - lr: 0.0010\n",
            "Epoch 191/5000\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 200.7133 - mae: 200.7133 - mse: 271856.2188 - val_loss: 975.8356 - val_mae: 975.8356 - val_mse: 2093313.3750 - lr: 0.0010\n",
            "Epoch 192/5000\n",
            "3/3 [==============================] - 0s 93ms/step - loss: 207.8462 - mae: 207.8462 - mse: 273970.5312 - val_loss: 1029.8500 - val_mae: 1029.8500 - val_mse: 2265315.5000 - lr: 0.0010\n",
            "Epoch 193/5000\n",
            "3/3 [==============================] - 0s 110ms/step - loss: 198.2046 - mae: 198.2046 - mse: 267387.2812 - val_loss: 976.3588 - val_mae: 976.3588 - val_mse: 2097161.5000 - lr: 0.0010\n",
            "Epoch 194/5000\n",
            "3/3 [==============================] - 0s 93ms/step - loss: 206.7130 - mae: 206.7130 - mse: 271407.1250 - val_loss: 1023.1188 - val_mae: 1023.1188 - val_mse: 2245655.2500 - lr: 0.0010\n",
            "Epoch 195/5000\n",
            "3/3 [==============================] - 0s 91ms/step - loss: 199.3720 - mae: 199.3720 - mse: 269166.1875 - val_loss: 976.0356 - val_mae: 976.0356 - val_mse: 2095138.2500 - lr: 0.0010\n",
            "Epoch 196/5000\n",
            "3/3 [==============================] - 0s 109ms/step - loss: 207.4308 - mae: 207.4308 - mse: 272851.0000 - val_loss: 1028.5613 - val_mae: 1028.5613 - val_mse: 2261136.0000 - lr: 0.0010\n",
            "Epoch 197/5000\n",
            "3/3 [==============================] - 0s 156ms/step - loss: 197.7765 - mae: 197.7765 - mse: 266485.8438 - val_loss: 976.1749 - val_mae: 976.1749 - val_mse: 2096903.3750 - lr: 0.0010\n",
            "Epoch 198/5000\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 206.7416 - mae: 206.7416 - mse: 271484.2188 - val_loss: 1023.6172 - val_mae: 1023.6172 - val_mse: 2246975.2500 - lr: 0.0010\n",
            "Epoch 199/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 198.9927 - mae: 198.9927 - mse: 268396.4375INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 198.9927 - mae: 198.9927 - mse: 268396.4375 - val_loss: 975.2635 - val_mae: 975.2635 - val_mse: 2092425.1250 - lr: 0.0010\n",
            "Epoch 200/5000\n",
            "3/3 [==============================] - 0s 90ms/step - loss: 206.5145 - mae: 206.5145 - mse: 271422.0000 - val_loss: 1025.6353 - val_mae: 1025.6353 - val_mse: 2253153.7500 - lr: 0.0010\n",
            "Epoch 201/5000\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 197.7149 - mae: 197.7149 - mse: 266243.8125 - val_loss: 976.0415 - val_mae: 976.0415 - val_mse: 2096668.6250 - lr: 0.0010\n",
            "Epoch 202/5000\n",
            "3/3 [==============================] - 0s 93ms/step - loss: 206.5342 - mae: 206.5342 - mse: 271237.2188 - val_loss: 1023.7411 - val_mae: 1023.7411 - val_mse: 2247158.2500 - lr: 0.0010\n",
            "Epoch 203/5000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 10.6004 - mae: 10.6004 - mse: 401.7068INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 3s 1s/step - loss: 198.7119 - mae: 198.7119 - mse: 267734.1250 - val_loss: 974.9257 - val_mae: 974.9257 - val_mse: 2091328.2500 - lr: 0.0010\n",
            "Epoch 204/5000\n",
            "3/3 [==============================] - 0s 161ms/step - loss: 206.1244 - mae: 206.1244 - mse: 270679.4688 - val_loss: 1024.9989 - val_mae: 1024.9989 - val_mse: 2250572.2500 - lr: 0.0010\n",
            "Epoch 205/5000\n",
            "3/3 [==============================] - 0s 124ms/step - loss: 197.5711 - mae: 197.5711 - mse: 265711.5938 - val_loss: 975.5754 - val_mae: 975.5754 - val_mse: 2094861.1250 - lr: 0.0010\n",
            "Epoch 206/5000\n",
            "3/3 [==============================] - 0s 195ms/step - loss: 206.1448 - mae: 206.1448 - mse: 270501.1250 - val_loss: 1022.1453 - val_mae: 1022.1453 - val_mse: 2241790.7500 - lr: 0.0010\n",
            "Epoch 207/5000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 10.5521 - mae: 10.5521 - mse: 396.1066INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 198.6729 - mae: 198.6729 - mse: 267504.6562 - val_loss: 974.0967 - val_mae: 974.0967 - val_mse: 2089185.7500 - lr: 0.0010\n",
            "Epoch 208/5000\n",
            "3/3 [==============================] - 0s 97ms/step - loss: 205.7171 - mae: 205.7171 - mse: 269918.3438 - val_loss: 1025.0377 - val_mae: 1025.0377 - val_mse: 2250812.0000 - lr: 0.0010\n",
            "Epoch 209/5000\n",
            "3/3 [==============================] - 0s 95ms/step - loss: 197.2857 - mae: 197.2857 - mse: 265381.2500 - val_loss: 975.2381 - val_mae: 975.2381 - val_mse: 2094201.2500 - lr: 0.0010\n",
            "Epoch 210/5000\n",
            "3/3 [==============================] - 0s 98ms/step - loss: 205.6775 - mae: 205.6775 - mse: 269616.7812 - val_loss: 1020.8093 - val_mae: 1020.8093 - val_mse: 2238594.2500 - lr: 0.0010\n",
            "Epoch 211/5000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 10.5319 - mae: 10.5319 - mse: 394.9111INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 198.5436 - mae: 198.5436 - mse: 267203.9375 - val_loss: 973.8592 - val_mae: 973.8592 - val_mse: 2089604.2500 - lr: 0.0010\n",
            "Epoch 212/5000\n",
            "3/3 [==============================] - 0s 96ms/step - loss: 205.7724 - mae: 205.7724 - mse: 269879.1875 - val_loss: 1025.7129 - val_mae: 1025.7129 - val_mse: 2253546.5000 - lr: 0.0010\n",
            "Epoch 213/5000\n",
            "3/3 [==============================] - 0s 109ms/step - loss: 196.6227 - mae: 196.6227 - mse: 264207.7500 - val_loss: 974.6989 - val_mae: 974.6989 - val_mse: 2093790.1250 - lr: 0.0010\n",
            "Epoch 214/5000\n",
            "3/3 [==============================] - 0s 159ms/step - loss: 204.9968 - mae: 204.9968 - mse: 268372.7188 - val_loss: 1020.9641 - val_mae: 1020.9641 - val_mse: 2240129.7500 - lr: 0.0010\n",
            "Epoch 215/5000\n",
            "3/3 [==============================] - 0s 82ms/step - loss: 197.9262 - mae: 197.9262 - mse: 266244.3125 - val_loss: 974.3068 - val_mae: 974.3068 - val_mse: 2093103.2500 - lr: 0.0010\n",
            "Epoch 216/5000\n",
            "3/3 [==============================] - 0s 111ms/step - loss: 205.9687 - mae: 205.9687 - mse: 270095.9688 - val_loss: 1025.4476 - val_mae: 1025.4476 - val_mse: 2252748.2500 - lr: 0.0010\n",
            "Epoch 217/5000\n",
            "3/3 [==============================] - 0s 148ms/step - loss: 196.6365 - mae: 196.6365 - mse: 263990.5938 - val_loss: 974.2900 - val_mae: 974.2900 - val_mse: 2093875.5000 - lr: 0.0010\n",
            "Epoch 218/5000\n",
            "3/3 [==============================] - 0s 101ms/step - loss: 205.7006 - mae: 205.7006 - mse: 269355.1562 - val_loss: 1022.8867 - val_mae: 1022.8867 - val_mse: 2245616.0000 - lr: 0.0010\n",
            "Epoch 219/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 197.6226 - mae: 197.6226 - mse: 265647.9688INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 197.6226 - mae: 197.6226 - mse: 265647.9688 - val_loss: 973.6707 - val_mae: 973.6707 - val_mse: 2091063.7500 - lr: 0.0010\n",
            "Epoch 220/5000\n",
            "3/3 [==============================] - 0s 98ms/step - loss: 205.2881 - mae: 205.2881 - mse: 268802.3125 - val_loss: 1023.3922 - val_mae: 1023.3922 - val_mse: 2247018.2500 - lr: 0.0010\n",
            "Epoch 221/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 196.9960 - mae: 196.9960 - mse: 264499.1875INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 196.9960 - mae: 196.9960 - mse: 264499.1875 - val_loss: 973.4828 - val_mae: 973.4828 - val_mse: 2090964.6250 - lr: 0.0010\n",
            "Epoch 222/5000\n",
            "3/3 [==============================] - 0s 106ms/step - loss: 204.8927 - mae: 204.8927 - mse: 267995.8125 - val_loss: 1019.3888 - val_mae: 1019.3888 - val_mse: 2235161.5000 - lr: 0.0010\n",
            "Epoch 223/5000\n",
            "3/3 [==============================] - 0s 178ms/step - loss: 198.0227 - mae: 198.0227 - mse: 266082.9375 - val_loss: 973.6406 - val_mae: 973.6406 - val_mse: 2091476.2500 - lr: 0.0010\n",
            "Epoch 224/5000\n",
            "3/3 [==============================] - 0s 93ms/step - loss: 206.5008 - mae: 206.5008 - mse: 270732.9375 - val_loss: 1031.5098 - val_mae: 1031.5098 - val_mse: 2271465.7500 - lr: 0.0010\n",
            "Epoch 225/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 195.0836 - mae: 195.0836 - mse: 261463.7812INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 195.0836 - mae: 195.0836 - mse: 261463.7812 - val_loss: 971.8198 - val_mae: 971.8198 - val_mse: 2083464.7500 - lr: 0.0010\n",
            "Epoch 226/5000\n",
            "3/3 [==============================] - 0s 126ms/step - loss: 199.7046 - mae: 199.7046 - mse: 258984.5625 - val_loss: 1017.9160 - val_mae: 1017.9160 - val_mse: 2229566.7500 - lr: 0.0010\n",
            "Epoch 227/5000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 10.4499 - mae: 10.4499 - mse: 383.2860INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 191.6830 - mae: 191.6830 - mse: 255548.9531 - val_loss: 971.7061 - val_mae: 971.7061 - val_mse: 2082353.7500 - lr: 0.0010\n",
            "Epoch 228/5000\n",
            "3/3 [==============================] - 0s 98ms/step - loss: 195.5273 - mae: 195.5273 - mse: 251974.0469 - val_loss: 1001.9169 - val_mae: 1001.9169 - val_mse: 2178962.7500 - lr: 0.0010\n",
            "Epoch 229/5000\n",
            "3/3 [==============================] - 0s 90ms/step - loss: 192.1400 - mae: 192.1400 - mse: 255626.2188 - val_loss: 977.4465 - val_mae: 977.4465 - val_mse: 2103179.5000 - lr: 0.0010\n",
            "Epoch 230/5000\n",
            "3/3 [==============================] - 0s 153ms/step - loss: 203.0714 - mae: 203.0714 - mse: 264237.9375 - val_loss: 1010.0766 - val_mae: 1010.0766 - val_mse: 2203777.0000 - lr: 0.0010\n",
            "Epoch 231/5000\n",
            "3/3 [==============================] - 0s 194ms/step - loss: 199.2208 - mae: 199.2208 - mse: 267526.4062 - val_loss: 974.3766 - val_mae: 974.3766 - val_mse: 2094016.5000 - lr: 0.0010\n",
            "Epoch 232/5000\n",
            "3/3 [==============================] - 0s 117ms/step - loss: 209.6126 - mae: 209.6126 - mse: 276145.9688 - val_loss: 1033.2749 - val_mae: 1033.2749 - val_mse: 2277364.7500 - lr: 0.0010\n",
            "Epoch 233/5000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 10.5970 - mae: 10.5970 - mse: 389.2487INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 198.0125 - mae: 198.0125 - mse: 266093.6875 - val_loss: 970.3848 - val_mae: 970.3848 - val_mse: 2077624.1250 - lr: 0.0010\n",
            "Epoch 234/5000\n",
            "3/3 [==============================] - 0s 173ms/step - loss: 200.7529 - mae: 200.7529 - mse: 260834.3125 - val_loss: 1019.5609 - val_mae: 1019.5609 - val_mse: 2236669.7500 - lr: 0.0010\n",
            "Epoch 235/5000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 10.4456 - mae: 10.4456 - mse: 382.6859INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 192.2986 - mae: 192.2986 - mse: 256101.1250 - val_loss: 970.3774 - val_mae: 970.3774 - val_mse: 2081273.2500 - lr: 0.0010\n",
            "Epoch 236/5000\n",
            "3/3 [==============================] - 0s 151ms/step - loss: 195.9087 - mae: 195.9087 - mse: 252423.4531 - val_loss: 1003.1489 - val_mae: 1003.1489 - val_mse: 2186855.5000 - lr: 0.0010\n",
            "Epoch 237/5000\n",
            "3/3 [==============================] - 0s 91ms/step - loss: 191.4260 - mae: 191.4260 - mse: 254087.1406 - val_loss: 972.3476 - val_mae: 972.3476 - val_mse: 2088618.6250 - lr: 0.0010\n",
            "Epoch 238/5000\n",
            "3/3 [==============================] - 0s 106ms/step - loss: 197.6434 - mae: 197.6434 - mse: 255010.0156 - val_loss: 1008.2877 - val_mae: 1008.2877 - val_mse: 2197170.0000 - lr: 0.0010\n",
            "Epoch 239/5000\n",
            "3/3 [==============================] - 0s 129ms/step - loss: 192.4035 - mae: 192.4035 - mse: 256308.5000 - val_loss: 975.0508 - val_mae: 975.0508 - val_mse: 2093728.7500 - lr: 0.0010\n",
            "Epoch 240/5000\n",
            "3/3 [==============================] - 1s 302ms/step - loss: 200.5563 - mae: 200.5563 - mse: 260002.4375 - val_loss: 1006.1165 - val_mae: 1006.1165 - val_mse: 2189642.2500 - lr: 0.0010\n",
            "Epoch 241/5000\n",
            "3/3 [==============================] - 0s 219ms/step - loss: 197.6946 - mae: 197.6946 - mse: 264771.4375 - val_loss: 977.8928 - val_mae: 977.8928 - val_mse: 2106090.2500 - lr: 0.0010\n",
            "Epoch 242/5000\n",
            "3/3 [==============================] - 1s 262ms/step - loss: 212.1355 - mae: 212.1355 - mse: 280513.1250 - val_loss: 1032.2646 - val_mae: 1032.2646 - val_mse: 2272606.5000 - lr: 0.0010\n",
            "Epoch 243/5000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 10.6185 - mae: 10.6185 - mse: 384.3538INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 4s 2s/step - loss: 200.7496 - mae: 200.7496 - mse: 270966.3750 - val_loss: 969.5345 - val_mae: 969.5345 - val_mse: 2076030.5000 - lr: 0.0010\n",
            "Epoch 244/5000\n",
            "3/3 [==============================] - 0s 94ms/step - loss: 203.6682 - mae: 203.6682 - mse: 265953.8750 - val_loss: 1035.2012 - val_mae: 1035.2012 - val_mse: 2284548.5000 - lr: 0.0010\n",
            "Epoch 245/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 190.8257 - mae: 190.8257 - mse: 254271.4844INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 190.8257 - mae: 190.8257 - mse: 254271.4844 - val_loss: 968.2896 - val_mae: 968.2896 - val_mse: 2073706.1250 - lr: 0.0010\n",
            "Epoch 246/5000\n",
            "3/3 [==============================] - 0s 111ms/step - loss: 190.9860 - mae: 190.9860 - mse: 243898.3125 - val_loss: 996.5945 - val_mae: 996.5945 - val_mse: 2169888.7500 - lr: 0.0010\n",
            "Epoch 247/5000\n",
            "3/3 [==============================] - 0s 92ms/step - loss: 187.4173 - mae: 187.4173 - mse: 246992.3438 - val_loss: 975.9682 - val_mae: 975.9682 - val_mse: 2103533.0000 - lr: 0.0010\n",
            "Epoch 248/5000\n",
            "3/3 [==============================] - 0s 96ms/step - loss: 195.8035 - mae: 195.8035 - mse: 251038.7031 - val_loss: 998.0990 - val_mae: 998.0990 - val_mse: 2168614.7500 - lr: 0.0010\n",
            "Epoch 249/5000\n",
            "3/3 [==============================] - 0s 121ms/step - loss: 192.9520 - mae: 192.9520 - mse: 256232.5625 - val_loss: 975.1497 - val_mae: 975.1497 - val_mse: 2097154.5000 - lr: 0.0010\n",
            "Epoch 250/5000\n",
            "3/3 [==============================] - 0s 100ms/step - loss: 203.3502 - mae: 203.3502 - mse: 264404.9062 - val_loss: 1011.7268 - val_mae: 1011.7268 - val_mse: 2207666.5000 - lr: 0.0010\n",
            "Epoch 251/5000\n",
            "3/3 [==============================] - 0s 176ms/step - loss: 197.7999 - mae: 197.7999 - mse: 264558.6875 - val_loss: 973.9322 - val_mae: 973.9322 - val_mse: 2093747.8750 - lr: 0.0010\n",
            "Epoch 252/5000\n",
            "3/3 [==============================] - 0s 101ms/step - loss: 209.4300 - mae: 209.4300 - mse: 275759.1562 - val_loss: 1028.6469 - val_mae: 1028.6469 - val_mse: 2261344.5000 - lr: 0.0010\n",
            "Epoch 253/5000\n",
            "3/3 [==============================] - 0s 102ms/step - loss: 199.6582 - mae: 199.6582 - mse: 269025.8438 - val_loss: 969.0825 - val_mae: 969.0825 - val_mse: 2074404.6250 - lr: 0.0010\n",
            "Epoch 254/5000\n",
            "3/3 [==============================] - 0s 109ms/step - loss: 202.5408 - mae: 202.5408 - mse: 264152.7812 - val_loss: 1027.4969 - val_mae: 1027.4969 - val_mse: 2259320.7500 - lr: 0.0010\n",
            "Epoch 255/5000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 10.5256 - mae: 10.5256 - mse: 374.3347INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 980ms/step - loss: 191.2615 - mae: 191.2615 - mse: 254577.1094 - val_loss: 968.0222 - val_mae: 968.0222 - val_mse: 2071842.2500 - lr: 0.0010\n",
            "Epoch 256/5000\n",
            "3/3 [==============================] - 0s 96ms/step - loss: 191.6935 - mae: 191.6935 - mse: 245600.3281 - val_loss: 999.4513 - val_mae: 999.4513 - val_mse: 2175371.7500 - lr: 0.0010\n",
            "Epoch 257/5000\n",
            "3/3 [==============================] - 0s 101ms/step - loss: 187.1396 - mae: 187.1396 - mse: 246363.0000 - val_loss: 973.9396 - val_mae: 973.9396 - val_mse: 2095399.8750 - lr: 0.0010\n",
            "Epoch 258/5000\n",
            "3/3 [==============================] - 0s 97ms/step - loss: 194.1594 - mae: 194.1594 - mse: 248652.3281 - val_loss: 995.7756 - val_mae: 995.7756 - val_mse: 2158892.5000 - lr: 0.0010\n",
            "Epoch 259/5000\n",
            "3/3 [==============================] - 0s 97ms/step - loss: 192.9159 - mae: 192.9159 - mse: 256230.1562 - val_loss: 975.3984 - val_mae: 975.3984 - val_mse: 2095335.0000 - lr: 0.0010\n",
            "Epoch 260/5000\n",
            "3/3 [==============================] - 0s 93ms/step - loss: 202.7731 - mae: 202.7731 - mse: 263451.9062 - val_loss: 1005.9642 - val_mae: 1005.9642 - val_mse: 2187850.0000 - lr: 0.0010\n",
            "Epoch 261/5000\n",
            "3/3 [==============================] - 0s 106ms/step - loss: 200.3165 - mae: 200.3164 - mse: 268369.8438 - val_loss: 971.3981 - val_mae: 971.3981 - val_mse: 2083889.6250 - lr: 0.0010\n",
            "Epoch 262/5000\n",
            "3/3 [==============================] - 0s 109ms/step - loss: 209.7684 - mae: 209.7684 - mse: 276421.6562 - val_loss: 1034.2156 - val_mae: 1034.2156 - val_mse: 2277980.7500 - lr: 0.0010\n",
            "Epoch 263/5000\n",
            "3/3 [==============================] - 0s 101ms/step - loss: 197.0014 - mae: 197.0014 - mse: 263829.1250 - val_loss: 968.5840 - val_mae: 968.5840 - val_mse: 2075139.6250 - lr: 0.0010\n",
            "Epoch 264/5000\n",
            "3/3 [==============================] - 0s 102ms/step - loss: 201.8264 - mae: 201.8264 - mse: 262572.5938 - val_loss: 1022.1367 - val_mae: 1022.1367 - val_mse: 2244405.7500 - lr: 0.0010\n",
            "Epoch 265/5000\n",
            "3/3 [==============================] - 1s 259ms/step - loss: 192.2716 - mae: 192.2716 - mse: 255679.2969 - val_loss: 968.8132 - val_mae: 968.8132 - val_mse: 2078046.7500 - lr: 0.0010\n",
            "Epoch 266/5000\n",
            "3/3 [==============================] - 0s 91ms/step - loss: 195.8966 - mae: 195.8966 - mse: 252193.0781 - val_loss: 1007.9158 - val_mae: 1007.9158 - val_mse: 2200835.5000 - lr: 0.0010\n",
            "Epoch 267/5000\n",
            "3/3 [==============================] - 0s 109ms/step - loss: 189.9542 - mae: 189.9542 - mse: 251179.3438 - val_loss: 969.4692 - val_mae: 969.4692 - val_mse: 2080395.0000 - lr: 0.0010\n",
            "Epoch 268/5000\n",
            "3/3 [==============================] - 0s 146ms/step - loss: 193.4121 - mae: 193.4121 - mse: 248023.8750 - val_loss: 1003.0954 - val_mae: 1003.0954 - val_mse: 2183910.7500 - lr: 0.0010\n",
            "Epoch 269/5000\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 188.4315 - mae: 188.4315 - mse: 248249.4062 - val_loss: 971.2206 - val_mae: 971.2206 - val_mse: 2083422.5000 - lr: 0.0010\n",
            "Epoch 270/5000\n",
            "3/3 [==============================] - 0s 110ms/step - loss: 192.3974 - mae: 192.3974 - mse: 246267.1562 - val_loss: 996.4548 - val_mae: 996.4548 - val_mse: 2159821.5000 - lr: 0.0010\n",
            "Epoch 271/5000\n",
            "3/3 [==============================] - 0s 92ms/step - loss: 190.1994 - mae: 190.1994 - mse: 251035.5625 - val_loss: 975.8973 - val_mae: 975.8973 - val_mse: 2096775.7500 - lr: 0.0010\n",
            "Epoch 272/5000\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 198.6525 - mae: 198.6525 - mse: 256086.1250 - val_loss: 995.9470 - val_mae: 995.9470 - val_mse: 2158903.2500 - lr: 0.0010\n",
            "Epoch 273/5000\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 200.0806 - mae: 200.0806 - mse: 267447.8750 - val_loss: 974.7440 - val_mae: 974.7440 - val_mse: 2096971.5000 - lr: 0.0010\n",
            "Epoch 274/5000\n",
            "3/3 [==============================] - 0s 93ms/step - loss: 213.5030 - mae: 213.5030 - mse: 282525.9375 - val_loss: 1045.2966 - val_mae: 1045.2966 - val_mse: 2310844.0000 - lr: 0.0010\n",
            "Epoch 275/5000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 10.6511 - mae: 10.6511 - mse: 369.4396INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 197.0596 - mae: 197.0596 - mse: 264211.0625 - val_loss: 967.7035 - val_mae: 967.7035 - val_mse: 2072385.8750 - lr: 0.0010\n",
            "Epoch 276/5000\n",
            "3/3 [==============================] - 0s 181ms/step - loss: 199.6055 - mae: 199.6055 - mse: 258838.9531 - val_loss: 1015.4938 - val_mae: 1015.4938 - val_mse: 2224584.2500 - lr: 0.0010\n",
            "Epoch 277/5000\n",
            "3/3 [==============================] - 0s 103ms/step - loss: 191.6397 - mae: 191.6397 - mse: 254439.6562 - val_loss: 968.5666 - val_mae: 968.5666 - val_mse: 2081393.8750 - lr: 0.0010\n",
            "Epoch 278/5000\n",
            "3/3 [==============================] - 0s 111ms/step - loss: 197.2713 - mae: 197.2713 - mse: 254215.1406 - val_loss: 998.5475 - val_mae: 998.5475 - val_mse: 2173353.5000 - lr: 0.0010\n",
            "Epoch 279/5000\n",
            "3/3 [==============================] - 0s 92ms/step - loss: 196.0179 - mae: 196.0179 - mse: 261399.0938 - val_loss: 972.5703 - val_mae: 972.5703 - val_mse: 2095111.7500 - lr: 0.0010\n",
            "Epoch 280/5000\n",
            "3/3 [==============================] - 0s 108ms/step - loss: 207.6223 - mae: 207.6223 - mse: 271660.0312 - val_loss: 1021.4883 - val_mae: 1021.4883 - val_mse: 2241058.0000 - lr: 0.0010\n",
            "Epoch 281/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 199.3457 - mae: 199.3457 - mse: 267728.0938INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 199.3457 - mae: 199.3457 - mse: 267728.0938 - val_loss: 967.5928 - val_mae: 967.5928 - val_mse: 2071648.2500 - lr: 0.0010\n",
            "Epoch 282/5000\n",
            "3/3 [==============================] - 0s 96ms/step - loss: 202.6153 - mae: 202.6153 - mse: 264052.6875 - val_loss: 1025.6986 - val_mae: 1025.6986 - val_mse: 2252509.0000 - lr: 0.0010\n",
            "Epoch 283/5000\n",
            "3/3 [==============================] - 0s 100ms/step - loss: 191.5678 - mae: 191.5678 - mse: 254370.1719 - val_loss: 968.1818 - val_mae: 968.1818 - val_mse: 2076094.3750 - lr: 0.0010\n",
            "Epoch 284/5000\n",
            "3/3 [==============================] - 0s 94ms/step - loss: 196.2618 - mae: 196.2618 - mse: 252326.4062 - val_loss: 1003.3788 - val_mae: 1003.3788 - val_mse: 2183071.0000 - lr: 0.0010\n",
            "Epoch 285/5000\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 192.0933 - mae: 192.0933 - mse: 254969.9219 - val_loss: 973.2448 - val_mae: 973.2448 - val_mse: 2092647.3750 - lr: 0.0010\n",
            "Epoch 286/5000\n",
            "3/3 [==============================] - 0s 100ms/step - loss: 202.1714 - mae: 202.1714 - mse: 262053.7031 - val_loss: 1007.4191 - val_mae: 1007.4191 - val_mse: 2194771.7500 - lr: 0.0010\n",
            "Epoch 287/5000\n",
            "3/3 [==============================] - 1s 226ms/step - loss: 199.2138 - mae: 199.2138 - mse: 266866.2812 - val_loss: 969.7751 - val_mae: 969.7751 - val_mse: 2082057.8750 - lr: 0.0010\n",
            "Epoch 288/5000\n",
            "3/3 [==============================] - 0s 92ms/step - loss: 208.0346 - mae: 208.0346 - mse: 272831.4062 - val_loss: 1030.1399 - val_mae: 1030.1399 - val_mse: 2267000.7500 - lr: 0.0010\n",
            "Epoch 289/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 195.7375 - mae: 195.7375 - mse: 261464.2188INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 5s 2s/step - loss: 195.7375 - mae: 195.7375 - mse: 261464.2188 - val_loss: 967.2128 - val_mae: 967.2128 - val_mse: 2076573.6250 - lr: 0.0010\n",
            "Epoch 290/5000\n",
            "3/3 [==============================] - 0s 92ms/step - loss: 202.3387 - mae: 202.3387 - mse: 262934.6250 - val_loss: 1023.0067 - val_mae: 1023.0067 - val_mse: 2247898.7500 - lr: 0.0010\n",
            "Epoch 291/5000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 10.3797 - mae: 10.3797 - mse: 356.8495INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 191.7725 - mae: 191.7725 - mse: 255033.6094 - val_loss: 966.4415 - val_mae: 966.4415 - val_mse: 2071899.7500 - lr: 0.0010\n",
            "Epoch 292/5000\n",
            "3/3 [==============================] - 0s 98ms/step - loss: 194.1576 - mae: 194.1576 - mse: 248683.2500 - val_loss: 1009.3728 - val_mae: 1009.3728 - val_mse: 2206222.5000 - lr: 0.0010\n",
            "Epoch 293/5000\n",
            "3/3 [==============================] - 0s 101ms/step - loss: 186.6748 - mae: 186.6748 - mse: 245527.0938 - val_loss: 967.9752 - val_mae: 967.9752 - val_mse: 2078095.6250 - lr: 0.0010\n",
            "Epoch 294/5000\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 190.4790 - mae: 190.4790 - mse: 242629.4062 - val_loss: 988.0406 - val_mae: 988.0406 - val_mse: 2138015.5000 - lr: 0.0010\n",
            "Epoch 295/5000\n",
            "3/3 [==============================] - 0s 91ms/step - loss: 189.8747 - mae: 189.8747 - mse: 250477.6875 - val_loss: 973.2335 - val_mae: 973.2335 - val_mse: 2091557.3750 - lr: 0.0010\n",
            "Epoch 296/5000\n",
            "3/3 [==============================] - 0s 100ms/step - loss: 199.0969 - mae: 199.0969 - mse: 256318.2031 - val_loss: 998.9246 - val_mae: 998.9246 - val_mse: 2167780.5000 - lr: 0.0010\n",
            "Epoch 297/5000\n",
            "3/3 [==============================] - 0s 112ms/step - loss: 197.9369 - mae: 197.9369 - mse: 264131.2188 - val_loss: 973.9252 - val_mae: 973.9252 - val_mse: 2095585.6250 - lr: 0.0010\n",
            "Epoch 298/5000\n",
            "3/3 [==============================] - 0s 97ms/step - loss: 211.8174 - mae: 211.8174 - mse: 279002.8125 - val_loss: 1039.7285 - val_mae: 1039.7285 - val_mse: 2294946.7500 - lr: 0.0010\n",
            "Epoch 299/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 196.6783 - mae: 196.6783 - mse: 263062.9062INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 196.6783 - mae: 196.6783 - mse: 263062.9062 - val_loss: 965.7117 - val_mae: 965.7117 - val_mse: 2068801.8750 - lr: 0.0010\n",
            "Epoch 300/5000\n",
            "3/3 [==============================] - 0s 197ms/step - loss: 199.2978 - mae: 199.2978 - mse: 257846.7188 - val_loss: 1013.5935 - val_mae: 1013.5935 - val_mse: 2219937.7500 - lr: 0.0010\n",
            "Epoch 301/5000\n",
            "3/3 [==============================] - 0s 99ms/step - loss: 191.4731 - mae: 191.4731 - mse: 253790.6562 - val_loss: 966.5720 - val_mae: 966.5720 - val_mse: 2075534.0000 - lr: 0.0010\n",
            "Epoch 302/5000\n",
            "3/3 [==============================] - 0s 124ms/step - loss: 195.6344 - mae: 195.6344 - mse: 251211.5312 - val_loss: 1009.6396 - val_mae: 1009.6396 - val_mse: 2204609.0000 - lr: 0.0010\n",
            "Epoch 303/5000\n",
            "3/3 [==============================] - 0s 93ms/step - loss: 189.0696 - mae: 189.0696 - mse: 247429.5625 - val_loss: 973.1894 - val_mae: 973.1894 - val_mse: 2097268.7500 - lr: 0.0010\n",
            "Epoch 304/5000\n",
            "3/3 [==============================] - 0s 111ms/step - loss: 193.9066 - mae: 193.9066 - mse: 247699.1250 - val_loss: 995.9551 - val_mae: 995.9551 - val_mse: 2163939.5000 - lr: 0.0010\n",
            "Epoch 305/5000\n",
            "3/3 [==============================] - 0s 170ms/step - loss: 191.0841 - mae: 191.0841 - mse: 252000.1406 - val_loss: 973.1661 - val_mae: 973.1661 - val_mse: 2093883.0000 - lr: 0.0010\n",
            "Epoch 306/5000\n",
            "3/3 [==============================] - 0s 139ms/step - loss: 201.8260 - mae: 201.8260 - mse: 261384.8438 - val_loss: 1004.3404 - val_mae: 1004.3404 - val_mse: 2184404.5000 - lr: 0.0010\n",
            "Epoch 307/5000\n",
            "3/3 [==============================] - 0s 148ms/step - loss: 198.1275 - mae: 198.1275 - mse: 264059.2188 - val_loss: 970.4416 - val_mae: 970.4416 - val_mse: 2083530.3750 - lr: 0.0010\n",
            "Epoch 308/5000\n",
            "3/3 [==============================] - 0s 182ms/step - loss: 209.2005 - mae: 209.2005 - mse: 274358.4375 - val_loss: 1033.0820 - val_mae: 1033.0820 - val_mse: 2273550.2500 - lr: 0.0010\n",
            "Epoch 309/5000\n",
            "3/3 [==============================] - 0s 152ms/step - loss: 196.4137 - mae: 196.4137 - mse: 262694.2500 - val_loss: 966.7673 - val_mae: 966.7673 - val_mse: 2071643.6250 - lr: 0.0010\n",
            "Epoch 310/5000\n",
            "3/3 [==============================] - 0s 97ms/step - loss: 200.6760 - mae: 200.6760 - mse: 260362.7500 - val_loss: 1016.7961 - val_mae: 1016.7961 - val_mse: 2227408.2500 - lr: 0.0010\n",
            "Epoch 311/5000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 10.2621 - mae: 10.2621 - mse: 344.8833INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 191.5955 - mae: 191.5955 - mse: 254132.6719 - val_loss: 965.2184 - val_mae: 965.2184 - val_mse: 2069039.2500 - lr: 0.0010\n",
            "Epoch 312/5000\n",
            "3/3 [==============================] - 0s 99ms/step - loss: 194.1862 - mae: 194.1862 - mse: 249003.4375 - val_loss: 1004.7243 - val_mae: 1004.7243 - val_mse: 2191308.0000 - lr: 0.0010\n",
            "Epoch 313/5000\n",
            "3/3 [==============================] - 0s 92ms/step - loss: 187.7908 - mae: 187.7908 - mse: 246649.4062 - val_loss: 966.6094 - val_mae: 966.6094 - val_mse: 2073077.0000 - lr: 0.0010\n",
            "Epoch 314/5000\n",
            "3/3 [==============================] - 0s 102ms/step - loss: 190.5322 - mae: 190.5322 - mse: 242389.1875 - val_loss: 993.7541 - val_mae: 993.7541 - val_mse: 2154606.5000 - lr: 0.0010\n",
            "Epoch 315/5000\n",
            "3/3 [==============================] - 0s 117ms/step - loss: 187.9252 - mae: 187.9252 - mse: 247003.6094 - val_loss: 972.2941 - val_mae: 972.2941 - val_mse: 2090075.6250 - lr: 0.0010\n",
            "Epoch 316/5000\n",
            "3/3 [==============================] - 0s 93ms/step - loss: 196.1754 - mae: 196.1754 - mse: 251347.1562 - val_loss: 993.8680 - val_mae: 993.8680 - val_mse: 2154585.2500 - lr: 0.0010\n",
            "Epoch 317/5000\n",
            "3/3 [==============================] - 0s 175ms/step - loss: 195.8951 - mae: 195.8951 - mse: 259931.8906 - val_loss: 975.0868 - val_mae: 975.0868 - val_mse: 2099788.2500 - lr: 0.0010\n",
            "Epoch 318/5000\n",
            "3/3 [==============================] - 0s 112ms/step - loss: 211.7937 - mae: 211.7937 - mse: 278427.5312 - val_loss: 1036.6740 - val_mae: 1036.6740 - val_mse: 2284913.5000 - lr: 0.0010\n",
            "Epoch 319/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 197.1092 - mae: 197.1092 - mse: 263566.2500INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 197.1092 - mae: 197.1092 - mse: 263566.2500 - val_loss: 965.0830 - val_mae: 965.0830 - val_mse: 2064623.7500 - lr: 0.0010\n",
            "Epoch 320/5000\n",
            "3/3 [==============================] - 0s 116ms/step - loss: 198.8843 - mae: 198.8843 - mse: 256712.8438 - val_loss: 1013.7158 - val_mae: 1013.7158 - val_mse: 2218860.5000 - lr: 0.0010\n",
            "Epoch 321/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 190.6911 - mae: 190.6911 - mse: 252224.6250INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 190.6911 - mae: 190.6911 - mse: 252224.6250 - val_loss: 964.7021 - val_mae: 964.7021 - val_mse: 2067501.8750 - lr: 0.0010\n",
            "Epoch 322/5000\n",
            "3/3 [==============================] - 1s 168ms/step - loss: 192.9880 - mae: 192.9880 - mse: 246490.0312 - val_loss: 999.1765 - val_mae: 999.1765 - val_mse: 2175347.7500 - lr: 0.0010\n",
            "Epoch 323/5000\n",
            "3/3 [==============================] - 0s 118ms/step - loss: 188.3228 - mae: 188.3228 - mse: 247298.2969 - val_loss: 965.7245 - val_mae: 965.7245 - val_mse: 2071192.6250 - lr: 0.0010\n",
            "Epoch 324/5000\n",
            "3/3 [==============================] - 0s 98ms/step - loss: 191.0980 - mae: 191.0980 - mse: 243320.8125 - val_loss: 992.1966 - val_mae: 992.1966 - val_mse: 2150448.0000 - lr: 0.0010\n",
            "Epoch 325/5000\n",
            "3/3 [==============================] - 0s 91ms/step - loss: 188.6718 - mae: 188.6718 - mse: 247860.1406 - val_loss: 970.6138 - val_mae: 970.6138 - val_mse: 2084902.0000 - lr: 0.0010\n",
            "Epoch 326/5000\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 196.2311 - mae: 196.2311 - mse: 251488.8125 - val_loss: 992.2715 - val_mae: 992.2715 - val_mse: 2148605.0000 - lr: 0.0010\n",
            "Epoch 327/5000\n",
            "3/3 [==============================] - 0s 100ms/step - loss: 197.2354 - mae: 197.2353 - mse: 262498.0312 - val_loss: 973.0743 - val_mae: 973.0743 - val_mse: 2093135.0000 - lr: 0.0010\n",
            "Epoch 328/5000\n",
            "3/3 [==============================] - 0s 113ms/step - loss: 211.4111 - mae: 211.4111 - mse: 277396.4062 - val_loss: 1036.6282 - val_mae: 1036.6282 - val_mse: 2284924.2500 - lr: 0.0010\n",
            "Epoch 329/5000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 10.4610 - mae: 10.4610 - mse: 346.5709INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 196.5836 - mae: 196.5836 - mse: 262829.6875 - val_loss: 964.6441 - val_mae: 964.6441 - val_mse: 2064578.3750 - lr: 0.0010\n",
            "Epoch 330/5000\n",
            "3/3 [==============================] - 0s 199ms/step - loss: 199.1539 - mae: 199.1539 - mse: 257522.4844 - val_loss: 1013.1315 - val_mae: 1013.1315 - val_mse: 2216956.0000 - lr: 0.0010\n",
            "Epoch 331/5000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 10.1937 - mae: 10.1937 - mse: 339.3607INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 190.8179 - mae: 190.8179 - mse: 252489.5000 - val_loss: 963.7066 - val_mae: 963.7066 - val_mse: 2065452.5000 - lr: 0.0010\n",
            "Epoch 332/5000\n",
            "3/3 [==============================] - 0s 186ms/step - loss: 193.2652 - mae: 193.2652 - mse: 247226.3594 - val_loss: 1000.7905 - val_mae: 1000.7905 - val_mse: 2179852.5000 - lr: 0.0010\n",
            "Epoch 333/5000\n",
            "3/3 [==============================] - 0s 148ms/step - loss: 187.4154 - mae: 187.4154 - mse: 245742.3438 - val_loss: 965.9287 - val_mae: 965.9287 - val_mse: 2073230.3750 - lr: 0.0010\n",
            "Epoch 334/5000\n",
            "3/3 [==============================] - 0s 186ms/step - loss: 190.7986 - mae: 190.7986 - mse: 242670.6875 - val_loss: 991.5298 - val_mae: 991.5298 - val_mse: 2149879.0000 - lr: 0.0010\n",
            "Epoch 335/5000\n",
            "3/3 [==============================] - 0s 162ms/step - loss: 189.0218 - mae: 189.0218 - mse: 248036.3281 - val_loss: 967.5358 - val_mae: 967.5358 - val_mse: 2074640.2500 - lr: 0.0010\n",
            "Epoch 336/5000\n",
            "3/3 [==============================] - 0s 116ms/step - loss: 192.9270 - mae: 192.9270 - mse: 246626.5000 - val_loss: 999.3685 - val_mae: 999.3685 - val_mse: 2169226.0000 - lr: 0.0010\n",
            "Epoch 337/5000\n",
            "3/3 [==============================] - 1s 179ms/step - loss: 188.6092 - mae: 188.6092 - mse: 248032.6406 - val_loss: 969.2684 - val_mae: 969.2684 - val_mse: 2077066.6250 - lr: 0.0010\n",
            "Epoch 338/5000\n",
            "3/3 [==============================] - 1s 285ms/step - loss: 193.6879 - mae: 193.6879 - mse: 247794.4375 - val_loss: 990.9785 - val_mae: 990.9785 - val_mse: 2144680.0000 - lr: 0.0010\n",
            "Epoch 339/5000\n",
            "3/3 [==============================] - 0s 179ms/step - loss: 194.2919 - mae: 194.2919 - mse: 257057.3750 - val_loss: 973.2075 - val_mae: 973.2075 - val_mse: 2093545.8750 - lr: 0.0010\n",
            "Epoch 340/5000\n",
            "3/3 [==============================] - 1s 277ms/step - loss: 206.4823 - mae: 206.4823 - mse: 268695.4688 - val_loss: 1015.4200 - val_mae: 1015.4200 - val_mse: 2222574.5000 - lr: 0.0010\n",
            "Epoch 341/5000\n",
            "3/3 [==============================] - 0s 176ms/step - loss: 199.9395 - mae: 199.9395 - mse: 267760.7812 - val_loss: 964.5060 - val_mae: 964.5060 - val_mse: 2064760.5000 - lr: 0.0010\n",
            "Epoch 342/5000\n",
            "3/3 [==============================] - 1s 268ms/step - loss: 202.9457 - mae: 202.9457 - mse: 264286.1562 - val_loss: 1030.3865 - val_mae: 1030.3865 - val_mse: 2268360.5000 - lr: 0.0010\n",
            "Epoch 343/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 189.4099 - mae: 189.4099 - mse: 250566.1719INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 3s 1s/step - loss: 189.4099 - mae: 189.4099 - mse: 250566.1719 - val_loss: 962.5406 - val_mae: 962.5406 - val_mse: 2057560.7500 - lr: 0.0010\n",
            "Epoch 344/5000\n",
            "3/3 [==============================] - 0s 191ms/step - loss: 188.4850 - mae: 188.4850 - mse: 239655.3281 - val_loss: 989.7868 - val_mae: 989.7868 - val_mse: 2150095.5000 - lr: 0.0010\n",
            "Epoch 345/5000\n",
            "3/3 [==============================] - 1s 230ms/step - loss: 185.0722 - mae: 185.0722 - mse: 241813.4375 - val_loss: 968.3431 - val_mae: 968.3431 - val_mse: 2085117.5000 - lr: 0.0010\n",
            "Epoch 346/5000\n",
            "3/3 [==============================] - 0s 180ms/step - loss: 191.9382 - mae: 191.9382 - mse: 244023.3750 - val_loss: 991.5015 - val_mae: 991.5015 - val_mse: 2151555.0000 - lr: 0.0010\n",
            "Epoch 347/5000\n",
            "3/3 [==============================] - 0s 164ms/step - loss: 189.8622 - mae: 189.8622 - mse: 249853.1250 - val_loss: 966.5710 - val_mae: 966.5710 - val_mse: 2074736.1250 - lr: 0.0010\n",
            "Epoch 348/5000\n",
            "3/3 [==============================] - 1s 214ms/step - loss: 194.7508 - mae: 194.7508 - mse: 249068.0469 - val_loss: 993.9084 - val_mae: 993.9084 - val_mse: 2155106.5000 - lr: 0.0010\n",
            "Epoch 349/5000\n",
            "3/3 [==============================] - 0s 179ms/step - loss: 193.3409 - mae: 193.3409 - mse: 255376.2188 - val_loss: 969.9842 - val_mae: 969.9842 - val_mse: 2083099.8750 - lr: 0.0010\n",
            "Epoch 350/5000\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 203.9633 - mae: 203.9633 - mse: 264613.0625 - val_loss: 1003.5156 - val_mae: 1003.5156 - val_mse: 2183493.7500 - lr: 0.0010\n",
            "Epoch 351/5000\n",
            "3/3 [==============================] - 0s 159ms/step - loss: 201.3094 - mae: 201.3094 - mse: 269078.3125 - val_loss: 965.1822 - val_mae: 965.1822 - val_mse: 2062625.5000 - lr: 0.0010\n",
            "Epoch 352/5000\n",
            "3/3 [==============================] - 0s 185ms/step - loss: 204.9804 - mae: 204.9804 - mse: 267578.9062 - val_loss: 1033.4470 - val_mae: 1033.4470 - val_mse: 2276111.7500 - lr: 0.0010\n",
            "Epoch 353/5000\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 191.0094 - mae: 191.0094 - mse: 252795.2500 - val_loss: 962.9841 - val_mae: 962.9841 - val_mse: 2058886.7500 - lr: 0.0010\n",
            "Epoch 354/5000\n",
            "3/3 [==============================] - 0s 179ms/step - loss: 190.8369 - mae: 190.8369 - mse: 243041.8281 - val_loss: 998.7283 - val_mae: 998.7283 - val_mse: 2174822.5000 - lr: 0.0010\n",
            "Epoch 355/5000\n",
            "3/3 [==============================] - 1s 188ms/step - loss: 185.5816 - mae: 185.5816 - mse: 242832.7500 - val_loss: 967.1310 - val_mae: 967.1310 - val_mse: 2081465.8750 - lr: 0.0010\n",
            "Epoch 356/5000\n",
            "3/3 [==============================] - 0s 162ms/step - loss: 191.4420 - mae: 191.4420 - mse: 243010.1094 - val_loss: 988.0127 - val_mae: 988.0127 - val_mse: 2142485.5000 - lr: 0.0010\n",
            "Epoch 357/5000\n",
            "3/3 [==============================] - 1s 264ms/step - loss: 190.1129 - mae: 190.1129 - mse: 249960.8281 - val_loss: 965.9706 - val_mae: 965.9706 - val_mse: 2074701.2500 - lr: 0.0010\n",
            "Epoch 358/5000\n",
            "3/3 [==============================] - 0s 148ms/step - loss: 196.4376 - mae: 196.4376 - mse: 251855.8594 - val_loss: 1001.6105 - val_mae: 1001.6105 - val_mse: 2179559.0000 - lr: 0.0010\n",
            "Epoch 359/5000\n",
            "3/3 [==============================] - 0s 203ms/step - loss: 191.2213 - mae: 191.2213 - mse: 252186.2656 - val_loss: 968.3965 - val_mae: 968.3965 - val_mse: 2079918.1250 - lr: 0.0010\n",
            "Epoch 360/5000\n",
            "3/3 [==============================] - 0s 188ms/step - loss: 200.4162 - mae: 200.4162 - mse: 258011.6250 - val_loss: 1003.9896 - val_mae: 1003.9896 - val_mse: 2185862.7500 - lr: 0.0010\n",
            "Epoch 361/5000\n",
            "3/3 [==============================] - 0s 195ms/step - loss: 195.7836 - mae: 195.7836 - mse: 260299.4062 - val_loss: 968.5943 - val_mae: 968.5943 - val_mse: 2082075.5000 - lr: 0.0010\n",
            "Epoch 362/5000\n",
            "3/3 [==============================] - 0s 207ms/step - loss: 206.9013 - mae: 206.9013 - mse: 269449.5312 - val_loss: 1021.4924 - val_mae: 1021.4924 - val_mse: 2242351.2500 - lr: 0.0010\n",
            "Epoch 363/5000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 10.2806 - mae: 10.2806 - mse: 337.4058INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 3s 2s/step - loss: 196.2276 - mae: 196.2276 - mse: 261052.4219 - val_loss: 962.1523 - val_mae: 962.1523 - val_mse: 2062020.7500 - lr: 0.0010\n",
            "Epoch 364/5000\n",
            "3/3 [==============================] - 0s 187ms/step - loss: 200.8244 - mae: 200.8244 - mse: 259770.1094 - val_loss: 1020.8936 - val_mae: 1020.8936 - val_mse: 2241828.5000 - lr: 0.0010\n",
            "Epoch 365/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 189.4776 - mae: 189.4776 - mse: 249910.3906INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 3s 1s/step - loss: 189.4776 - mae: 189.4776 - mse: 249910.3906 - val_loss: 961.3279 - val_mae: 961.3279 - val_mse: 2058566.8750 - lr: 0.0010\n",
            "Epoch 366/5000\n",
            "3/3 [==============================] - 0s 173ms/step - loss: 190.0097 - mae: 190.0097 - mse: 241235.5000 - val_loss: 996.0710 - val_mae: 996.0710 - val_mse: 2167746.5000 - lr: 0.0010\n",
            "Epoch 367/5000\n",
            "3/3 [==============================] - 0s 156ms/step - loss: 185.4047 - mae: 185.4047 - mse: 242252.3281 - val_loss: 965.6028 - val_mae: 965.6028 - val_mse: 2076865.1250 - lr: 0.0010\n",
            "Epoch 368/5000\n",
            "3/3 [==============================] - 0s 139ms/step - loss: 190.1217 - mae: 190.1217 - mse: 241174.3750 - val_loss: 983.9175 - val_mae: 983.9175 - val_mse: 2129866.7500 - lr: 0.0010\n",
            "Epoch 369/5000\n",
            "3/3 [==============================] - 0s 157ms/step - loss: 189.5529 - mae: 189.5529 - mse: 248771.5312 - val_loss: 971.6000 - val_mae: 971.6000 - val_mse: 2092858.2500 - lr: 0.0010\n",
            "Epoch 370/5000\n",
            "3/3 [==============================] - 0s 168ms/step - loss: 202.0253 - mae: 202.0253 - mse: 260620.2031 - val_loss: 998.5131 - val_mae: 998.5131 - val_mse: 2170748.0000 - lr: 0.0010\n",
            "Epoch 371/5000\n",
            "3/3 [==============================] - 0s 144ms/step - loss: 201.5042 - mae: 201.5042 - mse: 269996.4688 - val_loss: 964.2438 - val_mae: 964.2438 - val_mse: 2063006.0000 - lr: 0.0010\n",
            "Epoch 372/5000\n",
            "3/3 [==============================] - 0s 193ms/step - loss: 205.3341 - mae: 205.3341 - mse: 267583.8750 - val_loss: 1034.1766 - val_mae: 1034.1766 - val_mse: 2279735.5000 - lr: 0.0010\n",
            "Epoch 373/5000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 10.4114 - mae: 10.4114 - mse: 338.5481INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 190.5561 - mae: 190.5561 - mse: 251615.2188 - val_loss: 961.2846 - val_mae: 961.2846 - val_mse: 2055686.0000 - lr: 0.0010\n",
            "Epoch 374/5000\n",
            "3/3 [==============================] - 0s 176ms/step - loss: 190.1817 - mae: 190.1817 - mse: 241702.5938 - val_loss: 999.1622 - val_mae: 999.1622 - val_mse: 2177862.7500 - lr: 0.0010\n",
            "Epoch 375/5000\n",
            "3/3 [==============================] - 0s 144ms/step - loss: 184.3739 - mae: 184.3739 - mse: 240267.0938 - val_loss: 963.7667 - val_mae: 963.7667 - val_mse: 2069703.1250 - lr: 0.0010\n",
            "Epoch 376/5000\n",
            "3/3 [==============================] - 0s 163ms/step - loss: 185.3364 - mae: 185.3364 - mse: 234159.7031 - val_loss: 963.4680 - val_mae: 963.4680 - val_mse: 2068941.8750 - lr: 0.0010\n",
            "Epoch 377/5000\n",
            "3/3 [==============================] - 0s 192ms/step - loss: 195.4355 - mae: 195.4355 - mse: 256634.3594 - val_loss: 1005.8445 - val_mae: 1005.8445 - val_mse: 2194455.5000 - lr: 0.0010\n",
            "Epoch 378/5000\n",
            "3/3 [==============================] - 1s 295ms/step - loss: 236.0115 - mae: 236.0115 - mse: 322227.3750 - val_loss: 1051.4440 - val_mae: 1051.4440 - val_mse: 2328507.5000 - lr: 0.0010\n",
            "Epoch 379/5000\n",
            "3/3 [==============================] - 1s 219ms/step - loss: 217.4321 - mae: 217.4321 - mse: 303855.7500 - val_loss: 979.5829 - val_mae: 979.5829 - val_mse: 2067333.6250 - lr: 0.0010\n",
            "Epoch 380/5000\n",
            "3/3 [==============================] - 1s 255ms/step - loss: 197.7433 - mae: 197.7433 - mse: 255489.8594 - val_loss: 1046.7904 - val_mae: 1046.7904 - val_mse: 2319529.5000 - lr: 0.0010\n",
            "Epoch 381/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 182.3908 - mae: 182.3908 - mse: 239087.6094INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 4s 2s/step - loss: 182.3908 - mae: 182.3908 - mse: 239087.6094 - val_loss: 960.2365 - val_mae: 960.2365 - val_mse: 2053612.8750 - lr: 0.0010\n",
            "Epoch 382/5000\n",
            "3/3 [==============================] - 1s 262ms/step - loss: 179.8210 - mae: 179.8210 - mse: 227603.8125 - val_loss: 964.3345 - val_mae: 964.3345 - val_mse: 2080606.2500 - lr: 0.0010\n",
            "Epoch 383/5000\n",
            "3/3 [==============================] - 1s 279ms/step - loss: 183.3159 - mae: 183.3159 - mse: 238098.8438 - val_loss: 981.3134 - val_mae: 981.3134 - val_mse: 2130665.0000 - lr: 0.0010\n",
            "Epoch 384/5000\n",
            "3/3 [==============================] - 1s 587ms/step - loss: 197.1568 - mae: 197.1568 - mse: 250583.9688 - val_loss: 985.3929 - val_mae: 985.3929 - val_mse: 2138925.0000 - lr: 0.0010\n",
            "Epoch 385/5000\n",
            "3/3 [==============================] - 1s 339ms/step - loss: 199.8394 - mae: 199.8394 - mse: 267190.2188 - val_loss: 967.1128 - val_mae: 967.1128 - val_mse: 2084239.2500 - lr: 0.0010\n",
            "Epoch 386/5000\n",
            "3/3 [==============================] - 1s 590ms/step - loss: 212.6704 - mae: 212.6704 - mse: 279698.2188 - val_loss: 1048.0170 - val_mae: 1048.0170 - val_mse: 2323144.2500 - lr: 0.0010\n",
            "Epoch 387/5000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 10.5816 - mae: 10.5816 - mse: 341.6725INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 3s 2s/step - loss: 194.4793 - mae: 194.4793 - mse: 259190.0469 - val_loss: 960.1250 - val_mae: 960.1250 - val_mse: 2056831.3750 - lr: 0.0010\n",
            "Epoch 388/5000\n",
            "3/3 [==============================] - 0s 203ms/step - loss: 195.5771 - mae: 195.5771 - mse: 250269.0312 - val_loss: 1006.5908 - val_mae: 1006.5908 - val_mse: 2202315.2500 - lr: 0.0010\n",
            "Epoch 389/5000\n",
            "3/3 [==============================] - 1s 346ms/step - loss: 188.0228 - mae: 188.0228 - mse: 246888.0312 - val_loss: 963.4315 - val_mae: 963.4315 - val_mse: 2072204.2500 - lr: 0.0010\n",
            "Epoch 390/5000\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 193.4733 - mae: 193.4733 - mse: 246230.0156 - val_loss: 996.5903 - val_mae: 996.5903 - val_mse: 2169207.0000 - lr: 0.0010\n",
            "Epoch 391/5000\n",
            "3/3 [==============================] - 0s 219ms/step - loss: 189.7041 - mae: 189.7041 - mse: 249513.2344 - val_loss: 964.9756 - val_mae: 964.9756 - val_mse: 2075185.0000 - lr: 0.0010\n",
            "Epoch 392/5000\n",
            "3/3 [==============================] - 0s 218ms/step - loss: 196.6953 - mae: 196.6953 - mse: 251453.1719 - val_loss: 997.4453 - val_mae: 997.4453 - val_mse: 2170392.0000 - lr: 0.0010\n",
            "Epoch 393/5000\n",
            "3/3 [==============================] - 0s 103ms/step - loss: 193.2493 - mae: 193.2493 - mse: 255835.2969 - val_loss: 968.2078 - val_mae: 968.2078 - val_mse: 2085913.5000 - lr: 0.0010\n",
            "Epoch 394/5000\n",
            "3/3 [==============================] - 0s 144ms/step - loss: 205.4384 - mae: 205.4384 - mse: 266039.5938 - val_loss: 1013.9227 - val_mae: 1013.9227 - val_mse: 2222063.7500 - lr: 0.0010\n",
            "Epoch 395/5000\n",
            "3/3 [==============================] - 0s 104ms/step - loss: 197.8165 - mae: 197.8165 - mse: 263818.5625 - val_loss: 961.3527 - val_mae: 961.3527 - val_mse: 2063201.2500 - lr: 0.0010\n",
            "Epoch 396/5000\n",
            "3/3 [==============================] - 0s 165ms/step - loss: 202.7466 - mae: 202.7466 - mse: 262257.3125 - val_loss: 1024.2864 - val_mae: 1024.2864 - val_mse: 2257013.5000 - lr: 0.0010\n",
            "Epoch 397/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 190.7831 - mae: 190.7831 - mse: 252265.5781INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 3s 1s/step - loss: 190.7831 - mae: 190.7831 - mse: 252265.5781 - val_loss: 959.9899 - val_mae: 959.9899 - val_mse: 2060532.7500 - lr: 0.0010\n",
            "Epoch 398/5000\n",
            "3/3 [==============================] - 0s 116ms/step - loss: 192.2296 - mae: 192.2296 - mse: 244205.8594 - val_loss: 1002.8158 - val_mae: 1002.8158 - val_mse: 2192441.7500 - lr: 0.0010\n",
            "Epoch 399/5000\n",
            "3/3 [==============================] - 0s 117ms/step - loss: 185.4892 - mae: 185.4892 - mse: 242698.7500 - val_loss: 962.6017 - val_mae: 962.6017 - val_mse: 2068622.5000 - lr: 0.0010\n",
            "Epoch 400/5000\n",
            "3/3 [==============================] - 0s 94ms/step - loss: 188.8203 - mae: 188.8203 - mse: 238608.0781 - val_loss: 985.0031 - val_mae: 985.0031 - val_mse: 2134529.2500 - lr: 0.0010\n",
            "Epoch 401/5000\n",
            "3/3 [==============================] - 0s 109ms/step - loss: 187.7012 - mae: 187.7012 - mse: 246109.5938 - val_loss: 967.9523 - val_mae: 967.9523 - val_mse: 2082130.6250 - lr: 0.0010\n",
            "Epoch 402/5000\n",
            "3/3 [==============================] - 1s 292ms/step - loss: 196.0337 - mae: 196.0337 - mse: 250305.2812 - val_loss: 995.5408 - val_mae: 995.5408 - val_mse: 2162695.5000 - lr: 0.0010\n",
            "Epoch 403/5000\n",
            "3/3 [==============================] - 0s 108ms/step - loss: 192.7711 - mae: 192.7711 - mse: 254592.3438 - val_loss: 967.7593 - val_mae: 967.7593 - val_mse: 2083147.3750 - lr: 0.0010\n",
            "Epoch 404/5000\n",
            "3/3 [==============================] - 0s 166ms/step - loss: 204.2219 - mae: 204.2219 - mse: 264191.6562 - val_loss: 1010.5192 - val_mae: 1010.5192 - val_mse: 2212270.0000 - lr: 0.0010\n",
            "Epoch 405/5000\n",
            "3/3 [==============================] - 0s 91ms/step - loss: 197.8418 - mae: 197.8418 - mse: 263602.0312 - val_loss: 960.8900 - val_mae: 960.8900 - val_mse: 2060131.0000 - lr: 0.0010\n",
            "Epoch 406/5000\n",
            "3/3 [==============================] - 0s 130ms/step - loss: 200.8687 - mae: 200.8687 - mse: 259296.8594 - val_loss: 1021.0717 - val_mae: 1021.0717 - val_mse: 2246606.7500 - lr: 0.0010\n",
            "Epoch 407/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 189.6840 - mae: 189.6840 - mse: 249830.4844INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 3s 1s/step - loss: 189.6840 - mae: 189.6840 - mse: 249830.4844 - val_loss: 959.5031 - val_mae: 959.5031 - val_mse: 2055999.8750 - lr: 0.0010\n",
            "Epoch 408/5000\n",
            "3/3 [==============================] - 1s 273ms/step - loss: 189.7297 - mae: 189.7297 - mse: 240690.7500 - val_loss: 994.4041 - val_mae: 994.4041 - val_mse: 2167352.2500 - lr: 0.0010\n",
            "Epoch 409/5000\n",
            "3/3 [==============================] - 0s 107ms/step - loss: 184.6904 - mae: 184.6904 - mse: 240831.2812 - val_loss: 962.6552 - val_mae: 962.6552 - val_mse: 2069754.2500 - lr: 0.0010\n",
            "Epoch 410/5000\n",
            "3/3 [==============================] - 0s 94ms/step - loss: 188.3074 - mae: 188.3074 - mse: 237828.0000 - val_loss: 984.4525 - val_mae: 984.4525 - val_mse: 2133033.5000 - lr: 0.0010\n",
            "Epoch 411/5000\n",
            "3/3 [==============================] - 0s 91ms/step - loss: 187.5867 - mae: 187.5867 - mse: 245386.3594 - val_loss: 968.6447 - val_mae: 968.6447 - val_mse: 2084855.8750 - lr: 0.0010\n",
            "Epoch 412/5000\n",
            "3/3 [==============================] - 0s 116ms/step - loss: 195.9987 - mae: 195.9987 - mse: 249879.7344 - val_loss: 995.7412 - val_mae: 995.7412 - val_mse: 2164033.7500 - lr: 0.0010\n",
            "Epoch 413/5000\n",
            "3/3 [==============================] - 1s 292ms/step - loss: 193.1227 - mae: 193.1227 - mse: 254909.5469 - val_loss: 965.9482 - val_mae: 965.9482 - val_mse: 2074941.6250 - lr: 0.0010\n",
            "Epoch 414/5000\n",
            "3/3 [==============================] - 0s 116ms/step - loss: 201.7881 - mae: 201.7881 - mse: 260180.8438 - val_loss: 1009.9699 - val_mae: 1009.9699 - val_mse: 2208934.7500 - lr: 0.0010\n",
            "Epoch 415/5000\n",
            "3/3 [==============================] - 1s 189ms/step - loss: 194.4045 - mae: 194.4045 - mse: 257246.3438 - val_loss: 961.7645 - val_mae: 961.7645 - val_mse: 2060493.1250 - lr: 0.0010\n",
            "Epoch 416/5000\n",
            "3/3 [==============================] - 0s 219ms/step - loss: 198.7295 - mae: 198.7295 - mse: 255622.4844 - val_loss: 1014.2441 - val_mae: 1014.2441 - val_mse: 2221433.5000 - lr: 0.0010\n",
            "Epoch 417/5000\n",
            "3/3 [==============================] - 0s 98ms/step - loss: 188.9217 - mae: 188.9217 - mse: 248123.6875 - val_loss: 960.6700 - val_mae: 960.6700 - val_mse: 2057193.5000 - lr: 0.0010\n",
            "Epoch 418/5000\n",
            "3/3 [==============================] - 0s 112ms/step - loss: 191.0032 - mae: 191.0032 - mse: 242470.5938 - val_loss: 995.6305 - val_mae: 995.6305 - val_mse: 2164543.2500 - lr: 0.0010\n",
            "Epoch 419/5000\n",
            "3/3 [==============================] - 0s 225ms/step - loss: 186.0438 - mae: 186.0438 - mse: 242926.8125 - val_loss: 961.5939 - val_mae: 961.5939 - val_mse: 2060364.2500 - lr: 0.0010\n",
            "Epoch 420/5000\n",
            "3/3 [==============================] - 0s 110ms/step - loss: 188.7442 - mae: 188.7442 - mse: 238712.4375 - val_loss: 985.8848 - val_mae: 985.8848 - val_mse: 2133454.7500 - lr: 0.0010\n",
            "Epoch 421/5000\n",
            "3/3 [==============================] - 0s 101ms/step - loss: 187.1480 - mae: 187.1480 - mse: 244589.9375 - val_loss: 965.7958 - val_mae: 965.7958 - val_mse: 2072670.7500 - lr: 0.0010\n",
            "Epoch 422/5000\n",
            "3/3 [==============================] - 0s 154ms/step - loss: 193.9212 - mae: 193.9212 - mse: 246973.8906 - val_loss: 989.8243 - val_mae: 989.8243 - val_mse: 2142537.5000 - lr: 0.0010\n",
            "Epoch 423/5000\n",
            "3/3 [==============================] - 0s 100ms/step - loss: 193.0930 - mae: 193.0930 - mse: 254583.2812 - val_loss: 965.1322 - val_mae: 965.1322 - val_mse: 2070844.0000 - lr: 0.0010\n",
            "Epoch 424/5000\n",
            "3/3 [==============================] - 0s 211ms/step - loss: 201.6764 - mae: 201.6764 - mse: 260111.3594 - val_loss: 1007.4001 - val_mae: 1007.4001 - val_mse: 2198659.2500 - lr: 0.0010\n",
            "Epoch 425/5000\n",
            "3/3 [==============================] - 0s 164ms/step - loss: 195.2396 - mae: 195.2396 - mse: 258671.3438 - val_loss: 960.8990 - val_mae: 960.8990 - val_mse: 2056749.3750 - lr: 0.0010\n",
            "Epoch 426/5000\n",
            "3/3 [==============================] - 0s 171ms/step - loss: 198.6243 - mae: 198.6243 - mse: 255251.2500 - val_loss: 1011.3511 - val_mae: 1011.3511 - val_mse: 2212652.5000 - lr: 0.0010\n",
            "Epoch 427/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 189.9733 - mae: 189.9733 - mse: 249437.5625INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 3s 1s/step - loss: 189.9733 - mae: 189.9733 - mse: 249437.5625 - val_loss: 959.3381 - val_mae: 959.3381 - val_mse: 2053707.8750 - lr: 0.0010\n",
            "Epoch 428/5000\n",
            "3/3 [==============================] - 0s 155ms/step - loss: 191.5434 - mae: 191.5434 - mse: 243548.5938 - val_loss: 999.4582 - val_mae: 999.4582 - val_mse: 2178279.2500 - lr: 0.0010\n",
            "Epoch 429/5000\n",
            "3/3 [==============================] - 0s 110ms/step - loss: 184.9667 - mae: 184.9667 - mse: 241177.5781 - val_loss: 960.7296 - val_mae: 960.7296 - val_mse: 2061060.5000 - lr: 0.0010\n",
            "Epoch 430/5000\n",
            "3/3 [==============================] - 0s 103ms/step - loss: 187.7813 - mae: 187.7813 - mse: 236981.3906 - val_loss: 981.9866 - val_mae: 981.9866 - val_mse: 2124685.2500 - lr: 0.0010\n",
            "Epoch 431/5000\n",
            "3/3 [==============================] - 0s 96ms/step - loss: 188.0231 - mae: 188.0231 - mse: 246237.5938 - val_loss: 971.8953 - val_mae: 971.8953 - val_mse: 2095678.1250 - lr: 0.0010\n",
            "Epoch 432/5000\n",
            "3/3 [==============================] - 0s 132ms/step - loss: 200.3926 - mae: 200.3926 - mse: 257011.5000 - val_loss: 1001.2844 - val_mae: 1001.2844 - val_mse: 2180193.2500 - lr: 0.0010\n",
            "Epoch 433/5000\n",
            "3/3 [==============================] - 0s 93ms/step - loss: 197.6355 - mae: 197.6355 - mse: 263358.7500 - val_loss: 963.8469 - val_mae: 963.8469 - val_mse: 2068995.5000 - lr: 0.0010\n",
            "Epoch 434/5000\n",
            "3/3 [==============================] - 0s 153ms/step - loss: 205.6422 - mae: 205.6422 - mse: 267387.1250 - val_loss: 1021.9499 - val_mae: 1021.9499 - val_mse: 2245530.2500 - lr: 0.0010\n",
            "Epoch 435/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 193.5909 - mae: 193.5909 - mse: 256521.2812INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 3s 1s/step - loss: 193.5909 - mae: 193.5909 - mse: 256521.2812 - val_loss: 959.2599 - val_mae: 959.2599 - val_mse: 2052962.1250 - lr: 0.0010\n",
            "Epoch 436/5000\n",
            "3/3 [==============================] - 1s 336ms/step - loss: 194.1394 - mae: 194.1394 - mse: 248095.4375 - val_loss: 1008.6835 - val_mae: 1008.6835 - val_mse: 2208840.5000 - lr: 0.0010\n",
            "Epoch 437/5000\n",
            "3/3 [==============================] - 0s 166ms/step - loss: 185.2173 - mae: 185.2173 - mse: 242031.4062 - val_loss: 959.4640 - val_mae: 959.4640 - val_mse: 2057276.2500 - lr: 0.0010\n",
            "Epoch 438/5000\n",
            "3/3 [==============================] - 1s 174ms/step - loss: 186.1161 - mae: 186.1161 - mse: 234337.8594 - val_loss: 983.5024 - val_mae: 983.5024 - val_mse: 2133174.5000 - lr: 0.0010\n",
            "Epoch 439/5000\n",
            "3/3 [==============================] - 0s 168ms/step - loss: 184.5972 - mae: 184.5972 - mse: 240184.9844 - val_loss: 964.1440 - val_mae: 964.1440 - val_mse: 2074831.2500 - lr: 0.0010\n",
            "Epoch 440/5000\n",
            "3/3 [==============================] - 0s 189ms/step - loss: 189.8678 - mae: 189.8678 - mse: 239983.4844 - val_loss: 985.5351 - val_mae: 985.5351 - val_mse: 2134500.2500 - lr: 0.0010\n",
            "Epoch 441/5000\n",
            "3/3 [==============================] - 0s 97ms/step - loss: 188.5418 - mae: 188.5418 - mse: 247265.6094 - val_loss: 969.6821 - val_mae: 969.6821 - val_mse: 2085498.2500 - lr: 0.0010\n",
            "Epoch 442/5000\n",
            "3/3 [==============================] - 0s 108ms/step - loss: 199.0764 - mae: 199.0764 - mse: 254850.6562 - val_loss: 1000.0718 - val_mae: 1000.0718 - val_mse: 2174024.0000 - lr: 0.0010\n",
            "Epoch 443/5000\n",
            "3/3 [==============================] - 0s 104ms/step - loss: 195.4939 - mae: 195.4939 - mse: 258985.3594 - val_loss: 964.4306 - val_mae: 964.4306 - val_mse: 2067601.6250 - lr: 0.0010\n",
            "Epoch 444/5000\n",
            "3/3 [==============================] - 0s 98ms/step - loss: 203.1091 - mae: 203.1091 - mse: 262650.8438 - val_loss: 1012.3266 - val_mae: 1012.3266 - val_mse: 2215732.0000 - lr: 0.0010\n",
            "Epoch 445/5000\n",
            "3/3 [==============================] - 0s 171ms/step - loss: 195.1113 - mae: 195.1113 - mse: 258357.6875 - val_loss: 959.4641 - val_mae: 959.4641 - val_mse: 2050848.3750 - lr: 0.0010\n",
            "Epoch 446/5000\n",
            "3/3 [==============================] - 0s 169ms/step - loss: 194.9101 - mae: 194.9101 - mse: 249096.2812 - val_loss: 1006.7452 - val_mae: 1006.7452 - val_mse: 2202787.7500 - lr: 0.0010\n",
            "Epoch 447/5000\n",
            "3/3 [==============================] - 0s 97ms/step - loss: 187.5575 - mae: 187.5575 - mse: 245905.9219 - val_loss: 959.9068 - val_mae: 959.9068 - val_mse: 2059671.3750 - lr: 0.0010\n",
            "Epoch 448/5000\n",
            "3/3 [==============================] - 0s 158ms/step - loss: 189.4409 - mae: 189.4409 - mse: 239401.8125 - val_loss: 995.0134 - val_mae: 995.0134 - val_mse: 2167762.0000 - lr: 0.0010\n",
            "Epoch 449/5000\n",
            "3/3 [==============================] - 0s 160ms/step - loss: 184.1080 - mae: 184.1080 - mse: 239750.2500 - val_loss: 961.4869 - val_mae: 961.4869 - val_mse: 2064532.0000 - lr: 0.0010\n",
            "Epoch 450/5000\n",
            "3/3 [==============================] - 0s 157ms/step - loss: 187.4245 - mae: 187.4245 - mse: 236391.1562 - val_loss: 981.0000 - val_mae: 981.0000 - val_mse: 2122141.5000 - lr: 0.0010\n",
            "Epoch 451/5000\n",
            "3/3 [==============================] - 0s 115ms/step - loss: 187.4276 - mae: 187.4276 - mse: 245176.3750 - val_loss: 969.9905 - val_mae: 969.9905 - val_mse: 2086882.0000 - lr: 0.0010\n",
            "Epoch 452/5000\n",
            "3/3 [==============================] - 0s 158ms/step - loss: 197.2655 - mae: 197.2655 - mse: 251512.3438 - val_loss: 995.5346 - val_mae: 995.5346 - val_mse: 2161833.2500 - lr: 0.0010\n",
            "Epoch 453/5000\n",
            "3/3 [==============================] - 0s 131ms/step - loss: 194.8635 - mae: 194.8635 - mse: 257876.7969 - val_loss: 964.3063 - val_mae: 964.3063 - val_mse: 2069315.6250 - lr: 0.0010\n",
            "Epoch 454/5000\n",
            "3/3 [==============================] - 0s 113ms/step - loss: 202.7433 - mae: 202.7433 - mse: 261717.3750 - val_loss: 1012.2078 - val_mae: 1012.2078 - val_mse: 2216212.2500 - lr: 0.0010\n",
            "Epoch 455/5000\n",
            "3/3 [==============================] - 0s 97ms/step - loss: 194.6989 - mae: 194.6989 - mse: 257730.1719 - val_loss: 959.5563 - val_mae: 959.5563 - val_mse: 2052150.7500 - lr: 0.0010\n",
            "Epoch 456/5000\n",
            "3/3 [==============================] - 0s 215ms/step - loss: 195.3580 - mae: 195.3580 - mse: 249714.6406 - val_loss: 1010.2295 - val_mae: 1010.2295 - val_mse: 2212527.7500 - lr: 0.0010\n",
            "Epoch 457/5000\n",
            "3/3 [==============================] - 0s 185ms/step - loss: 186.7209 - mae: 186.7209 - mse: 244355.0000 - val_loss: 959.7803 - val_mae: 959.7803 - val_mse: 2058494.5000 - lr: 0.0010\n",
            "Epoch 458/5000\n",
            "3/3 [==============================] - 0s 98ms/step - loss: 188.7496 - mae: 188.7496 - mse: 238322.2969 - val_loss: 989.4399 - val_mae: 989.4399 - val_mse: 2150243.0000 - lr: 0.0010\n",
            "Epoch 459/5000\n",
            "3/3 [==============================] - 0s 125ms/step - loss: 185.1435 - mae: 185.1435 - mse: 241099.4062 - val_loss: 961.6701 - val_mae: 961.6701 - val_mse: 2064671.7500 - lr: 0.0010\n",
            "Epoch 460/5000\n",
            "3/3 [==============================] - 0s 133ms/step - loss: 188.9096 - mae: 188.9096 - mse: 238608.5156 - val_loss: 989.2026 - val_mae: 989.2026 - val_mse: 2144525.7500 - lr: 0.0010\n",
            "Epoch 461/5000\n",
            "3/3 [==============================] - 0s 105ms/step - loss: 186.0393 - mae: 186.0393 - mse: 243036.6250 - val_loss: 967.3076 - val_mae: 967.3076 - val_mse: 2077891.0000 - lr: 0.0010\n",
            "Epoch 462/5000\n",
            "3/3 [==============================] - 0s 182ms/step - loss: 193.6010 - mae: 193.6010 - mse: 245531.7969 - val_loss: 987.7944 - val_mae: 987.7944 - val_mse: 2138429.7500 - lr: 0.0010\n",
            "Epoch 463/5000\n",
            "3/3 [==============================] - 0s 130ms/step - loss: 193.1611 - mae: 193.1611 - mse: 254591.9531 - val_loss: 967.0270 - val_mae: 967.0270 - val_mse: 2080727.8750 - lr: 0.0010\n",
            "Epoch 464/5000\n",
            "3/3 [==============================] - 0s 111ms/step - loss: 205.4721 - mae: 205.4721 - mse: 265845.5000 - val_loss: 1014.5070 - val_mae: 1014.5070 - val_mse: 2222689.7500 - lr: 0.0010\n",
            "Epoch 465/5000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 10.0899 - mae: 10.0899 - mse: 321.8211INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 196.6788 - mae: 196.6788 - mse: 261211.8750 - val_loss: 959.0248 - val_mae: 959.0248 - val_mse: 2050795.1250 - lr: 0.0010\n",
            "Epoch 466/5000\n",
            "3/3 [==============================] - 0s 106ms/step - loss: 197.5066 - mae: 197.5066 - mse: 253208.3438 - val_loss: 1020.3809 - val_mae: 1020.3809 - val_mse: 2243225.0000 - lr: 0.0010\n",
            "Epoch 467/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 185.8771 - mae: 185.8771 - mse: 242967.5781INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 185.8771 - mae: 185.8771 - mse: 242967.5781 - val_loss: 958.8824 - val_mae: 958.8824 - val_mse: 2054218.5000 - lr: 0.0010\n",
            "Epoch 468/5000\n",
            "3/3 [==============================] - 0s 103ms/step - loss: 186.8270 - mae: 186.8270 - mse: 235284.1875 - val_loss: 985.1729 - val_mae: 985.1729 - val_mse: 2137581.2500 - lr: 0.0010\n",
            "Epoch 469/5000\n",
            "3/3 [==============================] - 0s 108ms/step - loss: 184.4503 - mae: 184.4503 - mse: 239873.8906 - val_loss: 962.8237 - val_mae: 962.8237 - val_mse: 2068854.7500 - lr: 0.0010\n",
            "Epoch 470/5000\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 189.0435 - mae: 189.0435 - mse: 238513.1250 - val_loss: 987.4333 - val_mae: 987.4333 - val_mse: 2138982.5000 - lr: 0.0010\n",
            "Epoch 471/5000\n",
            "3/3 [==============================] - 0s 92ms/step - loss: 186.6428 - mae: 186.6428 - mse: 244110.8125 - val_loss: 967.3683 - val_mae: 967.3683 - val_mse: 2077058.5000 - lr: 0.0010\n",
            "Epoch 472/5000\n",
            "3/3 [==============================] - 0s 124ms/step - loss: 194.3009 - mae: 194.3009 - mse: 246566.4531 - val_loss: 991.8860 - val_mae: 991.8860 - val_mse: 2149279.2500 - lr: 0.0010\n",
            "Epoch 473/5000\n",
            "3/3 [==============================] - 0s 138ms/step - loss: 192.7912 - mae: 192.7912 - mse: 254275.0781 - val_loss: 967.0894 - val_mae: 967.0894 - val_mse: 2079162.5000 - lr: 0.0010\n",
            "Epoch 474/5000\n",
            "3/3 [==============================] - 0s 168ms/step - loss: 204.5906 - mae: 204.5906 - mse: 264308.4688 - val_loss: 1011.4451 - val_mae: 1011.4451 - val_mse: 2212782.7500 - lr: 0.0010\n",
            "Epoch 475/5000\n",
            "3/3 [==============================] - 0s 141ms/step - loss: 196.5291 - mae: 196.5291 - mse: 260625.8750 - val_loss: 959.0055 - val_mae: 959.0055 - val_mse: 2053258.5000 - lr: 0.0010\n",
            "Epoch 476/5000\n",
            "3/3 [==============================] - 0s 144ms/step - loss: 199.9284 - mae: 199.9284 - mse: 257276.5625 - val_loss: 1025.1859 - val_mae: 1025.1859 - val_mse: 2257753.0000 - lr: 0.0010\n",
            "Epoch 477/5000\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 10.1754 - mae: 10.1754 - mse: 326.9278INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 187.1187 - mae: 187.1187 - mse: 245134.5000 - val_loss: 957.7851 - val_mae: 957.7851 - val_mse: 2048794.7500 - lr: 0.0010\n",
            "Epoch 478/5000\n",
            "3/3 [==============================] - 0s 152ms/step - loss: 186.4815 - mae: 186.4815 - mse: 234930.7969 - val_loss: 987.8571 - val_mae: 987.8571 - val_mse: 2148593.0000 - lr: 0.0010\n",
            "Epoch 479/5000\n",
            "3/3 [==============================] - 0s 127ms/step - loss: 182.6321 - mae: 182.6321 - mse: 236875.5781 - val_loss: 961.3476 - val_mae: 961.3476 - val_mse: 2068176.1250 - lr: 0.0010\n",
            "Epoch 480/5000\n",
            "3/3 [==============================] - 0s 105ms/step - loss: 186.3738 - mae: 186.3738 - mse: 234292.2500 - val_loss: 976.7861 - val_mae: 976.7861 - val_mse: 2113221.7500 - lr: 0.0010\n",
            "Epoch 481/5000\n",
            "3/3 [==============================] - 1s 257ms/step - loss: 187.2589 - mae: 187.2589 - mse: 243947.0312 - val_loss: 970.1110 - val_mae: 970.1110 - val_mse: 2090628.5000 - lr: 0.0010\n",
            "Epoch 482/5000\n",
            "3/3 [==============================] - 0s 197ms/step - loss: 199.6792 - mae: 199.6792 - mse: 255138.8438 - val_loss: 995.0991 - val_mae: 995.0991 - val_mse: 2163013.2500 - lr: 0.0010\n",
            "Epoch 483/5000\n",
            "3/3 [==============================] - 1s 178ms/step - loss: 196.3195 - mae: 196.3195 - mse: 260119.3750 - val_loss: 961.9382 - val_mae: 961.9382 - val_mse: 2061440.7500 - lr: 0.0010\n",
            "Epoch 484/5000\n",
            "3/3 [==============================] - 0s 134ms/step - loss: 202.0974 - mae: 202.0974 - mse: 260144.5781 - val_loss: 1019.6591 - val_mae: 1019.6591 - val_mse: 2238766.7500 - lr: 0.0010\n",
            "Epoch 485/5000\n",
            "3/3 [==============================] - 1s 266ms/step - loss: 190.7397 - mae: 190.7397 - mse: 251275.8594 - val_loss: 959.4916 - val_mae: 959.4916 - val_mse: 2057571.3750 - lr: 0.0010\n",
            "Epoch 486/5000\n",
            "3/3 [==============================] - 0s 100ms/step - loss: 194.4867 - mae: 194.4867 - mse: 247285.1562 - val_loss: 1001.7543 - val_mae: 1001.7543 - val_mse: 2187485.7500 - lr: 0.0010\n",
            "Epoch 487/5000\n",
            "3/3 [==============================] - 0s 109ms/step - loss: 188.0663 - mae: 188.0663 - mse: 246199.2656 - val_loss: 958.7991 - val_mae: 958.7991 - val_mse: 2056625.6250 - lr: 0.0010\n",
            "Epoch 488/5000\n",
            "3/3 [==============================] - 1s 229ms/step - loss: 190.7826 - mae: 190.7826 - mse: 241071.2656 - val_loss: 994.8936 - val_mae: 994.8936 - val_mse: 2163811.7500 - lr: 0.0010\n",
            "Epoch 489/5000\n",
            "3/3 [==============================] - 0s 161ms/step - loss: 185.9689 - mae: 185.9689 - mse: 242984.2969 - val_loss: 960.8729 - val_mae: 960.8729 - val_mse: 2059441.7500 - lr: 0.0010\n",
            "Epoch 490/5000\n",
            "3/3 [==============================] - 0s 156ms/step - loss: 188.7479 - mae: 188.7479 - mse: 237614.8125 - val_loss: 991.5943 - val_mae: 991.5943 - val_mse: 2152010.0000 - lr: 0.0010\n",
            "Epoch 491/5000\n",
            "3/3 [==============================] - 0s 105ms/step - loss: 184.5000 - mae: 184.5000 - mse: 240543.8125 - val_loss: 965.5410 - val_mae: 965.5410 - val_mse: 2076311.2500 - lr: 0.0010\n",
            "Epoch 492/5000\n",
            "3/3 [==============================] - 0s 106ms/step - loss: 191.9200 - mae: 191.9200 - mse: 242375.9844 - val_loss: 987.2793 - val_mae: 987.2793 - val_mse: 2138753.2500 - lr: 0.0010\n",
            "Epoch 493/5000\n",
            "3/3 [==============================] - 0s 119ms/step - loss: 190.9383 - mae: 190.9383 - mse: 251006.5938 - val_loss: 963.2004 - val_mae: 963.2004 - val_mse: 2067571.6250 - lr: 0.0010\n",
            "Epoch 494/5000\n",
            "3/3 [==============================] - 0s 94ms/step - loss: 197.1787 - mae: 197.1787 - mse: 251119.7344 - val_loss: 1009.4166 - val_mae: 1009.4166 - val_mse: 2206841.0000 - lr: 0.0010\n",
            "Epoch 495/5000\n",
            "3/3 [==============================] - 1s 263ms/step - loss: 188.3453 - mae: 188.3453 - mse: 247024.0938 - val_loss: 960.1403 - val_mae: 960.1403 - val_mse: 2056999.7500 - lr: 0.0010\n",
            "Epoch 496/5000\n",
            "3/3 [==============================] - 0s 96ms/step - loss: 191.5255 - mae: 191.5255 - mse: 242467.4688 - val_loss: 997.7092 - val_mae: 997.7092 - val_mse: 2172583.7500 - lr: 0.0010\n",
            "Epoch 497/5000\n",
            "3/3 [==============================] - 0s 99ms/step - loss: 185.2762 - mae: 185.2762 - mse: 241228.5156 - val_loss: 959.9321 - val_mae: 959.9321 - val_mse: 2056077.7500 - lr: 0.0010\n",
            "Epoch 498/5000\n",
            "3/3 [==============================] - 0s 183ms/step - loss: 187.5534 - mae: 187.5534 - mse: 236293.3438 - val_loss: 986.9523 - val_mae: 986.9523 - val_mse: 2138546.7500 - lr: 0.0010\n",
            "Epoch 499/5000\n",
            "3/3 [==============================] - 0s 92ms/step - loss: 184.6529 - mae: 184.6529 - mse: 240262.6094 - val_loss: 966.5402 - val_mae: 966.5402 - val_mse: 2078648.3750 - lr: 0.0010\n",
            "Epoch 500/5000\n",
            "3/3 [==============================] - 0s 188ms/step - loss: 192.5341 - mae: 192.5341 - mse: 243206.3125 - val_loss: 983.4447 - val_mae: 983.4447 - val_mse: 2127211.0000 - lr: 0.0010\n",
            "Epoch 501/5000\n",
            "3/3 [==============================] - 1s 226ms/step - loss: 194.5828 - mae: 194.5828 - mse: 257118.4062 - val_loss: 964.0682 - val_mae: 964.0682 - val_mse: 2070267.1250 - lr: 0.0010\n",
            "Epoch 502/5000\n",
            "3/3 [==============================] - 0s 198ms/step - loss: 202.6019 - mae: 202.6019 - mse: 260294.3125 - val_loss: 1019.9352 - val_mae: 1019.9352 - val_mse: 2236911.0000 - lr: 0.0010\n",
            "Epoch 503/5000\n",
            "3/3 [==============================] - 1s 203ms/step - loss: 192.9801 - mae: 192.9801 - mse: 256402.3281 - val_loss: 960.5198 - val_mae: 960.5198 - val_mse: 2055334.5000 - lr: 0.0010\n",
            "Epoch 504/5000\n",
            "3/3 [==============================] - 0s 187ms/step - loss: 195.1285 - mae: 195.1285 - mse: 248807.1094 - val_loss: 1005.1224 - val_mae: 1005.1224 - val_mse: 2192171.7500 - lr: 0.0010\n",
            "Epoch 505/5000\n",
            "3/3 [==============================] - 0s 182ms/step - loss: 186.8246 - mae: 186.8246 - mse: 244378.5625 - val_loss: 958.5215 - val_mae: 958.5215 - val_mse: 2050281.0000 - lr: 0.0010\n",
            "Epoch 506/5000\n",
            "3/3 [==============================] - 0s 110ms/step - loss: 189.8005 - mae: 189.8005 - mse: 240028.5781 - val_loss: 994.1992 - val_mae: 994.1992 - val_mse: 2158412.5000 - lr: 0.0010\n",
            "Epoch 507/5000\n",
            "3/3 [==============================] - 1s 274ms/step - loss: 183.5934 - mae: 183.5934 - mse: 238918.1719 - val_loss: 961.2059 - val_mae: 961.2059 - val_mse: 2060047.2500 - lr: 0.0010\n",
            "Epoch 508/5000\n",
            "3/3 [==============================] - 0s 102ms/step - loss: 187.4011 - mae: 187.4011 - mse: 235268.2656 - val_loss: 984.8918 - val_mae: 984.8918 - val_mse: 2130260.2500 - lr: 0.0010\n",
            "Epoch 509/5000\n",
            "3/3 [==============================] - 0s 109ms/step - loss: 186.2621 - mae: 186.2621 - mse: 243061.6875 - val_loss: 966.4338 - val_mae: 966.4338 - val_mse: 2077919.1250 - lr: 0.0010\n",
            "Epoch 510/5000\n",
            "3/3 [==============================] - 0s 135ms/step - loss: 193.8582 - mae: 193.8582 - mse: 245246.7969 - val_loss: 990.9475 - val_mae: 990.9475 - val_mse: 2149770.7500 - lr: 0.0010\n",
            "Epoch 511/5000\n",
            "3/3 [==============================] - 0s 94ms/step - loss: 191.9211 - mae: 191.9211 - mse: 252215.8594 - val_loss: 962.7212 - val_mae: 962.7212 - val_mse: 2068211.2500 - lr: 0.0010\n",
            "Epoch 512/5000\n",
            "3/3 [==============================] - 0s 98ms/step - loss: 200.4130 - mae: 200.4130 - mse: 256902.4375 - val_loss: 1005.6341 - val_mae: 1005.6341 - val_mse: 2196263.0000 - lr: 0.0010\n",
            "Epoch 513/5000\n",
            "3/3 [==============================] - 0s 188ms/step - loss: 193.3005 - mae: 193.3005 - mse: 254844.1562 - val_loss: 959.3075 - val_mae: 959.3075 - val_mse: 2051192.5000 - lr: 0.0010\n",
            "Epoch 514/5000\n",
            "3/3 [==============================] - 0s 92ms/step - loss: 195.3324 - mae: 195.3324 - mse: 248631.4531 - val_loss: 1010.9344 - val_mae: 1010.9344 - val_mse: 2211108.0000 - lr: 0.0010\n",
            "Epoch 515/5000\n",
            "3/3 [==============================] - 0s 99ms/step - loss: 186.0577 - mae: 186.0577 - mse: 242987.2500 - val_loss: 960.3925 - val_mae: 960.3925 - val_mse: 2058769.8750 - lr: 0.0010\n",
            "Epoch 516/5000\n",
            "3/3 [==============================] - 0s 134ms/step - loss: 190.2170 - mae: 190.2170 - mse: 239917.7188 - val_loss: 989.1558 - val_mae: 989.1558 - val_mse: 2145462.5000 - lr: 0.0010\n",
            "Epoch 517/5000\n",
            "3/3 [==============================] - 0s 93ms/step - loss: 187.0123 - mae: 187.0123 - mse: 244047.7188 - val_loss: 964.6007 - val_mae: 964.6007 - val_mse: 2074499.8750 - lr: 0.0010\n",
            "Epoch 518/5000\n",
            "3/3 [==============================] - 0s 102ms/step - loss: 195.9719 - mae: 195.9719 - mse: 248938.2031 - val_loss: 996.9955 - val_mae: 996.9955 - val_mse: 2168845.5000 - lr: 0.0010\n",
            "Epoch 519/5000\n",
            "3/3 [==============================] - 0s 223ms/step - loss: 191.1615 - mae: 191.1615 - mse: 251174.4062 - val_loss: 959.9974 - val_mae: 959.9974 - val_mse: 2055135.2500 - lr: 0.0010\n",
            "Epoch 520/5000\n",
            "3/3 [==============================] - 0s 108ms/step - loss: 194.4718 - mae: 194.4718 - mse: 247009.4375 - val_loss: 1002.3247 - val_mae: 1002.3247 - val_mse: 2185294.0000 - lr: 0.0010\n",
            "Epoch 521/5000\n",
            "3/3 [==============================] - 0s 136ms/step - loss: 187.6586 - mae: 187.6586 - mse: 245387.7500 - val_loss: 959.7440 - val_mae: 959.7440 - val_mse: 2056127.5000 - lr: 0.0010\n",
            "Epoch 522/5000\n",
            "3/3 [==============================] - 0s 113ms/step - loss: 191.5815 - mae: 191.5815 - mse: 242198.4219 - val_loss: 996.7316 - val_mae: 996.7316 - val_mse: 2168529.7500 - lr: 0.0010\n",
            "Epoch 523/5000\n",
            "3/3 [==============================] - 0s 174ms/step - loss: 185.8733 - mae: 185.8733 - mse: 242537.0938 - val_loss: 962.1162 - val_mae: 962.1162 - val_mse: 2065537.3750 - lr: 0.0010\n",
            "Epoch 524/5000\n",
            "3/3 [==============================] - 1s 258ms/step - loss: 191.9140 - mae: 191.9140 - mse: 242431.1719 - val_loss: 989.8247 - val_mae: 989.8247 - val_mse: 2147229.5000 - lr: 0.0010\n",
            "Epoch 525/5000\n",
            "3/3 [==============================] - 0s 107ms/step - loss: 189.4309 - mae: 189.4309 - mse: 247929.0000 - val_loss: 961.2665 - val_mae: 961.2665 - val_mse: 2062333.5000 - lr: 0.0010\n",
            "Epoch 526/5000\n",
            "3/3 [==============================] - 0s 176ms/step - loss: 195.2416 - mae: 195.2416 - mse: 247793.6094 - val_loss: 998.9099 - val_mae: 998.9099 - val_mse: 2175813.7500 - lr: 0.0010\n",
            "Epoch 527/5000\n",
            "3/3 [==============================] - 0s 94ms/step - loss: 189.7421 - mae: 189.7421 - mse: 248948.6250 - val_loss: 959.6973 - val_mae: 959.6973 - val_mse: 2056039.6250 - lr: 0.0010\n",
            "Epoch 528/5000\n",
            "3/3 [==============================] - 0s 123ms/step - loss: 193.3921 - mae: 193.3921 - mse: 245087.1094 - val_loss: 999.4206 - val_mae: 999.4206 - val_mse: 2177405.7500 - lr: 0.0010\n",
            "Epoch 529/5000\n",
            "3/3 [==============================] - 0s 126ms/step - loss: 187.3062 - mae: 187.3062 - mse: 244855.8438 - val_loss: 959.9631 - val_mae: 959.9631 - val_mse: 2057531.8750 - lr: 0.0010\n",
            "Epoch 530/5000\n",
            "3/3 [==============================] - 0s 105ms/step - loss: 191.5211 - mae: 191.5211 - mse: 241973.2656 - val_loss: 997.0266 - val_mae: 997.0266 - val_mse: 2168794.5000 - lr: 0.0010\n",
            "Epoch 531/5000\n",
            "3/3 [==============================] - 0s 92ms/step - loss: 185.8240 - mae: 185.8240 - mse: 242520.3906 - val_loss: 962.5549 - val_mae: 962.5549 - val_mse: 2066965.8750 - lr: 0.0010\n",
            "Epoch 532/5000\n",
            "3/3 [==============================] - 0s 112ms/step - loss: 192.4526 - mae: 192.4526 - mse: 243144.4688 - val_loss: 988.1870 - val_mae: 988.1870 - val_mse: 2142704.0000 - lr: 0.0010\n",
            "Epoch 533/5000\n",
            "3/3 [==============================] - 0s 114ms/step - loss: 190.7108 - mae: 190.7108 - mse: 250175.9219 - val_loss: 961.0724 - val_mae: 961.0724 - val_mse: 2062686.8750 - lr: 0.0010\n",
            "Epoch 534/5000\n",
            "3/3 [==============================] - 0s 120ms/step - loss: 197.2343 - mae: 197.2343 - mse: 251334.7031 - val_loss: 1007.1111 - val_mae: 1007.1111 - val_mse: 2200798.2500 - lr: 0.0010\n",
            "Epoch 535/5000\n",
            "3/3 [==============================] - 0s 102ms/step - loss: 188.9588 - mae: 188.9588 - mse: 247649.7812 - val_loss: 958.4876 - val_mae: 958.4876 - val_mse: 2051569.8750 - lr: 0.0010\n",
            "Epoch 536/5000\n",
            "3/3 [==============================] - 0s 111ms/step - loss: 191.7327 - mae: 191.7327 - mse: 242575.1562 - val_loss: 1001.7036 - val_mae: 1001.7036 - val_mse: 2185226.7500 - lr: 0.0010\n",
            "Epoch 537/5000\n",
            "3/3 [==============================] - 0s 94ms/step - loss: 184.3715 - mae: 184.3715 - mse: 240118.5000 - val_loss: 958.6586 - val_mae: 958.6586 - val_mse: 2049168.2500 - lr: 0.0010\n",
            "Epoch 538/5000\n",
            "3/3 [==============================] - 0s 116ms/step - loss: 185.1593 - mae: 185.1593 - mse: 231984.2344 - val_loss: 981.2776 - val_mae: 981.2776 - val_mse: 2121050.0000 - lr: 0.0010\n",
            "Epoch 539/5000\n",
            "3/3 [==============================] - 0s 111ms/step - loss: 183.5252 - mae: 183.5252 - mse: 238215.7969 - val_loss: 964.7115 - val_mae: 964.7115 - val_mse: 2070214.6250 - lr: 0.0010\n",
            "Epoch 540/5000\n",
            "3/3 [==============================] - 0s 113ms/step - loss: 190.0498 - mae: 190.0498 - mse: 239214.7344 - val_loss: 987.6033 - val_mae: 987.6033 - val_mse: 2135852.7500 - lr: 0.0010\n",
            "Epoch 541/5000\n",
            "3/3 [==============================] - 0s 104ms/step - loss: 188.0795 - mae: 188.0795 - mse: 245727.3750 - val_loss: 964.7971 - val_mae: 964.7971 - val_mse: 2069285.7500 - lr: 0.0010\n",
            "Epoch 542/5000\n",
            "3/3 [==============================] - 0s 102ms/step - loss: 195.8854 - mae: 195.8854 - mse: 248741.2969 - val_loss: 997.2524 - val_mae: 997.2524 - val_mse: 2167295.7500 - lr: 0.0010\n",
            "Epoch 543/5000\n",
            "3/3 [==============================] - 0s 155ms/step - loss: 190.3431 - mae: 190.3431 - mse: 249584.3125 - val_loss: 960.3059 - val_mae: 960.3059 - val_mse: 2057204.0000 - lr: 0.0010\n",
            "Epoch 544/5000\n",
            "3/3 [==============================] - 0s 93ms/step - loss: 195.4833 - mae: 195.4833 - mse: 248169.6562 - val_loss: 999.7195 - val_mae: 999.7195 - val_mse: 2178290.0000 - lr: 0.0010\n",
            "Epoch 545/5000\n",
            "3/3 [==============================] - 0s 102ms/step - loss: 189.9883 - mae: 189.9883 - mse: 249646.5938 - val_loss: 959.5234 - val_mae: 959.5234 - val_mse: 2053475.5000 - lr: 0.0010\n",
            "Epoch 546/5000\n",
            "3/3 [==============================] - 1s 201ms/step - loss: 191.7596 - mae: 191.7596 - mse: 241956.6094 - val_loss: 1004.3642 - val_mae: 1004.3642 - val_mse: 2191962.7500 - lr: 0.0010\n",
            "Epoch 547/5000\n",
            "3/3 [==============================] - 0s 110ms/step - loss: 184.0136 - mae: 184.0136 - mse: 239361.2812 - val_loss: 958.5737 - val_mae: 958.5737 - val_mse: 2048233.1250 - lr: 0.0010\n",
            "Epoch 548/5000\n",
            "3/3 [==============================] - 0s 179ms/step - loss: 184.8152 - mae: 184.8152 - mse: 231917.2031 - val_loss: 976.6066 - val_mae: 976.6066 - val_mse: 2107160.2500 - lr: 0.0010\n",
            "Epoch 549/5000\n",
            "3/3 [==============================] - 0s 163ms/step - loss: 184.3933 - mae: 184.3933 - mse: 239811.7969 - val_loss: 965.8566 - val_mae: 965.8566 - val_mse: 2076168.8750 - lr: 0.0010\n",
            "Epoch 550/5000\n",
            "3/3 [==============================] - 0s 218ms/step - loss: 193.1067 - mae: 193.1067 - mse: 244019.5781 - val_loss: 983.7563 - val_mae: 983.7563 - val_mse: 2128222.7500 - lr: 0.0010\n",
            "Epoch 551/5000\n",
            "3/3 [==============================] - 0s 158ms/step - loss: 192.8617 - mae: 192.8617 - mse: 253204.1406 - val_loss: 962.3859 - val_mae: 962.3859 - val_mse: 2065823.1250 - lr: 0.0010\n",
            "Epoch 552/5000\n",
            "3/3 [==============================] - 0s 103ms/step - loss: 202.2048 - mae: 202.2048 - mse: 259300.1562 - val_loss: 1015.3882 - val_mae: 1015.3882 - val_mse: 2223733.5000 - lr: 0.0010\n",
            "Epoch 553/5000\n",
            "3/3 [==============================] - 0s 126ms/step - loss: 191.9338 - mae: 191.9338 - mse: 252677.0156 - val_loss: 958.0612 - val_mae: 958.0612 - val_mse: 2042753.5000 - lr: 0.0010\n",
            "Epoch 554/5000\n",
            "3/3 [==============================] - 0s 217ms/step - loss: 191.2178 - mae: 191.2178 - mse: 242142.0938 - val_loss: 1008.1298 - val_mae: 1008.1298 - val_mse: 2203015.0000 - lr: 0.0010\n",
            "Epoch 555/5000\n",
            "3/3 [==============================] - 0s 97ms/step - loss: 181.6992 - mae: 181.6992 - mse: 235323.6406 - val_loss: 958.6014 - val_mae: 958.6014 - val_mse: 2049316.0000 - lr: 0.0010\n",
            "Epoch 556/5000\n",
            "3/3 [==============================] - 0s 149ms/step - loss: 182.2504 - mae: 182.2504 - mse: 227590.5625 - val_loss: 970.0391 - val_mae: 970.0391 - val_mse: 2089159.1250 - lr: 0.0010\n",
            "Epoch 557/5000\n",
            "3/3 [==============================] - 1s 200ms/step - loss: 184.9475 - mae: 184.9475 - mse: 239937.0000 - val_loss: 972.0500 - val_mae: 972.0500 - val_mse: 2094084.5000 - lr: 0.0010\n",
            "Epoch 558/5000\n",
            "3/3 [==============================] - 0s 119ms/step - loss: 197.7879 - mae: 197.7879 - mse: 250827.7656 - val_loss: 990.9640 - val_mae: 990.9640 - val_mse: 2148622.2500 - lr: 0.0010\n",
            "Epoch 559/5000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 0s 166ms/step - loss: 196.8452 - mae: 196.8452 - mse: 260759.4375 - val_loss: 960.7230 - val_mae: 960.7230 - val_mse: 2058650.1250 - lr: 0.0010\n",
            "Epoch 560/5000\n",
            "3/3 [==============================] - 0s 100ms/step - loss: 204.0379 - mae: 204.0379 - mse: 262438.3125 - val_loss: 1027.6041 - val_mae: 1027.6041 - val_mse: 2262121.2500 - lr: 0.0010\n",
            "Epoch 561/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 190.0650 - mae: 190.0650 - mse: 249806.1875INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 190.0650 - mae: 190.0650 - mse: 249806.1875 - val_loss: 957.3707 - val_mae: 957.3707 - val_mse: 2042474.2500 - lr: 0.0010\n",
            "Epoch 562/5000\n",
            "3/3 [==============================] - 0s 133ms/step - loss: 189.0464 - mae: 189.0464 - mse: 238259.7188 - val_loss: 1002.8249 - val_mae: 1002.8249 - val_mse: 2190607.0000 - lr: 0.0010\n",
            "Epoch 563/5000\n",
            "3/3 [==============================] - 0s 118ms/step - loss: 180.5484 - mae: 180.5484 - mse: 233226.2656 - val_loss: 957.6523 - val_mae: 957.6523 - val_mse: 2047666.8750 - lr: 0.0010\n",
            "Epoch 564/5000\n",
            "3/3 [==============================] - 0s 98ms/step - loss: 180.2173 - mae: 180.2173 - mse: 224969.4688 - val_loss: 966.2407 - val_mae: 966.2407 - val_mse: 2077290.7500 - lr: 0.0010\n",
            "Epoch 565/5000\n",
            "3/3 [==============================] - 0s 109ms/step - loss: 184.3507 - mae: 184.3507 - mse: 238755.6719 - val_loss: 972.7605 - val_mae: 972.7605 - val_mse: 2092232.0000 - lr: 0.0010\n",
            "Epoch 566/5000\n",
            "3/3 [==============================] - 0s 175ms/step - loss: 195.6208 - mae: 195.6208 - mse: 247446.8906 - val_loss: 988.4105 - val_mae: 988.4105 - val_mse: 2136298.7500 - lr: 0.0010\n",
            "Epoch 567/5000\n",
            "3/3 [==============================] - 0s 109ms/step - loss: 195.5365 - mae: 195.5365 - mse: 258472.5156 - val_loss: 961.8480 - val_mae: 961.8480 - val_mse: 2056206.7500 - lr: 0.0010\n",
            "Epoch 568/5000\n",
            "3/3 [==============================] - 0s 151ms/step - loss: 201.0704 - mae: 201.0704 - mse: 257502.6875 - val_loss: 1015.4752 - val_mae: 1015.4752 - val_mse: 2222438.2500 - lr: 0.0010\n",
            "Epoch 569/5000\n",
            "3/3 [==============================] - 0s 112ms/step - loss: 190.8375 - mae: 190.8375 - mse: 250800.2812 - val_loss: 959.3993 - val_mae: 959.3993 - val_mse: 2046330.6250 - lr: 0.0010\n",
            "Epoch 570/5000\n",
            "3/3 [==============================] - 0s 126ms/step - loss: 191.4118 - mae: 191.4118 - mse: 242281.9844 - val_loss: 980.9528 - val_mae: 980.9528 - val_mse: 2124314.2500 - lr: 0.0010\n",
            "Epoch 571/5000\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 191.4946 - mae: 191.4946 - mse: 251968.0938 - val_loss: 961.1356 - val_mae: 961.1356 - val_mse: 2065680.8750 - lr: 0.0010\n",
            "Epoch 572/5000\n",
            "3/3 [==============================] - 0s 100ms/step - loss: 197.3666 - mae: 197.3666 - mse: 250434.3438 - val_loss: 1007.8509 - val_mae: 1007.8509 - val_mse: 2204083.0000 - lr: 0.0010\n",
            "Epoch 573/5000\n",
            "3/3 [==============================] - 0s 141ms/step - loss: 188.4456 - mae: 188.4456 - mse: 247274.4219 - val_loss: 957.7880 - val_mae: 957.7880 - val_mse: 2047906.1250 - lr: 0.0010\n",
            "Epoch 574/5000\n",
            "3/3 [==============================] - 1s 203ms/step - loss: 190.5718 - mae: 190.5718 - mse: 239849.1719 - val_loss: 999.1610 - val_mae: 999.1610 - val_mse: 2176502.0000 - lr: 0.0010\n",
            "Epoch 575/5000\n",
            "3/3 [==============================] - 0s 118ms/step - loss: 183.7895 - mae: 183.7895 - mse: 239486.8594 - val_loss: 958.7035 - val_mae: 958.7035 - val_mse: 2047038.0000 - lr: 0.0010\n",
            "Epoch 576/5000\n",
            "3/3 [==============================] - 1s 330ms/step - loss: 184.0311 - mae: 184.0311 - mse: 229651.6094 - val_loss: 979.1187 - val_mae: 979.1187 - val_mse: 2114271.0000 - lr: 0.0010\n",
            "Epoch 577/5000\n",
            "3/3 [==============================] - 0s 115ms/step - loss: 183.1753 - mae: 183.1753 - mse: 237411.0938 - val_loss: 962.2357 - val_mae: 962.2357 - val_mse: 2061922.6250 - lr: 0.0010\n",
            "Epoch 578/5000\n",
            "3/3 [==============================] - 0s 117ms/step - loss: 187.8766 - mae: 187.8766 - mse: 235477.2656 - val_loss: 981.3784 - val_mae: 981.3784 - val_mse: 2118090.2500 - lr: 0.0010\n",
            "Epoch 579/5000\n",
            "3/3 [==============================] - 0s 171ms/step - loss: 187.8400 - mae: 187.8400 - mse: 245058.0781 - val_loss: 966.4258 - val_mae: 966.4258 - val_mse: 2073018.6250 - lr: 0.0010\n",
            "Epoch 580/5000\n",
            "3/3 [==============================] - 0s 97ms/step - loss: 196.5817 - mae: 196.5817 - mse: 249035.0156 - val_loss: 1001.0951 - val_mae: 1001.0951 - val_mse: 2176543.0000 - lr: 0.0010\n",
            "Epoch 581/5000\n",
            "3/3 [==============================] - 0s 140ms/step - loss: 191.2947 - mae: 191.2947 - mse: 251219.7031 - val_loss: 960.6058 - val_mae: 960.6058 - val_mse: 2051818.5000 - lr: 0.0010\n",
            "Epoch 582/5000\n",
            "3/3 [==============================] - 0s 124ms/step - loss: 193.5786 - mae: 193.5786 - mse: 245251.8438 - val_loss: 1000.8284 - val_mae: 1000.8284 - val_mse: 2179123.0000 - lr: 0.0010\n",
            "Epoch 583/5000\n",
            "3/3 [==============================] - 0s 145ms/step - loss: 187.1801 - mae: 187.1801 - mse: 244059.9219 - val_loss: 959.2271 - val_mae: 959.2271 - val_mse: 2052581.1250 - lr: 0.0010\n",
            "Epoch 584/5000\n",
            "3/3 [==============================] - 0s 202ms/step - loss: 190.9592 - mae: 190.9592 - mse: 240813.4062 - val_loss: 994.4232 - val_mae: 994.4232 - val_mse: 2162121.7500 - lr: 0.0010\n",
            "Epoch 585/5000\n",
            "3/3 [==============================] - 0s 99ms/step - loss: 184.7764 - mae: 184.7764 - mse: 240312.4219 - val_loss: 959.6868 - val_mae: 959.6868 - val_mse: 2056105.0000 - lr: 0.0010\n",
            "Epoch 586/5000\n",
            "3/3 [==============================] - 0s 199ms/step - loss: 188.7074 - mae: 188.7074 - mse: 236608.6562 - val_loss: 987.6946 - val_mae: 987.6946 - val_mse: 2139830.5000 - lr: 0.0010\n",
            "Epoch 587/5000\n",
            "3/3 [==============================] - 0s 122ms/step - loss: 186.1773 - mae: 186.1773 - mse: 242677.3438 - val_loss: 964.3325 - val_mae: 964.3325 - val_mse: 2071341.1250 - lr: 0.0010\n",
            "Epoch 588/5000\n",
            "3/3 [==============================] - 0s 96ms/step - loss: 194.7876 - mae: 194.7876 - mse: 246110.2500 - val_loss: 988.9027 - val_mae: 988.9027 - val_mse: 2144403.0000 - lr: 0.0010\n",
            "Epoch 589/5000\n",
            "3/3 [==============================] - 0s 143ms/step - loss: 192.5356 - mae: 192.5356 - mse: 253066.2188 - val_loss: 959.5630 - val_mae: 959.5630 - val_mse: 2054770.6250 - lr: 0.0010\n",
            "Epoch 590/5000\n",
            "3/3 [==============================] - 1s 166ms/step - loss: 197.9816 - mae: 197.9816 - mse: 252019.7500 - val_loss: 1006.3336 - val_mae: 1006.3336 - val_mse: 2197397.0000 - lr: 0.0010\n",
            "Epoch 591/5000\n",
            "3/3 [==============================] - 0s 126ms/step - loss: 190.7062 - mae: 190.7062 - mse: 250884.1094 - val_loss: 958.5936 - val_mae: 958.5936 - val_mse: 2047744.7500 - lr: 0.0010\n",
            "Epoch 592/5000\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 192.0516 - mae: 192.0516 - mse: 242474.1406 - val_loss: 1002.3663 - val_mae: 1002.3663 - val_mse: 2184753.5000 - lr: 0.0010\n",
            "Epoch 593/5000\n",
            "3/3 [==============================] - 0s 106ms/step - loss: 184.7299 - mae: 184.7299 - mse: 239908.8594 - val_loss: 958.1396 - val_mae: 958.1396 - val_mse: 2049976.3750 - lr: 0.0010\n",
            "Epoch 594/5000\n",
            "3/3 [==============================] - 0s 172ms/step - loss: 187.4344 - mae: 187.4344 - mse: 235264.0781 - val_loss: 988.7169 - val_mae: 988.7169 - val_mse: 2143596.5000 - lr: 0.0010\n",
            "Epoch 595/5000\n",
            "3/3 [==============================] - 0s 151ms/step - loss: 183.0545 - mae: 183.0545 - mse: 237747.7188 - val_loss: 960.3917 - val_mae: 960.3917 - val_mse: 2054767.5000 - lr: 0.0010\n",
            "Epoch 596/5000\n",
            "3/3 [==============================] - 0s 166ms/step - loss: 185.7057 - mae: 185.7057 - mse: 232327.9375 - val_loss: 981.8592 - val_mae: 981.8592 - val_mse: 2118985.5000 - lr: 0.0010\n",
            "Epoch 597/5000\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 185.2579 - mae: 185.2579 - mse: 241216.0781 - val_loss: 967.9242 - val_mae: 967.9242 - val_mse: 2076301.0000 - lr: 0.0010\n",
            "Epoch 598/5000\n",
            "3/3 [==============================] - 0s 104ms/step - loss: 193.2559 - mae: 193.2559 - mse: 243319.1875 - val_loss: 992.7827 - val_mae: 992.7827 - val_mse: 2151927.5000 - lr: 0.0010\n",
            "Epoch 599/5000\n",
            "3/3 [==============================] - 0s 160ms/step - loss: 190.1123 - mae: 190.1123 - mse: 248975.8594 - val_loss: 961.6234 - val_mae: 961.6234 - val_mse: 2059781.2500 - lr: 0.0010\n",
            "Epoch 600/5000\n",
            "3/3 [==============================] - 0s 129ms/step - loss: 196.2941 - mae: 196.2941 - mse: 249274.2656 - val_loss: 1005.3790 - val_mae: 1005.3790 - val_mse: 2193259.7500 - lr: 0.0010\n",
            "Epoch 601/5000\n",
            "3/3 [==============================] - 0s 135ms/step - loss: 188.5424 - mae: 188.5424 - mse: 246497.3750 - val_loss: 958.4142 - val_mae: 958.4142 - val_mse: 2047585.0000 - lr: 0.0010\n",
            "Epoch 602/5000\n",
            "3/3 [==============================] - 1s 269ms/step - loss: 189.6584 - mae: 189.6584 - mse: 238645.6875 - val_loss: 996.1509 - val_mae: 996.1509 - val_mse: 2167962.5000 - lr: 0.0010\n",
            "Epoch 603/5000\n",
            "3/3 [==============================] - 0s 166ms/step - loss: 183.7675 - mae: 183.7675 - mse: 238496.2812 - val_loss: 959.5416 - val_mae: 959.5416 - val_mse: 2055061.8750 - lr: 0.0010\n",
            "Epoch 604/5000\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 186.8670 - mae: 186.8670 - mse: 234143.3281 - val_loss: 985.9370 - val_mae: 985.9370 - val_mse: 2134512.0000 - lr: 0.0010\n",
            "Epoch 605/5000\n",
            "3/3 [==============================] - 0s 107ms/step - loss: 184.1387 - mae: 184.1387 - mse: 239271.9375 - val_loss: 964.4663 - val_mae: 964.4663 - val_mse: 2069220.2500 - lr: 0.0010\n",
            "Epoch 606/5000\n",
            "3/3 [==============================] - 0s 162ms/step - loss: 191.0699 - mae: 191.0699 - mse: 240224.2500 - val_loss: 981.6899 - val_mae: 981.6899 - val_mse: 2120497.5000 - lr: 0.0010\n",
            "Epoch 607/5000\n",
            "3/3 [==============================] - 1s 191ms/step - loss: 192.4086 - mae: 192.4086 - mse: 252525.9062 - val_loss: 962.1608 - val_mae: 962.1608 - val_mse: 2063474.5000 - lr: 0.0010\n",
            "Epoch 608/5000\n",
            "3/3 [==============================] - 0s 125ms/step - loss: 200.9808 - mae: 200.9808 - mse: 256882.8281 - val_loss: 1009.4250 - val_mae: 1009.4250 - val_mse: 2205918.5000 - lr: 0.0010\n",
            "Epoch 609/5000\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 192.4561 - mae: 192.4561 - mse: 253247.6875 - val_loss: 957.6025 - val_mae: 957.6025 - val_mse: 2042183.5000 - lr: 0.0010\n",
            "Epoch 610/5000\n",
            "3/3 [==============================] - 0s 102ms/step - loss: 192.3959 - mae: 192.3959 - mse: 243629.6875 - val_loss: 1002.0063 - val_mae: 1002.0063 - val_mse: 2185078.0000 - lr: 0.0010\n",
            "Epoch 611/5000\n",
            "3/3 [==============================] - 0s 157ms/step - loss: 185.4355 - mae: 185.4355 - mse: 241131.7812 - val_loss: 957.3888 - val_mae: 957.3888 - val_mse: 2047369.8750 - lr: 0.0010\n",
            "Epoch 612/5000\n",
            "3/3 [==============================] - 0s 176ms/step - loss: 186.6923 - mae: 186.6923 - mse: 233809.8438 - val_loss: 987.6360 - val_mae: 987.6360 - val_mse: 2142418.0000 - lr: 0.0010\n",
            "Epoch 613/5000\n",
            "3/3 [==============================] - 0s 139ms/step - loss: 182.7561 - mae: 182.7561 - mse: 236759.2656 - val_loss: 959.4691 - val_mae: 959.4691 - val_mse: 2054644.3750 - lr: 0.0010\n",
            "Epoch 614/5000\n",
            "3/3 [==============================] - 1s 275ms/step - loss: 185.5388 - mae: 185.5388 - mse: 231928.3906 - val_loss: 979.5999 - val_mae: 979.5999 - val_mse: 2114500.2500 - lr: 0.0010\n",
            "Epoch 615/5000\n",
            "3/3 [==============================] - 0s 109ms/step - loss: 185.5219 - mae: 185.5219 - mse: 241265.4531 - val_loss: 966.7001 - val_mae: 966.7001 - val_mse: 2074922.6250 - lr: 0.0010\n",
            "Epoch 616/5000\n",
            "3/3 [==============================] - 0s 115ms/step - loss: 194.3541 - mae: 194.3541 - mse: 245466.2969 - val_loss: 991.6761 - val_mae: 991.6761 - val_mse: 2149580.0000 - lr: 0.0010\n",
            "Epoch 617/5000\n",
            "3/3 [==============================] - 0s 179ms/step - loss: 191.3642 - mae: 191.3642 - mse: 250785.8594 - val_loss: 961.0494 - val_mae: 961.0494 - val_mse: 2056386.7500 - lr: 0.0010\n",
            "Epoch 618/5000\n",
            "3/3 [==============================] - 0s 121ms/step - loss: 197.1679 - mae: 197.1679 - mse: 250886.7969 - val_loss: 1003.1014 - val_mae: 1003.1014 - val_mse: 2186780.7500 - lr: 0.0010\n",
            "Epoch 619/5000\n",
            "3/3 [==============================] - 0s 126ms/step - loss: 190.6523 - mae: 190.6523 - mse: 250113.8125 - val_loss: 958.5935 - val_mae: 958.5935 - val_mse: 2046417.7500 - lr: 0.0010\n",
            "Epoch 620/5000\n",
            "3/3 [==============================] - 0s 124ms/step - loss: 191.9623 - mae: 191.9623 - mse: 242411.2031 - val_loss: 1004.5156 - val_mae: 1004.5156 - val_mse: 2191940.7500 - lr: 0.0010\n",
            "Epoch 621/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 183.8573 - mae: 183.8573 - mse: 238428.5000INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 1s/step - loss: 183.8573 - mae: 183.8573 - mse: 238428.5000 - val_loss: 957.2069 - val_mae: 957.2069 - val_mse: 2044826.0000 - lr: 0.0010\n",
            "Epoch 622/5000\n",
            "3/3 [==============================] - 0s 152ms/step - loss: 184.8698 - mae: 184.8698 - mse: 231122.5781 - val_loss: 982.4983 - val_mae: 982.4983 - val_mse: 2124194.7500 - lr: 0.0010\n",
            "Epoch 623/5000\n",
            "3/3 [==============================] - 0s 100ms/step - loss: 183.2787 - mae: 183.2787 - mse: 237478.8438 - val_loss: 961.6838 - val_mae: 961.6838 - val_mse: 2058128.6250 - lr: 0.0010\n",
            "Epoch 624/5000\n",
            "3/3 [==============================] - 0s 159ms/step - loss: 186.9624 - mae: 186.9624 - mse: 234199.6562 - val_loss: 984.1223 - val_mae: 984.1223 - val_mse: 2124180.5000 - lr: 0.0010\n",
            "Epoch 625/5000\n",
            "3/3 [==============================] - 0s 139ms/step - loss: 185.3235 - mae: 185.3235 - mse: 241218.2812 - val_loss: 966.3058 - val_mae: 966.3058 - val_mse: 2069513.2500 - lr: 0.0010\n",
            "Epoch 626/5000\n",
            "3/3 [==============================] - 0s 146ms/step - loss: 193.2815 - mae: 193.2815 - mse: 243290.6562 - val_loss: 988.6678 - val_mae: 988.6678 - val_mse: 2140341.2500 - lr: 0.0010\n",
            "Epoch 627/5000\n",
            "3/3 [==============================] - 1s 223ms/step - loss: 191.0559 - mae: 191.0559 - mse: 250641.0469 - val_loss: 961.1288 - val_mae: 961.1288 - val_mse: 2060536.5000 - lr: 0.0010\n",
            "Epoch 628/5000\n",
            "3/3 [==============================] - 0s 221ms/step - loss: 198.9983 - mae: 198.9983 - mse: 252916.3750 - val_loss: 1003.6398 - val_mae: 1003.6398 - val_mse: 2190900.0000 - lr: 0.0010\n",
            "Epoch 629/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 192.1620 - mae: 192.1620 - mse: 252899.9844INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 3s 1s/step - loss: 192.1620 - mae: 192.1620 - mse: 252899.9844 - val_loss: 956.8170 - val_mae: 956.8170 - val_mse: 2043410.7500 - lr: 0.0010\n",
            "Epoch 630/5000\n",
            "3/3 [==============================] - 0s 155ms/step - loss: 193.5414 - mae: 193.5414 - mse: 244943.4688 - val_loss: 1007.5999 - val_mae: 1007.5999 - val_mse: 2202442.7500 - lr: 0.0010\n",
            "Epoch 631/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 184.3518 - mae: 184.3518 - mse: 239289.3438INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_checkpoints\\model_univariate_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 3s 2s/step - loss: 184.3518 - mae: 184.3518 - mse: 239289.3438 - val_loss: 956.6699 - val_mae: 956.6699 - val_mse: 2044470.6250 - lr: 0.0010\n",
            "Epoch 632/5000\n",
            "3/3 [==============================] - 0s 124ms/step - loss: 185.7444 - mae: 185.7444 - mse: 231985.1250 - val_loss: 984.8176 - val_mae: 984.8176 - val_mse: 2131461.0000 - lr: 0.0010\n",
            "Epoch 633/5000\n",
            "3/3 [==============================] - 0s 125ms/step - loss: 183.0009 - mae: 183.0009 - mse: 237297.9531 - val_loss: 960.1293 - val_mae: 960.1293 - val_mse: 2052073.0000 - lr: 0.0010\n",
            "Epoch 634/5000\n",
            "3/3 [==============================] - 0s 107ms/step - loss: 185.1360 - mae: 185.1360 - mse: 231295.5469 - val_loss: 980.5624 - val_mae: 980.5624 - val_mse: 2111689.2500 - lr: 0.0010\n",
            "Epoch 635/5000\n",
            "3/3 [==============================] - 0s 91ms/step - loss: 184.6929 - mae: 184.6929 - mse: 240071.7031 - val_loss: 968.1402 - val_mae: 968.1402 - val_mse: 2073280.6250 - lr: 0.0010\n",
            "Epoch 636/5000\n",
            "3/3 [==============================] - 0s 93ms/step - loss: 193.2046 - mae: 193.2046 - mse: 243328.7812 - val_loss: 989.5629 - val_mae: 989.5629 - val_mse: 2142352.2500 - lr: 0.0010\n",
            "Epoch 637/5000\n",
            "3/3 [==============================] - 0s 142ms/step - loss: 190.8011 - mae: 190.8011 - mse: 249694.0312 - val_loss: 959.6013 - val_mae: 959.6013 - val_mse: 2053726.7500 - lr: 0.0010\n",
            "Epoch 638/5000\n",
            "3/3 [==============================] - 0s 131ms/step - loss: 195.7323 - mae: 195.7323 - mse: 247906.5781 - val_loss: 999.8792 - val_mae: 999.8792 - val_mse: 2180195.2500 - lr: 0.0010\n",
            "Epoch 639/5000\n",
            "3/3 [==============================] - 0s 99ms/step - loss: 188.7582 - mae: 188.7582 - mse: 246754.8281 - val_loss: 957.5704 - val_mae: 957.5704 - val_mse: 2045881.7500 - lr: 0.0010\n",
            "Epoch 640/5000\n",
            "3/3 [==============================] - 0s 97ms/step - loss: 189.6523 - mae: 189.6523 - mse: 238293.7656 - val_loss: 995.2145 - val_mae: 995.2145 - val_mse: 2165728.7500 - lr: 0.0010\n",
            "Epoch 641/5000\n",
            "3/3 [==============================] - 0s 113ms/step - loss: 184.3960 - mae: 184.3960 - mse: 239356.2188 - val_loss: 958.6437 - val_mae: 958.6437 - val_mse: 2052166.8750 - lr: 0.0010\n",
            "Epoch 642/5000\n",
            "3/3 [==============================] - 0s 98ms/step - loss: 187.7101 - mae: 187.7101 - mse: 235311.8906 - val_loss: 988.4645 - val_mae: 988.4645 - val_mse: 2142180.7500 - lr: 0.0010\n",
            "Epoch 643/5000\n",
            "3/3 [==============================] - 0s 114ms/step - loss: 183.8832 - mae: 183.8832 - mse: 238860.3281 - val_loss: 962.9866 - val_mae: 962.9866 - val_mse: 2064040.5000 - lr: 0.0010\n",
            "Epoch 644/5000\n",
            "3/3 [==============================] - 0s 97ms/step - loss: 190.4779 - mae: 190.4779 - mse: 238806.6875 - val_loss: 986.6786 - val_mae: 986.6786 - val_mse: 2134634.5000 - lr: 0.0010\n",
            "Epoch 645/5000\n",
            "3/3 [==============================] - 0s 103ms/step - loss: 188.2655 - mae: 188.2655 - mse: 245827.7812 - val_loss: 960.3846 - val_mae: 960.3846 - val_mse: 2056006.8750 - lr: 0.0010\n",
            "Epoch 646/5000\n",
            "3/3 [==============================] - 0s 126ms/step - loss: 193.8235 - mae: 193.8235 - mse: 244756.3125 - val_loss: 997.0015 - val_mae: 997.0015 - val_mse: 2169535.7500 - lr: 0.0010\n",
            "Epoch 647/5000\n",
            "3/3 [==============================] - 0s 92ms/step - loss: 187.7164 - mae: 187.7164 - mse: 244838.2812 - val_loss: 957.7906 - val_mae: 957.7906 - val_mse: 2050351.2500 - lr: 0.0010\n",
            "Epoch 648/5000\n",
            "3/3 [==============================] - 0s 178ms/step - loss: 191.0041 - mae: 191.0041 - mse: 239978.5469 - val_loss: 997.0875 - val_mae: 997.0875 - val_mse: 2172776.7500 - lr: 0.0010\n",
            "Epoch 649/5000\n",
            "3/3 [==============================] - 0s 110ms/step - loss: 185.1021 - mae: 185.1021 - mse: 240684.0156 - val_loss: 957.8306 - val_mae: 957.8306 - val_mse: 2052917.6250 - lr: 0.0010\n",
            "Epoch 650/5000\n",
            "3/3 [==============================] - 0s 122ms/step - loss: 188.1327 - mae: 188.1327 - mse: 235922.8438 - val_loss: 988.5662 - val_mae: 988.5662 - val_mse: 2145843.2500 - lr: 0.0010\n",
            "Epoch 651/5000\n",
            "3/3 [==============================] - 0s 105ms/step - loss: 183.7266 - mae: 183.7266 - mse: 238199.0156 - val_loss: 960.6221 - val_mae: 960.6221 - val_mse: 2058581.0000 - lr: 0.0010\n",
            "Epoch 652/5000\n",
            "3/3 [==============================] - 1s 193ms/step - loss: 188.6218 - mae: 188.6218 - mse: 236112.2031 - val_loss: 985.2167 - val_mae: 985.2167 - val_mse: 2130358.7500 - lr: 0.0010\n",
            "Epoch 653/5000\n",
            "3/3 [==============================] - 0s 204ms/step - loss: 187.2831 - mae: 187.2831 - mse: 243900.4688 - val_loss: 961.9637 - val_mae: 961.9637 - val_mse: 2060539.7500 - lr: 0.0010\n",
            "Epoch 654/5000\n",
            "3/3 [==============================] - 0s 156ms/step - loss: 193.5977 - mae: 193.5977 - mse: 244151.0938 - val_loss: 993.3977 - val_mae: 993.3977 - val_mse: 2157094.0000 - lr: 0.0010\n",
            "Epoch 655/5000\n",
            "3/3 [==============================] - 0s 110ms/step - loss: 189.1732 - mae: 189.1732 - mse: 247353.5781 - val_loss: 959.0756 - val_mae: 959.0756 - val_mse: 2052974.6250 - lr: 0.0010\n",
            "Epoch 656/5000\n",
            "3/3 [==============================] - 0s 147ms/step - loss: 193.9509 - mae: 193.9509 - mse: 244855.0625 - val_loss: 1003.7834 - val_mae: 1003.7834 - val_mse: 2190752.2500 - lr: 0.0010\n",
            "Epoch 657/5000\n",
            "3/3 [==============================] - 0s 102ms/step - loss: 186.4040 - mae: 186.4040 - mse: 243515.7812 - val_loss: 958.6178 - val_mae: 958.6178 - val_mse: 2048844.8750 - lr: 0.0010\n",
            "Epoch 658/5000\n",
            "3/3 [==============================] - 0s 129ms/step - loss: 187.2324 - mae: 187.2324 - mse: 233987.3438 - val_loss: 992.3658 - val_mae: 992.3658 - val_mse: 2154896.2500 - lr: 0.0010\n",
            "Epoch 659/5000\n",
            "3/3 [==============================] - 1s 224ms/step - loss: 182.6876 - mae: 182.6876 - mse: 236527.6719 - val_loss: 958.1910 - val_mae: 958.1910 - val_mse: 2047364.6250 - lr: 0.0010\n",
            "Epoch 660/5000\n",
            "3/3 [==============================] - 0s 109ms/step - loss: 184.0826 - mae: 184.0826 - mse: 230079.9219 - val_loss: 976.7545 - val_mae: 976.7545 - val_mse: 2105942.2500 - lr: 0.0010\n",
            "Epoch 661/5000\n",
            "3/3 [==============================] - 0s 162ms/step - loss: 183.7501 - mae: 183.7501 - mse: 237910.4219 - val_loss: 964.0302 - val_mae: 964.0302 - val_mse: 2068089.3750 - lr: 0.0010\n",
            "Epoch 662/5000\n",
            "3/3 [==============================] - 0s 199ms/step - loss: 191.2386 - mae: 191.2386 - mse: 239913.3594 - val_loss: 984.0718 - val_mae: 984.0718 - val_mse: 2127054.5000 - lr: 0.0010\n",
            "Epoch 663/5000\n",
            "3/3 [==============================] - 0s 137ms/step - loss: 191.9903 - mae: 191.9903 - mse: 252536.8281 - val_loss: 967.8153 - val_mae: 967.8153 - val_mse: 2080101.6250 - lr: 0.0010\n",
            "Epoch 664/5000\n",
            "3/3 [==============================] - 0s 161ms/step - loss: 206.5327 - mae: 206.5327 - mse: 266350.5312 - val_loss: 1028.7238 - val_mae: 1028.7238 - val_mse: 2261044.5000 - lr: 0.0010\n",
            "Epoch 665/5000\n",
            "3/3 [==============================] - 0s 99ms/step - loss: 190.8888 - mae: 190.8888 - mse: 250850.5000 - val_loss: 957.6240 - val_mae: 957.6240 - val_mse: 2037547.6250 - lr: 0.0010\n",
            "Epoch 666/5000\n",
            "3/3 [==============================] - 0s 138ms/step - loss: 188.8839 - mae: 188.8839 - mse: 237908.6094 - val_loss: 1001.7679 - val_mae: 1001.7679 - val_mse: 2184782.5000 - lr: 0.0010\n",
            "Epoch 667/5000\n",
            "3/3 [==============================] - 1s 253ms/step - loss: 181.7148 - mae: 181.7148 - mse: 234820.5312 - val_loss: 958.4719 - val_mae: 958.4719 - val_mse: 2046226.7500 - lr: 0.0010\n",
            "Epoch 668/5000\n",
            "3/3 [==============================] - 0s 99ms/step - loss: 180.6528 - mae: 180.6528 - mse: 224618.1562 - val_loss: 972.5014 - val_mae: 972.5014 - val_mse: 2095353.0000 - lr: 0.0010\n",
            "Epoch 669/5000\n",
            "3/3 [==============================] - 0s 97ms/step - loss: 181.7842 - mae: 181.7842 - mse: 234017.6875 - val_loss: 962.9589 - val_mae: 962.9589 - val_mse: 2065124.1250 - lr: 0.0010\n",
            "Epoch 670/5000\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 186.8284 - mae: 186.8284 - mse: 233776.6406 - val_loss: 973.5589 - val_mae: 973.5589 - val_mse: 2095087.3750 - lr: 0.0010\n",
            "Epoch 671/5000\n",
            "3/3 [==============================] - 0s 105ms/step - loss: 189.6666 - mae: 189.6666 - mse: 246985.5000 - val_loss: 965.4659 - val_mae: 965.4659 - val_mse: 2071506.8750 - lr: 0.0010\n",
            "Epoch 672/5000\n",
            "3/3 [==============================] - 1s 258ms/step - loss: 201.8066 - mae: 201.8066 - mse: 257592.5469 - val_loss: 1012.3807 - val_mae: 1012.3807 - val_mse: 2212924.7500 - lr: 0.0010\n",
            "Epoch 673/5000\n",
            "3/3 [==============================] - 0s 105ms/step - loss: 192.5106 - mae: 192.5106 - mse: 254153.6562 - val_loss: 960.2455 - val_mae: 960.2455 - val_mse: 2050002.1250 - lr: 0.0010\n",
            "Epoch 674/5000\n",
            "3/3 [==============================] - 0s 143ms/step - loss: 194.8934 - mae: 194.8934 - mse: 246798.9844 - val_loss: 1008.1138 - val_mae: 1008.1138 - val_mse: 2200066.2500 - lr: 0.0010\n",
            "Epoch 675/5000\n",
            "3/3 [==============================] - 0s 166ms/step - loss: 185.4163 - mae: 185.4163 - mse: 240923.1250 - val_loss: 958.1652 - val_mae: 958.1652 - val_mse: 2044885.3750 - lr: 0.0010\n",
            "Epoch 676/5000\n",
            "3/3 [==============================] - 0s 105ms/step - loss: 187.4155 - mae: 187.4155 - mse: 234730.8125 - val_loss: 986.4854 - val_mae: 986.4854 - val_mse: 2135649.0000 - lr: 0.0010\n",
            "Epoch 677/5000\n",
            "3/3 [==============================] - 0s 132ms/step - loss: 184.9404 - mae: 184.9404 - mse: 240274.5000 - val_loss: 961.8445 - val_mae: 961.8445 - val_mse: 2061593.3750 - lr: 0.0010\n",
            "Epoch 678/5000\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 190.4547 - mae: 190.4547 - mse: 238514.3594 - val_loss: 993.6928 - val_mae: 993.6928 - val_mse: 2156459.2500 - lr: 0.0010\n",
            "Epoch 679/5000\n",
            "3/3 [==============================] - 0s 154ms/step - loss: 185.9576 - mae: 185.9576 - mse: 242105.3438 - val_loss: 960.4604 - val_mae: 960.4604 - val_mse: 2055990.6250 - lr: 0.0010\n",
            "Epoch 680/5000\n",
            "3/3 [==============================] - 0s 179ms/step - loss: 191.0296 - mae: 191.0296 - mse: 239889.1406 - val_loss: 988.5005 - val_mae: 988.5005 - val_mse: 2142770.0000 - lr: 0.0010\n",
            "Epoch 681/5000\n",
            "3/3 [==============================] - 0s 168ms/step - loss: 188.0086 - mae: 188.0086 - mse: 245353.5312 - val_loss: 958.3690 - val_mae: 958.3690 - val_mse: 2050262.1250 - lr: 0.0010\n",
            "Epoch 682/5000\n",
            "3/3 [==============================] - 1s 315ms/step - loss: 191.0216 - mae: 191.0216 - mse: 239835.7188 - val_loss: 997.6599 - val_mae: 997.6599 - val_mse: 2173655.5000 - lr: 0.0010\n",
            "Epoch 683/5000\n",
            "3/3 [==============================] - 0s 160ms/step - loss: 185.0610 - mae: 185.0610 - mse: 240405.7969 - val_loss: 957.5112 - val_mae: 957.5112 - val_mse: 2050441.8750 - lr: 0.0010\n",
            "Epoch 684/5000\n",
            "3/3 [==============================] - 0s 171ms/step - loss: 188.0477 - mae: 188.0477 - mse: 235789.7031 - val_loss: 987.5247 - val_mae: 987.5247 - val_mse: 2142106.0000 - lr: 0.0010\n",
            "Epoch 685/5000\n",
            "3/3 [==============================] - 0s 103ms/step - loss: 184.0298 - mae: 184.0298 - mse: 238593.9062 - val_loss: 959.8757 - val_mae: 959.8757 - val_mse: 2057553.0000 - lr: 0.0010\n",
            "Epoch 686/5000\n",
            "3/3 [==============================] - 0s 104ms/step - loss: 189.7535 - mae: 189.7535 - mse: 237718.3750 - val_loss: 987.7216 - val_mae: 987.7216 - val_mse: 2139124.0000 - lr: 0.0010\n",
            "Epoch 687/5000\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 187.2484 - mae: 187.2484 - mse: 245027.3281 - val_loss: 962.4133 - val_mae: 962.4133 - val_mse: 2061794.3750 - lr: 0.0010\n",
            "Epoch 688/5000\n",
            "3/3 [==============================] - 0s 94ms/step - loss: 192.9817 - mae: 192.9817 - mse: 242513.9844 - val_loss: 1002.1232 - val_mae: 1002.1232 - val_mse: 2182893.0000 - lr: 0.0010\n",
            "Epoch 689/5000\n",
            "3/3 [==============================] - 0s 110ms/step - loss: 185.5708 - mae: 185.5708 - mse: 241508.8750 - val_loss: 958.2144 - val_mae: 958.2144 - val_mse: 2049625.6250 - lr: 0.0010\n",
            "Epoch 690/5000\n",
            "3/3 [==============================] - 0s 183ms/step - loss: 188.8676 - mae: 188.8676 - mse: 236852.8125 - val_loss: 988.7899 - val_mae: 988.7899 - val_mse: 2146081.5000 - lr: 0.0010\n",
            "Epoch 691/5000\n",
            "3/3 [==============================] - 0s 96ms/step - loss: 184.5325 - mae: 184.5325 - mse: 239126.6406 - val_loss: 958.4406 - val_mae: 958.4406 - val_mse: 2052108.3750 - lr: 0.0010\n",
            "Epoch 692/5000\n",
            "3/3 [==============================] - 0s 97ms/step - loss: 188.0352 - mae: 188.0352 - mse: 235088.7344 - val_loss: 985.1512 - val_mae: 985.1512 - val_mse: 2132781.0000 - lr: 0.0010\n",
            "Epoch 693/5000\n",
            "3/3 [==============================] - 0s 103ms/step - loss: 186.1365 - mae: 186.1365 - mse: 241986.3438 - val_loss: 959.5616 - val_mae: 959.5616 - val_mse: 2054814.3750 - lr: 0.0010\n",
            "Epoch 694/5000\n",
            "3/3 [==============================] - 0s 142ms/step - loss: 191.3244 - mae: 191.3244 - mse: 240365.0156 - val_loss: 990.1620 - val_mae: 990.1620 - val_mse: 2147889.5000 - lr: 0.0010\n",
            "Epoch 695/5000\n",
            "3/3 [==============================] - 0s 93ms/step - loss: 187.7701 - mae: 187.7701 - mse: 245274.0625 - val_loss: 959.0079 - val_mae: 959.0079 - val_mse: 2053156.0000 - lr: 0.0010\n",
            "Epoch 696/5000\n",
            "3/3 [==============================] - 0s 101ms/step - loss: 192.4270 - mae: 192.4270 - mse: 241830.3594 - val_loss: 998.9175 - val_mae: 998.9175 - val_mse: 2174978.2500 - lr: 0.0010\n",
            "Epoch 697/5000\n",
            "3/3 [==============================] - 0s 204ms/step - loss: 186.5877 - mae: 186.5877 - mse: 243819.9688 - val_loss: 959.6043 - val_mae: 959.6043 - val_mse: 2055268.5000 - lr: 0.0010\n",
            "Epoch 698/5000\n",
            "3/3 [==============================] - 0s 98ms/step - loss: 190.9366 - mae: 190.9366 - mse: 239396.2969 - val_loss: 996.4773 - val_mae: 996.4773 - val_mse: 2169380.5000 - lr: 0.0010\n",
            "Epoch 699/5000\n",
            "3/3 [==============================] - 0s 122ms/step - loss: 184.4335 - mae: 184.4335 - mse: 239462.9688 - val_loss: 957.8786 - val_mae: 957.8786 - val_mse: 2049193.8750 - lr: 0.0010\n",
            "Epoch 700/5000\n",
            "3/3 [==============================] - 0s 180ms/step - loss: 187.3849 - mae: 187.3849 - mse: 234021.6250 - val_loss: 986.4582 - val_mae: 986.4582 - val_mse: 2136483.2500 - lr: 0.0010\n",
            "Epoch 701/5000\n",
            "3/3 [==============================] - 0s 111ms/step - loss: 185.0291 - mae: 185.0291 - mse: 240832.4062 - val_loss: 961.4255 - val_mae: 961.4255 - val_mse: 2059491.7500 - lr: 0.0010\n",
            "Epoch 702/5000\n",
            "3/3 [==============================] - 0s 154ms/step - loss: 189.5235 - mae: 189.5235 - mse: 236846.6406 - val_loss: 993.0161 - val_mae: 993.0161 - val_mse: 2153847.0000 - lr: 0.0010\n",
            "Epoch 703/5000\n",
            "3/3 [==============================] - 0s 115ms/step - loss: 185.2194 - mae: 185.2194 - mse: 240651.5938 - val_loss: 961.3669 - val_mae: 961.3669 - val_mse: 2058821.3750 - lr: 0.0010\n",
            "Epoch 704/5000\n",
            "3/3 [==============================] - 0s 91ms/step - loss: 190.9704 - mae: 190.9704 - mse: 239346.9219 - val_loss: 988.0480 - val_mae: 988.0480 - val_mse: 2141206.7500 - lr: 0.0010\n",
            "Epoch 705/5000\n",
            "3/3 [==============================] - 0s 110ms/step - loss: 188.2746 - mae: 188.2746 - mse: 245842.7188 - val_loss: 960.3233 - val_mae: 960.3233 - val_mse: 2058117.2500 - lr: 0.0010\n",
            "Epoch 706/5000\n",
            "3/3 [==============================] - 0s 103ms/step - loss: 194.2790 - mae: 194.2790 - mse: 244558.9375 - val_loss: 1002.3762 - val_mae: 1002.3762 - val_mse: 2186210.0000 - lr: 0.0010\n",
            "Epoch 707/5000\n",
            "3/3 [==============================] - 0s 113ms/step - loss: 187.7612 - mae: 187.7612 - mse: 245373.4531 - val_loss: 958.0943 - val_mae: 958.0943 - val_mse: 2045766.2500 - lr: 0.0010\n",
            "Epoch 708/5000\n",
            "3/3 [==============================] - 0s 95ms/step - loss: 188.0169 - mae: 188.0169 - mse: 235074.5469 - val_loss: 998.9146 - val_mae: 998.9146 - val_mse: 2176052.0000 - lr: 0.0010\n",
            "Epoch 709/5000\n",
            "3/3 [==============================] - 0s 92ms/step - loss: 181.4574 - mae: 181.4574 - mse: 234342.5938 - val_loss: 958.2665 - val_mae: 958.2665 - val_mse: 2043507.7500 - lr: 0.0010\n",
            "Epoch 710/5000\n",
            "3/3 [==============================] - 0s 171ms/step - loss: 180.0020 - mae: 180.0020 - mse: 223558.7344 - val_loss: 973.9366 - val_mae: 973.9366 - val_mse: 2098459.7500 - lr: 0.0010\n",
            "Epoch 711/5000\n",
            "3/3 [==============================] - 0s 152ms/step - loss: 180.8352 - mae: 180.8352 - mse: 232771.9062 - val_loss: 962.9170 - val_mae: 962.9170 - val_mse: 2062966.8750 - lr: 0.0010\n",
            "Epoch 712/5000\n",
            "3/3 [==============================] - 0s 111ms/step - loss: 184.4454 - mae: 184.4454 - mse: 229587.6875 - val_loss: 977.2324 - val_mae: 977.2324 - val_mse: 2104485.5000 - lr: 0.0010\n",
            "Epoch 713/5000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 0s 191ms/step - loss: 185.5129 - mae: 185.5129 - mse: 240312.2969 - val_loss: 966.2112 - val_mae: 966.2112 - val_mse: 2070888.6250 - lr: 0.0010\n",
            "Epoch 714/5000\n",
            "3/3 [==============================] - 0s 91ms/step - loss: 193.7749 - mae: 193.7749 - mse: 243894.6250 - val_loss: 997.2887 - val_mae: 997.2887 - val_mse: 2166086.0000 - lr: 0.0010\n",
            "Epoch 715/5000\n",
            "3/3 [==============================] - 0s 158ms/step - loss: 188.4384 - mae: 188.4384 - mse: 245860.4688 - val_loss: 959.8440 - val_mae: 959.8440 - val_mse: 2050169.0000 - lr: 0.0010\n",
            "Epoch 716/5000\n",
            "3/3 [==============================] - 0s 104ms/step - loss: 191.4605 - mae: 191.4605 - mse: 240530.0156 - val_loss: 999.2709 - val_mae: 999.2709 - val_mse: 2175757.2500 - lr: 0.0010\n",
            "Epoch 717/5000\n",
            "3/3 [==============================] - 0s 91ms/step - loss: 185.3085 - mae: 185.3085 - mse: 241215.2031 - val_loss: 959.0263 - val_mae: 959.0263 - val_mse: 2051346.3750 - lr: 0.0010\n",
            "Epoch 718/5000\n",
            "3/3 [==============================] - 0s 93ms/step - loss: 187.3941 - mae: 187.3941 - mse: 234070.9375 - val_loss: 989.4951 - val_mae: 989.4951 - val_mse: 2147592.2500 - lr: 0.0010\n",
            "Epoch 719/5000\n",
            "3/3 [==============================] - 0s 97ms/step - loss: 183.7489 - mae: 183.7489 - mse: 238485.2344 - val_loss: 959.2881 - val_mae: 959.2881 - val_mse: 2052568.8750 - lr: 0.0010\n",
            "Epoch 720/5000\n",
            "3/3 [==============================] - 0s 136ms/step - loss: 186.1018 - mae: 186.1018 - mse: 232049.3906 - val_loss: 990.6830 - val_mae: 990.6830 - val_mse: 2148625.2500 - lr: 0.0010\n",
            "Epoch 721/5000\n",
            "3/3 [==============================] - 0s 93ms/step - loss: 182.1734 - mae: 182.1734 - mse: 235774.2031 - val_loss: 959.7493 - val_mae: 959.7493 - val_mse: 2047864.6250 - lr: 0.0010\n",
            "Epoch 722/5000\n",
            "3/3 [==============================] - 0s 99ms/step - loss: 181.7581 - mae: 181.7581 - mse: 226146.8438 - val_loss: 975.7899 - val_mae: 975.7899 - val_mse: 2098972.7500 - lr: 0.0010\n",
            "Epoch 723/5000\n",
            "3/3 [==============================] - 0s 107ms/step - loss: 182.4959 - mae: 182.4959 - mse: 235175.9062 - val_loss: 966.5251 - val_mae: 966.5251 - val_mse: 2070047.6250 - lr: 0.0010\n",
            "Epoch 724/5000\n",
            "3/3 [==============================] - 0s 99ms/step - loss: 189.2048 - mae: 189.2048 - mse: 236266.0312 - val_loss: 983.8795 - val_mae: 983.8795 - val_mse: 2123470.5000 - lr: 0.0010\n",
            "Epoch 725/5000\n",
            "3/3 [==============================] - 0s 98ms/step - loss: 189.2890 - mae: 189.2890 - mse: 246695.9844 - val_loss: 963.3077 - val_mae: 963.3077 - val_mse: 2066169.6250 - lr: 0.0010\n",
            "Epoch 726/5000\n",
            "3/3 [==============================] - 0s 93ms/step - loss: 198.1274 - mae: 198.1274 - mse: 251309.1875 - val_loss: 1006.6021 - val_mae: 1006.6021 - val_mse: 2198221.0000 - lr: 0.0010\n",
            "Epoch 727/5000\n",
            "3/3 [==============================] - 0s 172ms/step - loss: 189.4733 - mae: 189.4733 - mse: 247993.1406 - val_loss: 958.7379 - val_mae: 958.7379 - val_mse: 2048147.7500 - lr: 0.0010\n",
            "Epoch 728/5000\n",
            "3/3 [==============================] - 0s 97ms/step - loss: 191.1348 - mae: 191.1348 - mse: 240021.5469 - val_loss: 1005.4653 - val_mae: 1005.4653 - val_mse: 2196078.7500 - lr: 0.0010\n",
            "Epoch 729/5000\n",
            "3/3 [==============================] - 0s 108ms/step - loss: 182.9403 - mae: 182.9403 - mse: 237103.2500 - val_loss: 957.7092 - val_mae: 957.7092 - val_mse: 2041530.8750 - lr: 0.0010\n",
            "Epoch 730/5000\n",
            "3/3 [==============================] - 0s 152ms/step - loss: 181.1556 - mae: 181.1556 - mse: 225061.1250 - val_loss: 974.3850 - val_mae: 974.3850 - val_mse: 2101453.7500 - lr: 0.0010\n",
            "Epoch 731/5000\n",
            "3/3 [==============================] - ETA: 0s - loss: 181.4962 - mae: 181.4962 - mse: 233941.4062\n",
            "Epoch 731: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "3/3 [==============================] - 0s 113ms/step - loss: 181.4962 - mae: 181.4962 - mse: 233941.4062 - val_loss: 962.4380 - val_mae: 962.4380 - val_mse: 2062144.6250 - lr: 0.0010\n",
            "Epoch 732/5000\n",
            "3/3 [==============================] - 0s 209ms/step - loss: 172.7890 - mae: 172.7890 - mse: 216556.2188 - val_loss: 974.0441 - val_mae: 974.0441 - val_mse: 2097731.2500 - lr: 1.0000e-04\n",
            "Epoch 733/5000\n",
            "3/3 [==============================] - 0s 177ms/step - loss: 173.1857 - mae: 173.1857 - mse: 216637.4062 - val_loss: 980.1498 - val_mae: 980.1498 - val_mse: 2114789.5000 - lr: 1.0000e-04\n",
            "Epoch 734/5000\n",
            "3/3 [==============================] - 0s 92ms/step - loss: 173.1187 - mae: 173.1187 - mse: 216668.1562 - val_loss: 975.0750 - val_mae: 975.0750 - val_mse: 2100563.0000 - lr: 1.0000e-04\n",
            "Epoch 735/5000\n",
            "3/3 [==============================] - 0s 92ms/step - loss: 172.6794 - mae: 172.6794 - mse: 216686.3281 - val_loss: 966.5482 - val_mae: 966.5482 - val_mse: 2075868.6250 - lr: 1.0000e-04\n",
            "Epoch 736/5000\n",
            "3/3 [==============================] - 0s 102ms/step - loss: 172.6110 - mae: 172.6110 - mse: 217095.6094 - val_loss: 961.8915 - val_mae: 961.8915 - val_mse: 2060197.6250 - lr: 1.0000e-04\n",
            "Epoch 737/5000\n",
            "3/3 [==============================] - 0s 169ms/step - loss: 172.7290 - mae: 172.7290 - mse: 217510.3281 - val_loss: 960.5317 - val_mae: 960.5317 - val_mse: 2054939.2500 - lr: 1.0000e-04\n",
            "Epoch 738/5000\n",
            "3/3 [==============================] - 0s 94ms/step - loss: 172.7377 - mae: 172.7377 - mse: 217474.1094 - val_loss: 960.9684 - val_mae: 960.9684 - val_mse: 2057219.2500 - lr: 1.0000e-04\n",
            "Epoch 739/5000\n",
            "3/3 [==============================] - 0s 91ms/step - loss: 172.6165 - mae: 172.6165 - mse: 217106.4531 - val_loss: 962.6111 - val_mae: 962.6111 - val_mse: 2063843.0000 - lr: 1.0000e-04\n",
            "Epoch 740/5000\n",
            "3/3 [==============================] - 0s 147ms/step - loss: 172.5265 - mae: 172.5265 - mse: 216809.4531 - val_loss: 964.4100 - val_mae: 964.4100 - val_mse: 2070396.7500 - lr: 1.0000e-04\n",
            "Epoch 741/5000\n",
            "3/3 [==============================] - 0s 96ms/step - loss: 172.5071 - mae: 172.5071 - mse: 216658.2812 - val_loss: 965.6894 - val_mae: 965.6894 - val_mse: 2074692.0000 - lr: 1.0000e-04\n",
            "Epoch 742/5000\n",
            "3/3 [==============================] - 0s 151ms/step - loss: 172.5159 - mae: 172.5159 - mse: 216600.8438 - val_loss: 965.9526 - val_mae: 965.9526 - val_mse: 2075904.7500 - lr: 1.0000e-04\n",
            "Epoch 743/5000\n",
            "3/3 [==============================] - 0s 114ms/step - loss: 172.4929 - mae: 172.4929 - mse: 216593.1406 - val_loss: 965.2517 - val_mae: 965.2517 - val_mse: 2074077.8750 - lr: 1.0000e-04\n",
            "Epoch 744/5000\n",
            "3/3 [==============================] - 0s 100ms/step - loss: 172.4532 - mae: 172.4532 - mse: 216640.8281 - val_loss: 964.1249 - val_mae: 964.1249 - val_mse: 2070777.0000 - lr: 1.0000e-04\n",
            "Epoch 745/5000\n",
            "3/3 [==============================] - 0s 197ms/step - loss: 172.4475 - mae: 172.4475 - mse: 216710.2031 - val_loss: 963.3105 - val_mae: 963.3105 - val_mse: 2068223.3750 - lr: 1.0000e-04\n",
            "Epoch 746/5000\n",
            "3/3 [==============================] - 0s 104ms/step - loss: 172.4527 - mae: 172.4527 - mse: 216760.4219 - val_loss: 962.8178 - val_mae: 962.8178 - val_mse: 2066690.1250 - lr: 1.0000e-04\n",
            "Epoch 747/5000\n",
            "3/3 [==============================] - 0s 105ms/step - loss: 172.4544 - mae: 172.4544 - mse: 216787.3750 - val_loss: 962.7098 - val_mae: 962.7098 - val_mse: 2066384.7500 - lr: 1.0000e-04\n",
            "Epoch 748/5000\n",
            "3/3 [==============================] - 0s 134ms/step - loss: 172.4459 - mae: 172.4459 - mse: 216742.5000 - val_loss: 963.0664 - val_mae: 963.0664 - val_mse: 2067670.3750 - lr: 1.0000e-04\n",
            "Epoch 749/5000\n",
            "3/3 [==============================] - 0s 127ms/step - loss: 172.4336 - mae: 172.4336 - mse: 216671.2656 - val_loss: 963.5292 - val_mae: 963.5292 - val_mse: 2069233.1250 - lr: 1.0000e-04\n",
            "Epoch 750/5000\n",
            "3/3 [==============================] - 0s 97ms/step - loss: 172.4243 - mae: 172.4243 - mse: 216629.5625 - val_loss: 963.8609 - val_mae: 963.8609 - val_mse: 2070333.0000 - lr: 1.0000e-04\n",
            "Epoch 751/5000\n",
            "3/3 [==============================] - 0s 94ms/step - loss: 172.4158 - mae: 172.4158 - mse: 216600.3906 - val_loss: 964.0842 - val_mae: 964.0842 - val_mse: 2071020.8750 - lr: 1.0000e-04\n",
            "Epoch 752/5000\n",
            "3/3 [==============================] - 0s 118ms/step - loss: 172.4050 - mae: 172.4050 - mse: 216593.5781 - val_loss: 964.0901 - val_mae: 964.0901 - val_mse: 2070939.7500 - lr: 1.0000e-04\n",
            "Epoch 753/5000\n",
            "3/3 [==============================] - 0s 97ms/step - loss: 172.4053 - mae: 172.4053 - mse: 216595.4375 - val_loss: 964.0267 - val_mae: 964.0267 - val_mse: 2070639.3750 - lr: 1.0000e-04\n",
            "Epoch 754/5000\n",
            "3/3 [==============================] - 0s 92ms/step - loss: 172.4056 - mae: 172.4056 - mse: 216594.5312 - val_loss: 963.8607 - val_mae: 963.8607 - val_mse: 2070007.1250 - lr: 1.0000e-04\n",
            "Epoch 755/5000\n",
            "3/3 [==============================] - 0s 127ms/step - loss: 172.4071 - mae: 172.4071 - mse: 216636.4688 - val_loss: 963.5561 - val_mae: 963.5561 - val_mse: 2068918.6250 - lr: 1.0000e-04\n",
            "Epoch 756/5000\n",
            "3/3 [==============================] - 0s 164ms/step - loss: 172.3988 - mae: 172.3988 - mse: 216631.9844 - val_loss: 963.4199 - val_mae: 963.4199 - val_mse: 2068551.5000 - lr: 1.0000e-04\n",
            "Epoch 757/5000\n",
            "3/3 [==============================] - 0s 97ms/step - loss: 172.3959 - mae: 172.3959 - mse: 216605.0625 - val_loss: 963.4254 - val_mae: 963.4254 - val_mse: 2068643.2500 - lr: 1.0000e-04\n",
            "Epoch 758/5000\n",
            "3/3 [==============================] - 0s 96ms/step - loss: 172.3927 - mae: 172.3927 - mse: 216611.0312 - val_loss: 963.4514 - val_mae: 963.4514 - val_mse: 2068761.1250 - lr: 1.0000e-04\n",
            "Epoch 759/5000\n",
            "3/3 [==============================] - 0s 113ms/step - loss: 172.3880 - mae: 172.3880 - mse: 216587.8125 - val_loss: 963.6154 - val_mae: 963.6154 - val_mse: 2069356.0000 - lr: 1.0000e-04\n",
            "Epoch 760/5000\n",
            "3/3 [==============================] - 0s 104ms/step - loss: 172.3822 - mae: 172.3822 - mse: 216543.5000 - val_loss: 963.7434 - val_mae: 963.7434 - val_mse: 2069831.2500 - lr: 1.0000e-04\n",
            "Epoch 761/5000\n",
            "3/3 [==============================] - 0s 101ms/step - loss: 172.3717 - mae: 172.3717 - mse: 216551.2344 - val_loss: 963.7097 - val_mae: 963.7097 - val_mse: 2069706.1250 - lr: 1.0000e-04\n",
            "Epoch 762/5000\n",
            "3/3 [==============================] - 0s 211ms/step - loss: 172.3662 - mae: 172.3662 - mse: 216539.6719 - val_loss: 963.8472 - val_mae: 963.8472 - val_mse: 2070092.8750 - lr: 1.0000e-04\n",
            "Epoch 763/5000\n",
            "3/3 [==============================] - 0s 96ms/step - loss: 172.3708 - mae: 172.3708 - mse: 216525.0781 - val_loss: 963.8727 - val_mae: 963.8727 - val_mse: 2070099.6250 - lr: 1.0000e-04\n",
            "Epoch 764/5000\n",
            "3/3 [==============================] - 0s 93ms/step - loss: 172.3734 - mae: 172.3734 - mse: 216581.4219 - val_loss: 963.7085 - val_mae: 963.7085 - val_mse: 2069581.1250 - lr: 1.0000e-04\n",
            "Epoch 765/5000\n",
            "3/3 [==============================] - 0s 125ms/step - loss: 172.3845 - mae: 172.3845 - mse: 216551.4688 - val_loss: 963.6908 - val_mae: 963.6908 - val_mse: 2069653.8750 - lr: 1.0000e-04\n",
            "Epoch 766/5000\n",
            "3/3 [==============================] - 0s 173ms/step - loss: 172.3671 - mae: 172.3671 - mse: 216508.2969 - val_loss: 963.5873 - val_mae: 963.5873 - val_mse: 2069396.7500 - lr: 1.0000e-04\n",
            "Epoch 767/5000\n",
            "3/3 [==============================] - 0s 116ms/step - loss: 172.3519 - mae: 172.3519 - mse: 216523.9844 - val_loss: 963.2648 - val_mae: 963.2648 - val_mse: 2068276.5000 - lr: 1.0000e-04\n",
            "Epoch 768/5000\n",
            "3/3 [==============================] - 0s 177ms/step - loss: 172.3654 - mae: 172.3654 - mse: 216560.2344 - val_loss: 963.1580 - val_mae: 963.1580 - val_mse: 2067854.8750 - lr: 1.0000e-04\n",
            "Epoch 769/5000\n",
            "3/3 [==============================] - 0s 95ms/step - loss: 172.3713 - mae: 172.3713 - mse: 216530.8906 - val_loss: 963.5242 - val_mae: 963.5242 - val_mse: 2069071.0000 - lr: 1.0000e-04\n",
            "Epoch 770/5000\n",
            "3/3 [==============================] - 0s 99ms/step - loss: 172.3537 - mae: 172.3537 - mse: 216473.4219 - val_loss: 964.0945 - val_mae: 964.0945 - val_mse: 2070865.3750 - lr: 1.0000e-04\n",
            "Epoch 771/5000\n",
            "3/3 [==============================] - 0s 133ms/step - loss: 172.3409 - mae: 172.3409 - mse: 216432.9844 - val_loss: 964.3924 - val_mae: 964.3924 - val_mse: 2071772.1250 - lr: 1.0000e-04\n",
            "Epoch 772/5000\n",
            "3/3 [==============================] - 0s 175ms/step - loss: 172.3453 - mae: 172.3453 - mse: 216447.4219 - val_loss: 964.0864 - val_mae: 964.0864 - val_mse: 2070735.2500 - lr: 1.0000e-04\n",
            "Epoch 773/5000\n",
            "3/3 [==============================] - 0s 111ms/step - loss: 172.3450 - mae: 172.3450 - mse: 216508.6875 - val_loss: 963.6547 - val_mae: 963.6547 - val_mse: 2069337.6250 - lr: 1.0000e-04\n",
            "Epoch 774/5000\n",
            "3/3 [==============================] - 0s 114ms/step - loss: 172.3417 - mae: 172.3417 - mse: 216491.4219 - val_loss: 963.4132 - val_mae: 963.4132 - val_mse: 2068598.7500 - lr: 1.0000e-04\n",
            "Epoch 775/5000\n",
            "3/3 [==============================] - 0s 134ms/step - loss: 172.3374 - mae: 172.3374 - mse: 216496.3281 - val_loss: 963.3891 - val_mae: 963.3891 - val_mse: 2068559.3750 - lr: 1.0000e-04\n",
            "Epoch 776/5000\n",
            "3/3 [==============================] - 0s 99ms/step - loss: 172.3344 - mae: 172.3344 - mse: 216467.9062 - val_loss: 963.6255 - val_mae: 963.6255 - val_mse: 2069305.7500 - lr: 1.0000e-04\n",
            "Epoch 777/5000\n",
            "3/3 [==============================] - 0s 111ms/step - loss: 172.3277 - mae: 172.3277 - mse: 216437.0625 - val_loss: 963.9307 - val_mae: 963.9307 - val_mse: 2070223.0000 - lr: 1.0000e-04\n",
            "Epoch 778/5000\n",
            "3/3 [==============================] - 0s 151ms/step - loss: 172.3280 - mae: 172.3280 - mse: 216411.0469 - val_loss: 964.0284 - val_mae: 964.0284 - val_mse: 2070440.8750 - lr: 1.0000e-04\n",
            "Epoch 779/5000\n",
            "3/3 [==============================] - 0s 114ms/step - loss: 172.3328 - mae: 172.3328 - mse: 216447.8125 - val_loss: 963.9288 - val_mae: 963.9288 - val_mse: 2070054.8750 - lr: 1.0000e-04\n",
            "Epoch 780/5000\n",
            "3/3 [==============================] - 0s 124ms/step - loss: 172.3323 - mae: 172.3323 - mse: 216419.1562 - val_loss: 963.8531 - val_mae: 963.8531 - val_mse: 2069844.2500 - lr: 1.0000e-04\n",
            "Epoch 781/5000\n",
            "3/3 [==============================] - 0s 137ms/step - loss: 172.3233 - mae: 172.3233 - mse: 216425.1875 - val_loss: 963.7982 - val_mae: 963.7982 - val_mse: 2069669.6250 - lr: 1.0000e-04\n",
            "Epoch 782/5000\n",
            "3/3 [==============================] - 0s 94ms/step - loss: 172.3126 - mae: 172.3126 - mse: 216411.3125 - val_loss: 963.8888 - val_mae: 963.8888 - val_mse: 2069914.7500 - lr: 1.0000e-04\n",
            "Epoch 783/5000\n",
            "3/3 [==============================] - 0s 131ms/step - loss: 172.3163 - mae: 172.3163 - mse: 216397.2188 - val_loss: 963.8495 - val_mae: 963.8495 - val_mse: 2069743.0000 - lr: 1.0000e-04\n",
            "Epoch 784/5000\n",
            "3/3 [==============================] - 1s 227ms/step - loss: 172.3162 - mae: 172.3162 - mse: 216425.3906 - val_loss: 963.7526 - val_mae: 963.7526 - val_mse: 2069425.1250 - lr: 1.0000e-04\n",
            "Epoch 785/5000\n",
            "3/3 [==============================] - 0s 195ms/step - loss: 172.3142 - mae: 172.3142 - mse: 216392.1094 - val_loss: 963.7631 - val_mae: 963.7631 - val_mse: 2069471.2500 - lr: 1.0000e-04\n",
            "Epoch 786/5000\n",
            "3/3 [==============================] - 1s 280ms/step - loss: 172.3047 - mae: 172.3047 - mse: 216399.9531 - val_loss: 963.7314 - val_mae: 963.7314 - val_mse: 2069291.6250 - lr: 1.0000e-04\n",
            "Epoch 787/5000\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 172.3046 - mae: 172.3046 - mse: 216391.3906 - val_loss: 963.8431 - val_mae: 963.8431 - val_mse: 2069559.3750 - lr: 1.0000e-04\n",
            "Epoch 788/5000\n",
            "3/3 [==============================] - 0s 206ms/step - loss: 172.3049 - mae: 172.3049 - mse: 216368.3125 - val_loss: 963.9429 - val_mae: 963.9429 - val_mse: 2069848.1250 - lr: 1.0000e-04\n",
            "Epoch 789/5000\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 172.2997 - mae: 172.2997 - mse: 216380.8594 - val_loss: 963.9927 - val_mae: 963.9927 - val_mse: 2070031.8750 - lr: 1.0000e-04\n",
            "Epoch 790/5000\n",
            "3/3 [==============================] - 0s 179ms/step - loss: 172.2967 - mae: 172.2967 - mse: 216341.1094 - val_loss: 963.9138 - val_mae: 963.9138 - val_mse: 2069819.6250 - lr: 1.0000e-04\n",
            "Epoch 791/5000\n",
            "3/3 [==============================] - 1s 303ms/step - loss: 172.2972 - mae: 172.2972 - mse: 216374.7969 - val_loss: 963.6815 - val_mae: 963.6815 - val_mse: 2069041.7500 - lr: 1.0000e-04\n",
            "Epoch 792/5000\n",
            "3/3 [==============================] - 0s 175ms/step - loss: 172.2944 - mae: 172.2944 - mse: 216362.1094 - val_loss: 963.6417 - val_mae: 963.6417 - val_mse: 2068879.1250 - lr: 1.0000e-04\n",
            "Epoch 793/5000\n",
            "3/3 [==============================] - 0s 204ms/step - loss: 172.2893 - mae: 172.2893 - mse: 216372.8906 - val_loss: 963.7187 - val_mae: 963.7187 - val_mse: 2069163.1250 - lr: 1.0000e-04\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 794/5000\n",
            "3/3 [==============================] - 0s 130ms/step - loss: 172.2845 - mae: 172.2845 - mse: 216327.8281 - val_loss: 963.8207 - val_mae: 963.8207 - val_mse: 2069562.8750 - lr: 1.0000e-04\n",
            "Epoch 795/5000\n",
            "3/3 [==============================] - 0s 109ms/step - loss: 172.2913 - mae: 172.2913 - mse: 216341.4844 - val_loss: 963.8523 - val_mae: 963.8523 - val_mse: 2069663.7500 - lr: 1.0000e-04\n",
            "Epoch 796/5000\n",
            "3/3 [==============================] - 0s 203ms/step - loss: 172.2850 - mae: 172.2850 - mse: 216305.7656 - val_loss: 963.8138 - val_mae: 963.8138 - val_mse: 2069499.7500 - lr: 1.0000e-04\n",
            "Epoch 797/5000\n",
            "3/3 [==============================] - 0s 121ms/step - loss: 172.2721 - mae: 172.2721 - mse: 216332.7188 - val_loss: 963.7073 - val_mae: 963.7073 - val_mse: 2069142.6250 - lr: 1.0000e-04\n",
            "Epoch 798/5000\n",
            "3/3 [==============================] - 0s 130ms/step - loss: 172.2760 - mae: 172.2760 - mse: 216302.4375 - val_loss: 963.8271 - val_mae: 963.8271 - val_mse: 2069553.7500 - lr: 1.0000e-04\n",
            "Epoch 799/5000\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 172.2824 - mae: 172.2824 - mse: 216357.7031 - val_loss: 963.7769 - val_mae: 963.7769 - val_mse: 2069318.5000 - lr: 1.0000e-04\n",
            "Epoch 800/5000\n",
            "3/3 [==============================] - 0s 135ms/step - loss: 172.2783 - mae: 172.2783 - mse: 216336.2656 - val_loss: 963.7481 - val_mae: 963.7481 - val_mse: 2069254.3750 - lr: 1.0000e-04\n",
            "Epoch 801/5000\n",
            "3/3 [==============================] - 0s 135ms/step - loss: 172.2876 - mae: 172.2876 - mse: 216286.1406 - val_loss: 963.6996 - val_mae: 963.6996 - val_mse: 2069144.2500 - lr: 1.0000e-04\n",
            "Epoch 802/5000\n",
            "3/3 [==============================] - 0s 155ms/step - loss: 172.2668 - mae: 172.2668 - mse: 216290.8281 - val_loss: 963.4540 - val_mae: 963.4540 - val_mse: 2068376.3750 - lr: 1.0000e-04\n",
            "Epoch 803/5000\n",
            "3/3 [==============================] - 0s 149ms/step - loss: 172.2853 - mae: 172.2853 - mse: 216334.1875 - val_loss: 963.4034 - val_mae: 963.4034 - val_mse: 2068247.0000 - lr: 1.0000e-04\n",
            "Epoch 804/5000\n",
            "3/3 [==============================] - 0s 213ms/step - loss: 172.2845 - mae: 172.2845 - mse: 216279.4219 - val_loss: 963.7247 - val_mae: 963.7247 - val_mse: 2069355.5000 - lr: 1.0000e-04\n",
            "Epoch 805/5000\n",
            "3/3 [==============================] - 1s 210ms/step - loss: 172.2715 - mae: 172.2716 - mse: 216222.7031 - val_loss: 963.9342 - val_mae: 963.9342 - val_mse: 2070006.8750 - lr: 1.0000e-04\n",
            "Epoch 806/5000\n",
            "3/3 [==============================] - 0s 164ms/step - loss: 172.2552 - mae: 172.2552 - mse: 216248.9531 - val_loss: 963.5668 - val_mae: 963.5668 - val_mse: 2068732.3750 - lr: 1.0000e-04\n",
            "Epoch 807/5000\n",
            "3/3 [==============================] - 1s 232ms/step - loss: 172.2742 - mae: 172.2742 - mse: 216360.1250 - val_loss: 963.2516 - val_mae: 963.2516 - val_mse: 2067642.6250 - lr: 1.0000e-04\n",
            "Epoch 808/5000\n",
            "3/3 [==============================] - 0s 153ms/step - loss: 172.2736 - mae: 172.2736 - mse: 216330.1719 - val_loss: 963.3442 - val_mae: 963.3442 - val_mse: 2068155.6250 - lr: 1.0000e-04\n",
            "Epoch 809/5000\n",
            "3/3 [==============================] - 0s 160ms/step - loss: 172.2695 - mae: 172.2695 - mse: 216241.3750 - val_loss: 963.4778 - val_mae: 963.4778 - val_mse: 2068738.3750 - lr: 1.0000e-04\n",
            "Epoch 810/5000\n",
            "3/3 [==============================] - 0s 135ms/step - loss: 172.2483 - mae: 172.2483 - mse: 216246.6250 - val_loss: 963.2920 - val_mae: 963.2920 - val_mse: 2068133.1250 - lr: 1.0000e-04\n",
            "Epoch 811/5000\n",
            "3/3 [==============================] - 0s 144ms/step - loss: 172.2689 - mae: 172.2689 - mse: 216309.7812 - val_loss: 963.2266 - val_mae: 963.2266 - val_mse: 2067850.8750 - lr: 1.0000e-04\n",
            "Epoch 812/5000\n",
            "3/3 [==============================] - 0s 156ms/step - loss: 172.2695 - mae: 172.2695 - mse: 216260.0156 - val_loss: 963.4747 - val_mae: 963.4747 - val_mse: 2068752.6250 - lr: 1.0000e-04\n",
            "Epoch 813/5000\n",
            "3/3 [==============================] - 0s 148ms/step - loss: 172.2672 - mae: 172.2672 - mse: 216191.8594 - val_loss: 963.6992 - val_mae: 963.6992 - val_mse: 2069494.5000 - lr: 1.0000e-04\n",
            "Epoch 814/5000\n",
            "3/3 [==============================] - 0s 162ms/step - loss: 172.2421 - mae: 172.2421 - mse: 216206.7188 - val_loss: 963.4752 - val_mae: 963.4752 - val_mse: 2068701.7500 - lr: 1.0000e-04\n",
            "Epoch 815/5000\n",
            "3/3 [==============================] - 0s 143ms/step - loss: 172.2427 - mae: 172.2427 - mse: 216286.7969 - val_loss: 963.2548 - val_mae: 963.2548 - val_mse: 2067885.3750 - lr: 1.0000e-04\n",
            "Epoch 816/5000\n",
            "3/3 [==============================] - 0s 149ms/step - loss: 172.2434 - mae: 172.2434 - mse: 216270.2656 - val_loss: 963.2982 - val_mae: 963.2982 - val_mse: 2068127.6250 - lr: 1.0000e-04\n",
            "Epoch 817/5000\n",
            "3/3 [==============================] - 1s 321ms/step - loss: 172.2403 - mae: 172.2403 - mse: 216214.5000 - val_loss: 963.4370 - val_mae: 963.4370 - val_mse: 2068643.0000 - lr: 1.0000e-04\n",
            "Epoch 818/5000\n",
            "3/3 [==============================] - 0s 125ms/step - loss: 172.2329 - mae: 172.2329 - mse: 216244.6406 - val_loss: 963.4440 - val_mae: 963.4440 - val_mse: 2068645.3750 - lr: 1.0000e-04\n",
            "Epoch 819/5000\n",
            "3/3 [==============================] - 1s 259ms/step - loss: 172.2282 - mae: 172.2282 - mse: 216215.3438 - val_loss: 963.3503 - val_mae: 963.3503 - val_mse: 2068381.0000 - lr: 1.0000e-04\n",
            "Epoch 820/5000\n",
            "3/3 [==============================] - 0s 101ms/step - loss: 172.2314 - mae: 172.2314 - mse: 216236.4531 - val_loss: 963.2748 - val_mae: 963.2748 - val_mse: 2068199.2500 - lr: 1.0000e-04\n",
            "Epoch 821/5000\n",
            "3/3 [==============================] - 0s 195ms/step - loss: 172.2466 - mae: 172.2466 - mse: 216196.7656 - val_loss: 963.3687 - val_mae: 963.3687 - val_mse: 2068570.0000 - lr: 1.0000e-04\n",
            "Epoch 822/5000\n",
            "3/3 [==============================] - 1s 219ms/step - loss: 172.2300 - mae: 172.2300 - mse: 216204.3906 - val_loss: 963.3001 - val_mae: 963.3001 - val_mse: 2068236.6250 - lr: 1.0000e-04\n",
            "Epoch 823/5000\n",
            "3/3 [==============================] - 0s 165ms/step - loss: 172.2464 - mae: 172.2464 - mse: 216282.0781 - val_loss: 963.2893 - val_mae: 963.2893 - val_mse: 2068091.5000 - lr: 1.0000e-04\n",
            "Epoch 824/5000\n",
            "3/3 [==============================] - 0s 190ms/step - loss: 172.2309 - mae: 172.2309 - mse: 216229.1875 - val_loss: 963.4280 - val_mae: 963.4280 - val_mse: 2068646.7500 - lr: 1.0000e-04\n",
            "Epoch 825/5000\n",
            "3/3 [==============================] - 0s 185ms/step - loss: 172.2364 - mae: 172.2364 - mse: 216170.8438 - val_loss: 963.3713 - val_mae: 963.3713 - val_mse: 2068458.2500 - lr: 1.0000e-04\n",
            "Epoch 826/5000\n",
            "3/3 [==============================] - 0s 156ms/step - loss: 172.2189 - mae: 172.2189 - mse: 216205.0469 - val_loss: 963.1011 - val_mae: 963.1011 - val_mse: 2067510.2500 - lr: 1.0000e-04\n",
            "Epoch 827/5000\n",
            "3/3 [==============================] - 0s 126ms/step - loss: 172.2311 - mae: 172.2311 - mse: 216274.3281 - val_loss: 963.0613 - val_mae: 963.0613 - val_mse: 2067409.3750 - lr: 1.0000e-04\n",
            "Epoch 828/5000\n",
            "3/3 [==============================] - 0s 137ms/step - loss: 172.2323 - mae: 172.2323 - mse: 216236.5625 - val_loss: 963.2625 - val_mae: 963.2625 - val_mse: 2068274.0000 - lr: 1.0000e-04\n",
            "Epoch 829/5000\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 172.2150 - mae: 172.2150 - mse: 216154.7031 - val_loss: 963.3468 - val_mae: 963.3468 - val_mse: 2068640.1250 - lr: 1.0000e-04\n",
            "Epoch 830/5000\n",
            "3/3 [==============================] - 0s 106ms/step - loss: 172.2031 - mae: 172.2031 - mse: 216172.4062 - val_loss: 963.1332 - val_mae: 963.1332 - val_mse: 2067821.7500 - lr: 1.0000e-04\n",
            "Epoch 831/5000\n",
            "2/3 [===================>..........] - ETA: 0s - loss: 99.0902 - mae: 99.0902 - mse: 63170.2734\n",
            "Epoch 831: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "3/3 [==============================] - 1s 220ms/step - loss: 172.2169 - mae: 172.2169 - mse: 216223.3594 - val_loss: 963.0594 - val_mae: 963.0594 - val_mse: 2067404.5000 - lr: 1.0000e-04\n"
          ]
        }
      ],
      "source": [
        "history_model_univariate_2 = model_univariate_2.fit(\n",
        "    train_dataset,\n",
        "    epochs=5000,\n",
        "    validation_data=test_dataset,\n",
        "    callbacks=[\n",
        "        create_model_checkpoint(model_name=model_univariate_2.name),\n",
        "        create_tensorboard_callback(\n",
        "            dir_name='tensorboard_logs',\n",
        "            experiment_name=model_univariate_2.name\n",
        "        ),\n",
        "        early_stopping,\n",
        "        reduce_lr_plateau,\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f277059",
      "metadata": {},
      "source": [
        "Results are so much better, but this is just a single model.\n",
        "\n",
        "An ensemble would perform better, as it has the \"vote of majority\", and it can provide a range of predictions, which is what we want"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c89a744",
      "metadata": {},
      "source": [
        "### Create ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "787947d9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a function to create an ensemble of models\n",
        "def create_ensemble(\n",
        "    num_models=10,\n",
        "    num_epochs=5000,\n",
        "    horizon=HORIZON,\n",
        "    train_data=train_dataset,\n",
        "    test_data=test_dataset,\n",
        "    loss_fns=['mae', 'mse', 'mape']\n",
        "):\n",
        "    ensemble = []\n",
        "\n",
        "    for i in range(num_models):\n",
        "        for loss_fn in loss_fns:\n",
        "            print(f'Model loss: {loss_fn} | model number: {i}')\n",
        "            model = tf.keras.Sequential([\n",
        "                tf.keras.layers.Input(\n",
        "                    shape=(WINDOW_SIZE)\n",
        "                ),\n",
        "                tf.keras.layers.Lambda(\n",
        "                    lambda x: tf.expand_dims(x, axis=1)\n",
        "                ),\n",
        "                tf.keras.layers.RNN(\n",
        "                    LTSCell(16),\n",
        "                    time_major=True,\n",
        "                    return_sequences=True\n",
        "                ),\n",
        "                tf.keras.layers.LSTM(\n",
        "                    16,\n",
        "                    activation='relu'\n",
        "                ),\n",
        "                tf.keras.layers.Dense(\n",
        "                    128,\n",
        "                    \n",
        "                    # This is required for the prediction intervals\n",
        "                    kernel_initializer='he_normal',\n",
        "                    activation='relu'\n",
        "                ),\n",
        "                tf.keras.layers.Dense(\n",
        "                    128,\n",
        "                    kernel_initializer='he_normal',\n",
        "                    activation='relu'\n",
        "                ),\n",
        "                tf.keras.layers.Dense(HORIZON)\n",
        "            ])\n",
        "\n",
        "            model.compile(\n",
        "                loss=loss_fn,\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['mae', 'mse']\n",
        "            )\n",
        "\n",
        "            model.fit(\n",
        "                train_data,\n",
        "                epochs=num_epochs,\n",
        "                verbose=0,\n",
        "                validation_data=test_data,\n",
        "                callbacks=[\n",
        "                    early_stopping,\n",
        "                    reduce_lr_plateau\n",
        "                ]\n",
        "            )\n",
        "\n",
        "            ensemble.append(model)\n",
        "\n",
        "    return ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "28e08817",
      "metadata": {
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loss: mae | model number: 0\n",
            "\n",
            "Epoch 247: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 508: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "\n",
            "Epoch 608: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "Model loss: mse | model number: 0\n",
            "\n",
            "Epoch 445: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 545: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Model loss: mape | model number: 0\n",
            "\n",
            "Epoch 188: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 288: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Model loss: mae | model number: 1\n",
            "\n",
            "Epoch 797: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 897: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Model loss: mse | model number: 1\n",
            "\n",
            "Epoch 127: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 227: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Model loss: mape | model number: 1\n",
            "\n",
            "Epoch 202: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 303: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "\n",
            "Epoch 403: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "Model loss: mae | model number: 2\n",
            "\n",
            "Epoch 310: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 1157: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "\n",
            "Epoch 1257: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "Model loss: mse | model number: 2\n",
            "\n",
            "Epoch 185: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 285: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Model loss: mape | model number: 2\n",
            "\n",
            "Epoch 120: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 1018: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "\n",
            "Epoch 1119: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "\n",
            "Epoch 1219: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
            "Model loss: mae | model number: 3\n",
            "\n",
            "Epoch 768: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 868: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Model loss: mse | model number: 3\n",
            "\n",
            "Epoch 297: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 397: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Model loss: mape | model number: 3\n",
            "\n",
            "Epoch 218: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 332: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "\n",
            "Epoch 432: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "Model loss: mae | model number: 4\n",
            "\n",
            "Epoch 1030: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 1130: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Model loss: mse | model number: 4\n",
            "\n",
            "Epoch 237: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 337: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Model loss: mape | model number: 4\n",
            "\n",
            "Epoch 142: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 591: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "\n",
            "Epoch 691: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "Model loss: mae | model number: 5\n",
            "\n",
            "Epoch 270: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 548: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "\n",
            "Epoch 648: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "Model loss: mse | model number: 5\n",
            "\n",
            "Epoch 402: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 519: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "\n",
            "Epoch 619: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "Model loss: mape | model number: 5\n",
            "\n",
            "Epoch 252: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 361: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "\n",
            "Epoch 461: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "Model loss: mae | model number: 6\n",
            "\n",
            "Epoch 391: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 810: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "\n",
            "Epoch 910: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "Model loss: mse | model number: 6\n",
            "\n",
            "Epoch 501: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 601: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Model loss: mape | model number: 6\n",
            "\n",
            "Epoch 108: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 560: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "\n",
            "Epoch 667: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "\n",
            "Epoch 767: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
            "Model loss: mae | model number: 7\n",
            "\n",
            "Epoch 695: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 795: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Model loss: mse | model number: 7\n",
            "\n",
            "Epoch 396: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 496: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Model loss: mape | model number: 7\n",
            "\n",
            "Epoch 123: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 616: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "\n",
            "Epoch 722: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "\n",
            "Epoch 822: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
            "Model loss: mae | model number: 8\n",
            "\n",
            "Epoch 729: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 842: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "\n",
            "Epoch 942: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "Model loss: mse | model number: 8\n",
            "\n",
            "Epoch 289: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 389: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Model loss: mape | model number: 8\n",
            "\n",
            "Epoch 377: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 864: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "\n",
            "Epoch 964: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "Model loss: mae | model number: 9\n",
            "\n",
            "Epoch 1907: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 2007: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Model loss: mse | model number: 9\n",
            "\n",
            "Epoch 478: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 578: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Model loss: mape | model number: 9\n",
            "\n",
            "Epoch 279: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\n",
            "Epoch 700: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "\n",
            "Epoch 800: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n"
          ]
        }
      ],
      "source": [
        "ensemble = create_ensemble()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "50c32567",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(ensemble)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "995e7dae",
      "metadata": {},
      "source": [
        "A total of 30 models have been made"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "7ed04547",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a function to return a list of predictions from an emsemble\n",
        "def make_ensemble_preds(ensemble, data):\n",
        "    preds = []\n",
        "    for model in ensemble:\n",
        "        preds.append(model.predict(data))\n",
        "        \n",
        "    return tf.constant(tf.squeeze(preds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "557810d0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 119ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 98ms/step\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000275A10F0048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000275A10F0048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 83ms/step\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000027598DE9438> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000027598DE9438> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 188ms/step\n",
            "1/1 [==============================] - 0s 90ms/step\n",
            "1/1 [==============================] - 0s 169ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 189ms/step\n",
            "1/1 [==============================] - 0s 310ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 147ms/step\n",
            "1/1 [==============================] - 0s 157ms/step\n",
            "1/1 [==============================] - 0s 285ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 110ms/step\n",
            "1/1 [==============================] - 0s 199ms/step\n",
            "1/1 [==============================] - 0s 251ms/step\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 173ms/step\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 179ms/step\n",
            "1/1 [==============================] - 0s 196ms/step\n",
            "1/1 [==============================] - 0s 194ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(30, 661), dtype=float32, numpy=\n",
              "array([[57035.355, 58158.215, 59021.92 , ..., 22903.691, 22831.457,\n",
              "        22909.37 ],\n",
              "       [57116.96 , 58013.223, 58804.844, ..., 22828.314, 22914.988,\n",
              "        22763.43 ],\n",
              "       [56927.74 , 58000.676, 58815.957, ..., 22932.383, 22810.992,\n",
              "        22859.123],\n",
              "       ...,\n",
              "       [57211.613, 57910.594, 59006.145, ..., 22814.637, 22662.574,\n",
              "        22718.19 ],\n",
              "       [56765.805, 57777.63 , 58496.543, ..., 22759.797, 22820.76 ,\n",
              "        22875.621],\n",
              "       [57141.965, 58069.81 , 58894.27 , ..., 22897.664, 22763.055,\n",
              "        22868.922]], dtype=float32)>"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_preds = make_ensemble_preds(\n",
        "    ensemble,\n",
        "    test_dataset\n",
        ")\n",
        "\n",
        "ensemble_preds"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bcac94a",
      "metadata": {},
      "source": [
        "There are 30 sets of predictions, each for each model. To get the best set of predictions, the Median can be taken.\n",
        "\n",
        "The median is more robust than the mean as it is not sensitive to outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "b1a7f9ad",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([57050.434, 58002.13 , 58831.17 , 57981.777, 55911.79 , 57750.715,\n",
              "       58073.434, 59716.098, 59966.324, 59863.79 ], dtype=float32)"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.median(\n",
        "    ensemble_preds,\n",
        "    axis=0\n",
        ")[:10],\n",
        "\n",
        "np.mean(\n",
        "    ensemble_preds,\n",
        "    axis=0\n",
        ")[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a1ee069",
      "metadata": {},
      "source": [
        "Based on the above it can be noticed that the median set of predictions and the mean are different"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e0f5a95",
      "metadata": {},
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "id": "832a3fe8",
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "Create MASE function (Not in tf API)\n",
        "recommended in the time series forecasting book\n",
        "https://otexts.com/fpp3/intro.html\n",
        "\n",
        "btc price forecasting in non-seasonal\n",
        "shift by 1 cuz seasonality is 1 day (collect data each day)\n",
        "'''\n",
        "def mean_absolute_scaled_error(y_true, y_pred):\n",
        "    # Better to perform tf subtraction due to nan possibilities\n",
        "    mae = tf.reduce_mean(\n",
        "        tf.abs(tf.subtract(y_true, y_pred))\n",
        "    )\n",
        "    mae_naive_no_season = tf.reduce_mean(\n",
        "        tf.abs(tf.subtract(y_true[1:], y_true[:-1]))\n",
        "    )\n",
        "    \n",
        "    return mae / mae_naive_no_season\n",
        "\n",
        "# Create a function to evaluate the predictions against the test set\n",
        "def evaluate(y_true, y_pred):\n",
        "    mae = tf.keras.metrics.mean_absolute_error(\n",
        "        y_true,\n",
        "        y_pred\n",
        "    )\n",
        "    mse = tf.keras.metrics.mean_squared_error(\n",
        "        y_true,\n",
        "        y_pred\n",
        "    )\n",
        "    mape = tf.keras.metrics.mean_absolute_percentage_error(\n",
        "        y_true,\n",
        "        y_pred\n",
        "    )\n",
        "    rmse = tf.sqrt(mse)\n",
        "    mase = mean_absolute_scaled_error(y_true, y_pred)\n",
        "    \n",
        "    return {\n",
        "        'mae': mae.numpy(),\n",
        "        'mse': mse.numpy(),\n",
        "        'rmse': rmse.numpy(),\n",
        "        'mape': f'{mape.numpy()}%',\n",
        "        'mase': mase.numpy(),\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "id": "995b3791",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'mae': 950.30084,\n",
              " 'mse': 2013928.4,\n",
              " 'rmse': 1419.1294,\n",
              " 'mape': '2.557239532470703%',\n",
              " 'mase': 0.99826974}"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "median_preds = np.median(\n",
        "    ensemble_preds,\n",
        "    axis=0\n",
        ")\n",
        "\n",
        "ensemble_results = evaluate(\n",
        "    y_test,\n",
        "    median_preds\n",
        ")\n",
        "\n",
        "ensemble_results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75abaefb",
      "metadata": {},
      "source": [
        "This is a fantastic result, as it is usually very difficult to even get a value close to 1 for the MASE value. The MASE value for naive forecast is very close/exactly 1. In open market forecasting, its always difficult to surpass the naive forecast\n",
        "\n",
        "* The naive forecast is using yesterdays value as tomorrows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "id": "1a38eb15",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'mae': 951.94794,\n",
              " 'mse': 2021966.0,\n",
              " 'rmse': 1421.9585,\n",
              " 'mape': '2.5654945373535156%',\n",
              " 'mase': 0.99974763}"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create naive forecast prediction as proof\n",
        "naive_forecast = y_test[:-1]\n",
        "naive_forecast_results = evaluate(y_test[1:], naive_forecast)\n",
        "naive_forecast_results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4cffe49",
      "metadata": {},
      "source": [
        "The ensemble's best model has surpassed the naive forecast."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "id": "6a2dd00d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_0\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_0\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_1\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_1\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_2\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_2\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_3\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_3\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_4\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_4\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_5\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_5\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_6\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_6\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_7\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_7\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_8\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_8\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_9\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_9\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_10\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_10\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_11\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_11\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_12\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_12\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_13\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_13\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_14\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_14\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_15\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_15\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_16\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_16\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_17\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_17\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_18\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_18\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_19\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_19\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_20\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_20\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_21\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_21\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_22\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_22\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_23\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_23\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_24\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_24\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_25\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_25\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_26\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_26\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_27\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_27\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_28\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_28\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_29\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate/model_29\\assets\n"
          ]
        }
      ],
      "source": [
        "# Save ensemble in case of future requirements\n",
        "for i, model in enumerate(ensemble):\n",
        "    model.save(f'models/ensemble_univariate/model_{i}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "09a7d74c",
      "metadata": {
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.99826974>"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.reduce_mean(tf.abs(y_test - median_preds)) / tf.reduce_mean(tf.abs(tf.subtract(y_test[1:], y_test[:-1])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "id": "610fb00f",
      "metadata": {
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mae</th>\n",
              "      <th>mse</th>\n",
              "      <th>rmse</th>\n",
              "      <th>mape</th>\n",
              "      <th>mase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>naive_forecast_results</th>\n",
              "      <td>951.947937</td>\n",
              "      <td>2021966.0</td>\n",
              "      <td>1421.958496</td>\n",
              "      <td>2.5654945373535156%</td>\n",
              "      <td>0.999748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ensemble_results</th>\n",
              "      <td>950.300842</td>\n",
              "      <td>2013928.375</td>\n",
              "      <td>1419.129395</td>\n",
              "      <td>2.557239532470703%</td>\n",
              "      <td>0.99827</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               mae          mse         rmse  \\\n",
              "naive_forecast_results  951.947937    2021966.0  1421.958496   \n",
              "ensemble_results        950.300842  2013928.375  1419.129395   \n",
              "\n",
              "                                       mape      mase  \n",
              "naive_forecast_results  2.5654945373535156%  0.999748  \n",
              "ensemble_results         2.557239532470703%   0.99827  "
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eval_frame = pd.DataFrame({\n",
        "    'naive_forecast_results': naive_forecast_results,\n",
        "    'ensemble_results': ensemble_results\n",
        "}).transpose()\n",
        "\n",
        "eval_frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "id": "8cda2e52",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save metric values in case of ui requirements\n",
        "eval_frame.to_csv('data/univariate_evaluation.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2db34c9",
      "metadata": {},
      "source": [
        "#### Uncertainty estimates for price ranges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "id": "9e902257",
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "Create function to find upper and lower bounds of the ensemble predictions\n",
        "(Uncertainty estimates) - the range of values that we need\n",
        "'''\n",
        "def get_upper_lower(preds):\n",
        "    std = tf.math.reduce_std(preds, axis=0)\n",
        "    # 1.96 is the 97.5th percentile point\n",
        "    interval = 1.96 * std\n",
        "    preds_mean = tf.reduce_mean(preds, axis=0)\n",
        "    lower, upper = preds_mean - interval, preds_mean + interval\n",
        "    return lower, upper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "id": "7ddd7831",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lower bound: [56670.36  57706.504 58494.64  57546.48  55487.06  57258.01  57626.48\n",
            " 59305.53  59591.562 59390.832]\n",
            "upper bound: [57430.508 58297.74  59167.71  58417.074 56336.535 58243.41  58520.387\n",
            " 60126.68  60341.08  60336.715]\n",
            "point forecast: [57069.715 58022.48  58855.242 58060.652 55983.375 57765.03  58101.39\n",
            " 59754.227 59949.395 59875.484]\n"
          ]
        }
      ],
      "source": [
        "lower, upper = get_upper_lower(ensemble_preds)\n",
        "med_ensemble_preds = np.median(ensemble_preds, axis=0)\n",
        "print(f'lower bound: {lower[:10]}')\n",
        "print(f'upper bound: {upper[:10]}')\n",
        "print(f'point forecast: {med_ensemble_preds[:10]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aae9b56e",
      "metadata": {},
      "source": [
        "### Demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4da90fb",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import datetime\n",
        "import os\n",
        "\n",
        "from lts import LTSCell"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86548d78",
      "metadata": {},
      "source": [
        "### Import and format data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "64139e35",
      "metadata": {},
      "outputs": [],
      "source": [
        "BTC_PRICES_DATA = 'D:/Uni/FYP/GitHub/BitForecast/ml/data/BTC_Prices_2.csv'\n",
        "data = pd.read_csv(BTC_PRICES_DATA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e3d3b902",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>volume</th>\n",
              "      <th>close</th>\n",
              "      <th>open</th>\n",
              "      <th>max</th>\n",
              "      <th>min</th>\n",
              "      <th>change_percent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1/1/2014</td>\n",
              "      <td>10757</td>\n",
              "      <td>815.940002</td>\n",
              "      <td>805.940002</td>\n",
              "      <td>829.929993</td>\n",
              "      <td>770.969971</td>\n",
              "      <td>1.240787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1/2/2014</td>\n",
              "      <td>12812</td>\n",
              "      <td>856.909973</td>\n",
              "      <td>815.940002</td>\n",
              "      <td>886.210022</td>\n",
              "      <td>810.469971</td>\n",
              "      <td>5.021199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1/3/2014</td>\n",
              "      <td>9709</td>\n",
              "      <td>884.260010</td>\n",
              "      <td>856.909973</td>\n",
              "      <td>888.229981</td>\n",
              "      <td>839.440002</td>\n",
              "      <td>3.191705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1/4/2014</td>\n",
              "      <td>14239</td>\n",
              "      <td>924.690002</td>\n",
              "      <td>884.260010</td>\n",
              "      <td>932.159973</td>\n",
              "      <td>848.320007</td>\n",
              "      <td>4.572184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1/5/2014</td>\n",
              "      <td>21374</td>\n",
              "      <td>1014.739990</td>\n",
              "      <td>924.690002</td>\n",
              "      <td>1029.859985</td>\n",
              "      <td>911.359985</td>\n",
              "      <td>9.738397</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       date  volume        close        open          max         min  \\\n",
              "0  1/1/2014   10757   815.940002  805.940002   829.929993  770.969971   \n",
              "1  1/2/2014   12812   856.909973  815.940002   886.210022  810.469971   \n",
              "2  1/3/2014    9709   884.260010  856.909973   888.229981  839.440002   \n",
              "3  1/4/2014   14239   924.690002  884.260010   932.159973  848.320007   \n",
              "4  1/5/2014   21374  1014.739990  924.690002  1029.859985  911.359985   \n",
              "\n",
              "   change_percent  \n",
              "0        1.240787  \n",
              "1        5.021199  \n",
              "2        3.191705  \n",
              "3        4.572184  \n",
              "4        9.738397  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b57c49d9",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>close</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1/1/2014</td>\n",
              "      <td>815.940002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1/2/2014</td>\n",
              "      <td>856.909973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1/3/2014</td>\n",
              "      <td>884.260010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1/4/2014</td>\n",
              "      <td>924.690002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1/5/2014</td>\n",
              "      <td>1014.739990</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       date        close\n",
              "0  1/1/2014   815.940002\n",
              "1  1/2/2014   856.909973\n",
              "2  1/3/2014   884.260010\n",
              "3  1/4/2014   924.690002\n",
              "4  1/5/2014  1014.739990"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.drop(['volume', 'open', 'max', 'min', 'change_percent'], axis=1, inplace=True)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "477efdf5",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Price</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2014-01-01</th>\n",
              "      <td>815.940002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-01-02</th>\n",
              "      <td>856.909973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-01-03</th>\n",
              "      <td>884.260010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-01-04</th>\n",
              "      <td>924.690002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-01-05</th>\n",
              "      <td>1014.739990</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Price\n",
              "date                   \n",
              "2014-01-01   815.940002\n",
              "2014-01-02   856.909973\n",
              "2014-01-03   884.260010\n",
              "2014-01-04   924.690002\n",
              "2014-01-05  1014.739990"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data['date'] = pd.to_datetime(data['date'])\n",
        "data.set_index('date', inplace=True)\n",
        "data.rename(columns={ 'close': 'Price' }, inplace=True)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e80d4092",
      "metadata": {},
      "source": [
        "### Create windowed datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a7034713",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Price</th>\n",
              "      <th>Price+1</th>\n",
              "      <th>Price+2</th>\n",
              "      <th>Price+3</th>\n",
              "      <th>Price+4</th>\n",
              "      <th>Price+5</th>\n",
              "      <th>Price+6</th>\n",
              "      <th>Price+7</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2014-01-01</th>\n",
              "      <td>815.940002</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-01-02</th>\n",
              "      <td>856.909973</td>\n",
              "      <td>815.940002</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-01-03</th>\n",
              "      <td>884.260010</td>\n",
              "      <td>856.909973</td>\n",
              "      <td>815.940002</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-01-04</th>\n",
              "      <td>924.690002</td>\n",
              "      <td>884.260010</td>\n",
              "      <td>856.909973</td>\n",
              "      <td>815.940002</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-01-05</th>\n",
              "      <td>1014.739990</td>\n",
              "      <td>924.690002</td>\n",
              "      <td>884.260010</td>\n",
              "      <td>856.909973</td>\n",
              "      <td>815.940002</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-01-06</th>\n",
              "      <td>1012.650024</td>\n",
              "      <td>1014.739990</td>\n",
              "      <td>924.690002</td>\n",
              "      <td>884.260010</td>\n",
              "      <td>856.909973</td>\n",
              "      <td>815.940002</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-01-07</th>\n",
              "      <td>879.900024</td>\n",
              "      <td>1012.650024</td>\n",
              "      <td>1014.739990</td>\n",
              "      <td>924.690002</td>\n",
              "      <td>884.260010</td>\n",
              "      <td>856.909973</td>\n",
              "      <td>815.940002</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-01-08</th>\n",
              "      <td>938.840027</td>\n",
              "      <td>879.900024</td>\n",
              "      <td>1012.650024</td>\n",
              "      <td>1014.739990</td>\n",
              "      <td>924.690002</td>\n",
              "      <td>884.260010</td>\n",
              "      <td>856.909973</td>\n",
              "      <td>815.940002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-01-09</th>\n",
              "      <td>936.950012</td>\n",
              "      <td>938.840027</td>\n",
              "      <td>879.900024</td>\n",
              "      <td>1012.650024</td>\n",
              "      <td>1014.739990</td>\n",
              "      <td>924.690002</td>\n",
              "      <td>884.260010</td>\n",
              "      <td>856.909973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-01-10</th>\n",
              "      <td>957.760010</td>\n",
              "      <td>936.950012</td>\n",
              "      <td>938.840027</td>\n",
              "      <td>879.900024</td>\n",
              "      <td>1012.650024</td>\n",
              "      <td>1014.739990</td>\n",
              "      <td>924.690002</td>\n",
              "      <td>884.260010</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Price      Price+1      Price+2      Price+3      Price+4  \\\n",
              "date                                                                          \n",
              "2014-01-01   815.940002          NaN          NaN          NaN          NaN   \n",
              "2014-01-02   856.909973   815.940002          NaN          NaN          NaN   \n",
              "2014-01-03   884.260010   856.909973   815.940002          NaN          NaN   \n",
              "2014-01-04   924.690002   884.260010   856.909973   815.940002          NaN   \n",
              "2014-01-05  1014.739990   924.690002   884.260010   856.909973   815.940002   \n",
              "2014-01-06  1012.650024  1014.739990   924.690002   884.260010   856.909973   \n",
              "2014-01-07   879.900024  1012.650024  1014.739990   924.690002   884.260010   \n",
              "2014-01-08   938.840027   879.900024  1012.650024  1014.739990   924.690002   \n",
              "2014-01-09   936.950012   938.840027   879.900024  1012.650024  1014.739990   \n",
              "2014-01-10   957.760010   936.950012   938.840027   879.900024  1012.650024   \n",
              "\n",
              "                Price+5     Price+6     Price+7  \n",
              "date                                             \n",
              "2014-01-01          NaN         NaN         NaN  \n",
              "2014-01-02          NaN         NaN         NaN  \n",
              "2014-01-03          NaN         NaN         NaN  \n",
              "2014-01-04          NaN         NaN         NaN  \n",
              "2014-01-05          NaN         NaN         NaN  \n",
              "2014-01-06   815.940002         NaN         NaN  \n",
              "2014-01-07   856.909973  815.940002         NaN  \n",
              "2014-01-08   884.260010  856.909973  815.940002  \n",
              "2014-01-09   924.690002  884.260010  856.909973  \n",
              "2014-01-10  1014.739990  924.690002  884.260010  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "HORIZON = 1\n",
        "WINDOW_SIZE = 7\n",
        "\n",
        "data_windowed = data.copy()\n",
        "for i in range(WINDOW_SIZE):\n",
        "    data_windowed[f'Price+{i+1}'] = data_windowed['Price'].shift(periods=i+1)\n",
        "\n",
        "data_windowed.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "94e590b4",
      "metadata": {},
      "outputs": [],
      "source": [
        "X = data_windowed.dropna().drop('Price', axis=1).astype(np.float32)\n",
        "y = data_windowed.dropna()['Price'].astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "a96b7d97",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2643, 2643, 661, 661)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "split_size = int(len(X) * .8)\n",
        "\n",
        "X_train, y_train = X[:split_size], y[:split_size]\n",
        "X_test, y_test = X[split_size:], y[split_size:]\n",
        "len(X_train), len(y_train), len(X_test), len(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d858c658",
      "metadata": {},
      "source": [
        "### Create performant tensorflow datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "eccbf82f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<PrefetchDataset element_spec=(TensorSpec(shape=(None, 7), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.float32, name=None))>,\n",
              " <PrefetchDataset element_spec=(TensorSpec(shape=(None, 7), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.float32, name=None))>)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# create tensorflow Datasets\n",
        "train_features_dataset = tf.data.Dataset.from_tensor_slices(X_train)\n",
        "train_labels_dataset = tf.data.Dataset.from_tensor_slices(y_train)\n",
        "\n",
        "test_features_dataset = tf.data.Dataset.from_tensor_slices(X_test)\n",
        "test_labels_dataset = tf.data.Dataset.from_tensor_slices(y_test)\n",
        "\n",
        "# Combine features and labels\n",
        "train_dataset = tf.data.Dataset.zip((train_features_dataset, train_labels_dataset))\n",
        "test_dataset = tf.data.Dataset.zip((test_features_dataset, test_labels_dataset))\n",
        "\n",
        "# batch and prefetch for optimal performance\n",
        "BATCH_SIZE = 1024\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_dataset, test_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "af49f481",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Predictions\n",
        "def make_ensemble_preds(ensemble, data):\n",
        "    preds = []\n",
        "    for model in ensemble:\n",
        "        preds.append(model.predict(data))\n",
        "        \n",
        "    return tf.constant(tf.squeeze(preds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "258cef91",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncertainty estimates\n",
        "def get_upper_lower(preds):\n",
        "    std = tf.math.reduce_std(preds, axis=0)\n",
        "    # 1.96 is the 97.5th percentile point\n",
        "    interval = 1.96 * std\n",
        "    preds_mean = tf.reduce_mean(preds, axis=0)\n",
        "    lower, upper = preds_mean - interval, preds_mean + interval\n",
        "    return lower, upper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "b9729fc7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import models\n",
        "MODELS_PATH = './models/ensemble_univariate'\n",
        "ensemble = [tf.keras.models.load_model(f'{MODELS_PATH}/{model}') for model in os.listdir(MODELS_PATH)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "79f787f2",
      "metadata": {
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 778ms/step\n",
            "1/1 [==============================] - 0s 122ms/step\n",
            "1/1 [==============================] - 0s 108ms/step\n",
            "1/1 [==============================] - 0s 138ms/step\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000017BB2F51E58> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 425ms/step\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000017BB2F68DC8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 105ms/step\n",
            "1/1 [==============================] - 0s 92ms/step\n",
            "1/1 [==============================] - 0s 104ms/step\n",
            "1/1 [==============================] - 0s 121ms/step\n",
            "1/1 [==============================] - 0s 254ms/step\n",
            "1/1 [==============================] - 0s 132ms/step\n",
            "1/1 [==============================] - 0s 90ms/step\n",
            "1/1 [==============================] - 0s 83ms/step\n",
            "1/1 [==============================] - 0s 392ms/step\n",
            "1/1 [==============================] - 0s 216ms/step\n",
            "1/1 [==============================] - 0s 94ms/step\n",
            "1/1 [==============================] - 0s 108ms/step\n",
            "1/1 [==============================] - 0s 100ms/step\n",
            "1/1 [==============================] - 0s 108ms/step\n",
            "1/1 [==============================] - 0s 138ms/step\n",
            "1/1 [==============================] - 0s 189ms/step\n",
            "1/1 [==============================] - 0s 94ms/step\n",
            "1/1 [==============================] - 0s 100ms/step\n",
            "1/1 [==============================] - 0s 193ms/step\n",
            "1/1 [==============================] - 0s 291ms/step\n",
            "1/1 [==============================] - 0s 130ms/step\n",
            "1/1 [==============================] - 0s 100ms/step\n",
            "1/1 [==============================] - 0s 96ms/step\n",
            "1/1 [==============================] - 0s 179ms/step\n",
            "1/1 [==============================] - 0s 117ms/step\n"
          ]
        }
      ],
      "source": [
        "ensemble_preds = make_ensemble_preds(\n",
        "    ensemble,\n",
        "    test_dataset\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "93b69072",
      "metadata": {
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lower bound: [56670.36  57706.516 58494.637 57546.48  55487.06  57258.016 57626.477\n",
            " 59305.523 59591.566 59390.844]\n",
            "upper bound: [57430.508 58297.75  59167.707 58417.074 56336.535 58243.414 58520.383\n",
            " 60126.67  60341.082 60336.727]\n",
            "point forecast: [57069.715 58022.48  58855.242 58060.652 55983.375 57765.03  58101.39\n",
            " 59754.227 59949.395 59875.484]\n"
          ]
        }
      ],
      "source": [
        "lower, upper = get_upper_lower(ensemble_preds)\n",
        "med_ensemble_preds = np.median(ensemble_preds, axis=0)\n",
        "print(f'lower bound: {lower[:10]}')\n",
        "print(f'upper bound: {upper[:10]}')\n",
        "print(f'point forecast: {med_ensemble_preds[:10]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "276f72ca",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatetimeIndex(['2021-04-04', '2021-04-05', '2021-04-06', '2021-04-07',\n",
              "               '2021-04-08', '2021-04-09', '2021-04-10', '2021-04-11',\n",
              "               '2021-04-12', '2021-04-13'],\n",
              "              dtype='datetime64[ns]', name='date', freq=None)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test.index[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20e6c0cc",
      "metadata": {},
      "source": [
        "### Make predictions in future\n",
        "\n",
        "In order to actually predict into the future, the model must now be trained on the complete dataset. As the same architecture has already been evaluated and fine tuned, the best performing architecture can be used, but this time, having trained on the entire dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6dc2f3ec",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import datetime\n",
        "import os\n",
        "\n",
        "from lts import LTSCell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "fb6f88bc",
      "metadata": {},
      "outputs": [],
      "source": [
        "HORIZON = 1\n",
        "WINDOW_SIZE = 7\n",
        "BATCH_SIZE = 1024\n",
        "BTC_PRICES_DATA = 'D:/Uni/FYP/GitHub/BitForecast/ml/data/BTC_Prices.csv'\n",
        "\n",
        "# Create the required dataset format\n",
        "def create_dataset():\n",
        "    # Import data\n",
        "    data = pd.read_csv(BTC_PRICES_DATA)\n",
        "\n",
        "    # Clean up data\n",
        "    data.drop(['volume', 'open', 'max', 'min', 'change_percent'], axis=1, inplace=True)\n",
        "    data['date'] = pd.to_datetime(data['date'])\n",
        "    data.set_index('date', inplace=True)\n",
        "    data.rename(columns={ 'close': 'Price' }, inplace=True)\n",
        "\n",
        "    # Create window datasets\n",
        "    data_windowed = data.copy()\n",
        "    for i in range(WINDOW_SIZE):\n",
        "        data_windowed[f'Price+{i+1}'] = data_windowed['Price'].shift(periods=i+1)\n",
        "\n",
        "    # Create X and y\n",
        "    X_all = data_windowed.dropna().drop('Price', axis=1).astype(np.float32)\n",
        "    y_all = data_windowed.dropna()['Price'].astype(np.float32)\n",
        "\n",
        "    # Convert tensorflow datasets\n",
        "    features_dataset_all = tf.data.Dataset.from_tensor_slices(X_all)\n",
        "    labels_dataset_all = tf.data.Dataset.from_tensor_slices(y_all)\n",
        "    dataset_all = tf.data.Dataset.zip((features_dataset_all, labels_dataset_all))\n",
        "    dataset_all = dataset_all.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "    return data, y_all, dataset_all\n",
        "\n",
        "# Create an ensemble of models\n",
        "def create_ensemble(\n",
        "    num_models=10,\n",
        "    num_epochs=5000,\n",
        "    horizon=HORIZON,\n",
        "    loss_fns=['mae', 'mse', 'mape']\n",
        "):\n",
        "    _, _, dataset_all = create_dataset()\n",
        "    ensemble = []\n",
        "\n",
        "    for i in range(num_models):\n",
        "        for loss_fn in loss_fns:\n",
        "            print(f'Model loss: {loss_fn} | model number: {i}')\n",
        "            model = tf.keras.Sequential([\n",
        "                tf.keras.layers.Input(\n",
        "                    shape=(WINDOW_SIZE)\n",
        "                ),\n",
        "                tf.keras.layers.Lambda(\n",
        "                    lambda x: tf.expand_dims(x, axis=1)\n",
        "                ),\n",
        "                tf.keras.layers.RNN(\n",
        "                    LTSCell(16),\n",
        "                    time_major=True,\n",
        "                    return_sequences=True\n",
        "                ),\n",
        "                tf.keras.layers.LSTM(\n",
        "                    16,\n",
        "                    activation='relu'\n",
        "                ),\n",
        "                tf.keras.layers.Dense(\n",
        "                    128,\n",
        "                    \n",
        "                    # This is required for the prediction intervals\n",
        "                    kernel_initializer='he_normal',\n",
        "                    activation='relu'\n",
        "                ),\n",
        "                tf.keras.layers.Dense(\n",
        "                    128,\n",
        "                    kernel_initializer='he_normal',\n",
        "                    activation='relu'\n",
        "                ),\n",
        "                tf.keras.layers.Dense(HORIZON)\n",
        "            ])\n",
        "\n",
        "            model.compile(\n",
        "                loss=loss_fn,\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['mae', 'mse']\n",
        "            )\n",
        "\n",
        "            model.fit(\n",
        "                dataset_all,\n",
        "                epochs=num_epochs,\n",
        "                verbose=0,\n",
        "            )\n",
        "\n",
        "            ensemble.append(model)\n",
        "\n",
        "    return ensemble\n",
        "\n",
        "# Create prediction uncertainty estimates\n",
        "def get_upper_lower(preds):\n",
        "    std = tf.math.reduce_std(preds, axis=0)\n",
        "    # 1.96 is the 97.5th percentile point\n",
        "    interval = 1.96 * std\n",
        "    preds_mean = tf.reduce_mean(preds, axis=0)\n",
        "    lower, upper = preds_mean - interval, preds_mean + interval\n",
        "    return lower, upper\n",
        "\n",
        "# Make predictions into the future\n",
        "def make_future_forecasts(\n",
        "    values,\n",
        "    ensemble,\n",
        "    into_future,\n",
        "    window_size=WINDOW_SIZE\n",
        "):\n",
        "    future_forecast = []\n",
        "   \n",
        "    # Predict {into_future} times with all models in the ensemble\n",
        "    for i, model in enumerate(ensemble):\n",
        "        model_forecast = []\n",
        "        last_window = values[-window_size:] # last {WINDOW_SIZE} prices\n",
        "        for _ in range(into_future):\n",
        "            future_pred = tf.squeeze(\n",
        "                model.predict(tf.expand_dims(last_window, axis=0))\n",
        "            ).numpy()\n",
        "\n",
        "            print(f'Model {i} Predicting on:\\n{last_window} -> Prediction: {future_pred}')\n",
        "\n",
        "            # Update future forecast list\n",
        "            model_forecast.append(future_pred)\n",
        "\n",
        "            # Update last window: append latest and take last {WINDOW_SIZE} values\n",
        "            last_window = np.append(last_window, future_pred)[-window_size:]\n",
        "        \n",
        "        future_forecast.append(model_forecast)\n",
        "        \n",
        "    return future_forecast\n",
        "\n",
        "# Return dates from start_date to start_date+into_future\n",
        "def get_future_dates(start_date, into_future, offset=1):\n",
        "    start_date = start_date + np.timedelta64(offset, 'D')\n",
        "    end_date = start_date + np.timedelta64(into_future, 'D')\n",
        "    return np.arange(start_date, end_date, dtype='datetime64[D]')\n",
        "\n",
        "# Create a helper plotting function\n",
        "def plot_time_series(\n",
        "    timesteps,\n",
        "    prices,\n",
        "    format='.',\n",
        "    start=0,\n",
        "    end=None,\n",
        "    label=None\n",
        "):\n",
        "    plt.plot(timesteps[start:end], prices[start:end], format, label=label)\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Price')\n",
        "    if label:\n",
        "        plt.legend(fontsize=14)\n",
        "\n",
        "    # Display a grid for easier measurement readings\n",
        "    plt.grid(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "c1b90723",
      "metadata": {
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loss: mae | model number: 0\n",
            "Model loss: mse | model number: 0\n",
            "Model loss: mape | model number: 0\n",
            "Model loss: mae | model number: 1\n",
            "Model loss: mse | model number: 1\n",
            "Model loss: mape | model number: 1\n",
            "Model loss: mae | model number: 2\n",
            "Model loss: mse | model number: 2\n",
            "Model loss: mape | model number: 2\n",
            "Model loss: mae | model number: 3\n",
            "Model loss: mse | model number: 3\n",
            "Model loss: mape | model number: 3\n",
            "Model loss: mae | model number: 4\n",
            "Model loss: mse | model number: 4\n",
            "Model loss: mape | model number: 4\n",
            "Model loss: mae | model number: 5\n",
            "Model loss: mse | model number: 5\n",
            "Model loss: mape | model number: 5\n",
            "Model loss: mae | model number: 6\n",
            "Model loss: mse | model number: 6\n",
            "Model loss: mape | model number: 6\n",
            "Model loss: mae | model number: 7\n",
            "Model loss: mse | model number: 7\n",
            "Model loss: mape | model number: 7\n",
            "Model loss: mae | model number: 8\n",
            "Model loss: mse | model number: 8\n",
            "Model loss: mape | model number: 8\n",
            "Model loss: mae | model number: 9\n",
            "Model loss: mse | model number: 9\n",
            "Model loss: mape | model number: 9\n"
          ]
        }
      ],
      "source": [
        "ensemble = create_ensemble()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "487e51bf",
      "metadata": {
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: models/ensemble_univariate_complete/model_0\\assets\n",
            "INFO:tensorflow:Assets written to: models/ensemble_univariate_complete/model_1\\assets\n",
            "INFO:tensorflow:Assets written to: models/ensemble_univariate_complete/model_2\\assets\n",
            "INFO:tensorflow:Assets written to: models/ensemble_univariate_complete/model_3\\assets\n",
            "INFO:tensorflow:Assets written to: models/ensemble_univariate_complete/model_4\\assets\n",
            "INFO:tensorflow:Assets written to: models/ensemble_univariate_complete/model_5\\assets\n",
            "INFO:tensorflow:Assets written to: models/ensemble_univariate_complete/model_6\\assets\n",
            "INFO:tensorflow:Assets written to: models/ensemble_univariate_complete/model_7\\assets\n",
            "INFO:tensorflow:Assets written to: models/ensemble_univariate_complete/model_8\\assets\n",
            "INFO:tensorflow:Assets written to: models/ensemble_univariate_complete/model_9\\assets\n",
            "INFO:tensorflow:Assets written to: models/ensemble_univariate_complete/model_10\\assets\n",
            "INFO:tensorflow:Assets written to: models/ensemble_univariate_complete/model_11\\assets\n",
            "INFO:tensorflow:Assets written to: models/ensemble_univariate_complete/model_12\\assets\n",
            "INFO:tensorflow:Assets written to: models/ensemble_univariate_complete/model_13\\assets\n",
            "INFO:tensorflow:Assets written to: models/ensemble_univariate_complete/model_14\\assets\n",
            "INFO:tensorflow:Assets written to: models/ensemble_univariate_complete/model_15\\assets\n",
            "INFO:tensorflow:Assets written to: models/ensemble_univariate_complete/model_16\\assets\n",
            "INFO:tensorflow:Assets written to: models/ensemble_univariate_complete/model_17\\assets\n",
            "INFO:tensorflow:Assets written to: models/ensemble_univariate_complete/model_18\\assets\n",
            "INFO:tensorflow:Assets written to: models/ensemble_univariate_complete/model_19\\assets\n",
            "INFO:tensorflow:Assets written to: models/ensemble_univariate_complete/model_20\\assets\n",
            "INFO:tensorflow:Assets written to: models/ensemble_univariate_complete/model_21\\assets\n",
            "INFO:tensorflow:Assets written to: models/ensemble_univariate_complete/model_22\\assets\n",
            "INFO:tensorflow:Assets written to: models/ensemble_univariate_complete/model_23\\assets\n",
            "INFO:tensorflow:Assets written to: models/ensemble_univariate_complete/model_24\\assets\n",
            "INFO:tensorflow:Assets written to: models/ensemble_univariate_complete/model_25\\assets\n",
            "INFO:tensorflow:Assets written to: models/ensemble_univariate_complete/model_26\\assets\n",
            "INFO:tensorflow:Assets written to: models/ensemble_univariate_complete/model_27\\assets\n",
            "INFO:tensorflow:Assets written to: models/ensemble_univariate_complete/model_28\\assets\n",
            "INFO:tensorflow:Assets written to: models/ensemble_univariate_complete/model_29\\assets\n"
          ]
        }
      ],
      "source": [
        "# Save ensemble in case of future requirements\n",
        "for i, model in enumerate(ensemble):\n",
        "    model.save(f'models/ensemble_univariate_complete/model_{i}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "d7390ca0",
      "metadata": {
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 27ms/step\n",
            "Model 0 Predicting on:\n",
            "date\n",
            "2023-02-17    24573.505859\n",
            "2023-02-18    24631.441406\n",
            "2023-02-19    24302.927734\n",
            "2023-02-20    24839.453125\n",
            "2023-02-21    24450.666016\n",
            "2023-02-22    24186.593750\n",
            "2023-02-23    24141.316406\n",
            "Name: Price, dtype: float32 -> Prediction: 24577.9296875\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Model 0 Predicting on:\n",
            "[24631.441 24302.928 24839.453 24450.666 24186.594 24141.316 24577.93 ] -> Prediction: 24508.720703125\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Model 0 Predicting on:\n",
            "[24302.928 24839.453 24450.666 24186.594 24141.316 24577.93  24508.72 ] -> Prediction: 24282.880859375\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "Model 0 Predicting on:\n",
            "[24839.453 24450.666 24186.594 24141.316 24577.93  24508.72  24282.88 ] -> Prediction: 24763.787109375\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "Model 0 Predicting on:\n",
            "[24450.666 24186.594 24141.316 24577.93  24508.72  24282.88  24763.787] -> Prediction: 24377.095703125\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "Model 1 Predicting on:\n",
            "date\n",
            "2023-02-17    24573.505859\n",
            "2023-02-18    24631.441406\n",
            "2023-02-19    24302.927734\n",
            "2023-02-20    24839.453125\n",
            "2023-02-21    24450.666016\n",
            "2023-02-22    24186.593750\n",
            "2023-02-23    24141.316406\n",
            "Name: Price, dtype: float32 -> Prediction: 24456.560546875\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Model 1 Predicting on:\n",
            "[24631.441 24302.928 24839.453 24450.666 24186.594 24141.316 24456.56 ] -> Prediction: 24546.099609375\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Model 1 Predicting on:\n",
            "[24302.928 24839.453 24450.666 24186.594 24141.316 24456.56  24546.1  ] -> Prediction: 24192.939453125\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Model 1 Predicting on:\n",
            "[24839.453 24450.666 24186.594 24141.316 24456.56  24546.1   24192.94 ] -> Prediction: 24913.427734375\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "Model 1 Predicting on:\n",
            "[24450.666 24186.594 24141.316 24456.56  24546.1   24192.94  24913.428] -> Prediction: 24440.212890625\n",
            "1/1 [==============================] - 0s 164ms/step\n",
            "Model 2 Predicting on:\n",
            "date\n",
            "2023-02-17    24573.505859\n",
            "2023-02-18    24631.441406\n",
            "2023-02-19    24302.927734\n",
            "2023-02-20    24839.453125\n",
            "2023-02-21    24450.666016\n",
            "2023-02-22    24186.593750\n",
            "2023-02-23    24141.316406\n",
            "Name: Price, dtype: float32 -> Prediction: 24525.119140625\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "Model 2 Predicting on:\n",
            "[24631.441 24302.928 24839.453 24450.666 24186.594 24141.316 24525.12 ] -> Prediction: 24457.162109375\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Model 2 Predicting on:\n",
            "[24302.928 24839.453 24450.666 24186.594 24141.316 24525.12  24457.162] -> Prediction: 24189.408203125\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "Model 2 Predicting on:\n",
            "[24839.453 24450.666 24186.594 24141.316 24525.12  24457.162 24189.408] -> Prediction: 24654.6796875\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Model 2 Predicting on:\n",
            "[24450.666 24186.594 24141.316 24525.12  24457.162 24189.408 24654.68 ] -> Prediction: 24298.390625\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Model 3 Predicting on:\n",
            "date\n",
            "2023-02-17    24573.505859\n",
            "2023-02-18    24631.441406\n",
            "2023-02-19    24302.927734\n",
            "2023-02-20    24839.453125\n",
            "2023-02-21    24450.666016\n",
            "2023-02-22    24186.593750\n",
            "2023-02-23    24141.316406\n",
            "Name: Price, dtype: float32 -> Prediction: 24593.35546875\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Model 3 Predicting on:\n",
            "[24631.441 24302.928 24839.453 24450.666 24186.594 24141.316 24593.355] -> Prediction: 24654.138671875\n",
            "1/1 [==============================] - 0s 135ms/step\n",
            "Model 3 Predicting on:\n",
            "[24302.928 24839.453 24450.666 24186.594 24141.316 24593.355 24654.139] -> Prediction: 24389.26953125\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "Model 3 Predicting on:\n",
            "[24839.453 24450.666 24186.594 24141.316 24593.355 24654.139 24389.27 ] -> Prediction: 24798.900390625\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Model 3 Predicting on:\n",
            "[24450.666 24186.594 24141.316 24593.355 24654.139 24389.27  24798.9  ] -> Prediction: 24488.12890625\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Model 4 Predicting on:\n",
            "date\n",
            "2023-02-17    24573.505859\n",
            "2023-02-18    24631.441406\n",
            "2023-02-19    24302.927734\n",
            "2023-02-20    24839.453125\n",
            "2023-02-21    24450.666016\n",
            "2023-02-22    24186.593750\n",
            "2023-02-23    24141.316406\n",
            "Name: Price, dtype: float32 -> Prediction: 24488.830078125\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Model 4 Predicting on:\n",
            "[24631.441 24302.928 24839.453 24450.666 24186.594 24141.316 24488.83 ] -> Prediction: 24610.640625\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "Model 4 Predicting on:\n",
            "[24302.928 24839.453 24450.666 24186.594 24141.316 24488.83  24610.64 ] -> Prediction: 24297.001953125\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "Model 4 Predicting on:\n",
            "[24839.453 24450.666 24186.594 24141.316 24488.83  24610.64  24297.002] -> Prediction: 24806.052734375\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "Model 4 Predicting on:\n",
            "[24450.666 24186.594 24141.316 24488.83  24610.64  24297.002 24806.053] -> Prediction: 24407.896484375\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "Model 5 Predicting on:\n",
            "date\n",
            "2023-02-17    24573.505859\n",
            "2023-02-18    24631.441406\n",
            "2023-02-19    24302.927734\n",
            "2023-02-20    24839.453125\n",
            "2023-02-21    24450.666016\n",
            "2023-02-22    24186.593750\n",
            "2023-02-23    24141.316406\n",
            "Name: Price, dtype: float32 -> Prediction: 24602.9609375\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "Model 5 Predicting on:\n",
            "[24631.441 24302.928 24839.453 24450.666 24186.594 24141.316 24602.96 ] -> Prediction: 24641.3203125\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Model 5 Predicting on:\n",
            "[24302.928 24839.453 24450.666 24186.594 24141.316 24602.96  24641.32 ] -> Prediction: 24343.3984375\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Model 5 Predicting on:\n",
            "[24839.453 24450.666 24186.594 24141.316 24602.96  24641.32  24343.398] -> Prediction: 24876.716796875\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Model 5 Predicting on:\n",
            "[24450.666 24186.594 24141.316 24602.96  24641.32  24343.398 24876.717] -> Prediction: 24448.91015625\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "Model 6 Predicting on:\n",
            "date\n",
            "2023-02-17    24573.505859\n",
            "2023-02-18    24631.441406\n",
            "2023-02-19    24302.927734\n",
            "2023-02-20    24839.453125\n",
            "2023-02-21    24450.666016\n",
            "2023-02-22    24186.593750\n",
            "2023-02-23    24141.316406\n",
            "Name: Price, dtype: float32 -> Prediction: 24525.068359375\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "Model 6 Predicting on:\n",
            "[24631.441 24302.928 24839.453 24450.666 24186.594 24141.316 24525.068] -> Prediction: 24561.390625\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "Model 6 Predicting on:\n",
            "[24302.928 24839.453 24450.666 24186.594 24141.316 24525.068 24561.39 ] -> Prediction: 24392.609375\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Model 6 Predicting on:\n",
            "[24839.453 24450.666 24186.594 24141.316 24525.068 24561.39  24392.61 ] -> Prediction: 24783.638671875\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Model 6 Predicting on:\n",
            "[24450.666 24186.594 24141.316 24525.068 24561.39  24392.61  24783.639] -> Prediction: 24405.94140625\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "Model 7 Predicting on:\n",
            "date\n",
            "2023-02-17    24573.505859\n",
            "2023-02-18    24631.441406\n",
            "2023-02-19    24302.927734\n",
            "2023-02-20    24839.453125\n",
            "2023-02-21    24450.666016\n",
            "2023-02-22    24186.593750\n",
            "2023-02-23    24141.316406\n",
            "Name: Price, dtype: float32 -> Prediction: 24631.748046875\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Model 7 Predicting on:\n",
            "[24631.441 24302.928 24839.453 24450.666 24186.594 24141.316 24631.748] -> Prediction: 24471.65625\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "Model 7 Predicting on:\n",
            "[24302.928 24839.453 24450.666 24186.594 24141.316 24631.748 24471.656] -> Prediction: 24323.73046875\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "Model 7 Predicting on:\n",
            "[24839.453 24450.666 24186.594 24141.316 24631.748 24471.656 24323.73 ] -> Prediction: 24760.02734375\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "Model 7 Predicting on:\n",
            "[24450.666 24186.594 24141.316 24631.748 24471.656 24323.73  24760.027] -> Prediction: 24379.400390625\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 32ms/step\n",
            "Model 8 Predicting on:\n",
            "date\n",
            "2023-02-17    24573.505859\n",
            "2023-02-18    24631.441406\n",
            "2023-02-19    24302.927734\n",
            "2023-02-20    24839.453125\n",
            "2023-02-21    24450.666016\n",
            "2023-02-22    24186.593750\n",
            "2023-02-23    24141.316406\n",
            "Name: Price, dtype: float32 -> Prediction: 24703.521484375\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Model 8 Predicting on:\n",
            "[24631.441 24302.928 24839.453 24450.666 24186.594 24141.316 24703.521] -> Prediction: 24717.681640625\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "Model 8 Predicting on:\n",
            "[24302.928 24839.453 24450.666 24186.594 24141.316 24703.521 24717.682] -> Prediction: 24504.015625\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "Model 8 Predicting on:\n",
            "[24839.453 24450.666 24186.594 24141.316 24703.521 24717.682 24504.016] -> Prediction: 24903.8125\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Model 8 Predicting on:\n",
            "[24450.666 24186.594 24141.316 24703.521 24717.682 24504.016 24903.812] -> Prediction: 24561.369140625\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "Model 9 Predicting on:\n",
            "date\n",
            "2023-02-17    24573.505859\n",
            "2023-02-18    24631.441406\n",
            "2023-02-19    24302.927734\n",
            "2023-02-20    24839.453125\n",
            "2023-02-21    24450.666016\n",
            "2023-02-22    24186.593750\n",
            "2023-02-23    24141.316406\n",
            "Name: Price, dtype: float32 -> Prediction: 24515.638671875\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "Model 9 Predicting on:\n",
            "[24631.441 24302.928 24839.453 24450.666 24186.594 24141.316 24515.639] -> Prediction: 24548.79296875\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Model 9 Predicting on:\n",
            "[24302.928 24839.453 24450.666 24186.594 24141.316 24515.639 24548.793] -> Prediction: 24317.234375\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Model 9 Predicting on:\n",
            "[24839.453 24450.666 24186.594 24141.316 24515.639 24548.793 24317.234] -> Prediction: 24778.25\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Model 9 Predicting on:\n",
            "[24450.666 24186.594 24141.316 24515.639 24548.793 24317.234 24778.25 ] -> Prediction: 24426.943359375\n",
            "1/1 [==============================] - 0s 110ms/step\n",
            "Model 10 Predicting on:\n",
            "date\n",
            "2023-02-17    24573.505859\n",
            "2023-02-18    24631.441406\n",
            "2023-02-19    24302.927734\n",
            "2023-02-20    24839.453125\n",
            "2023-02-21    24450.666016\n",
            "2023-02-22    24186.593750\n",
            "2023-02-23    24141.316406\n",
            "Name: Price, dtype: float32 -> Prediction: 24521.3828125\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "Model 10 Predicting on:\n",
            "[24631.441 24302.928 24839.453 24450.666 24186.594 24141.316 24521.383] -> Prediction: 24591.7890625\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "Model 10 Predicting on:\n",
            "[24302.928 24839.453 24450.666 24186.594 24141.316 24521.383 24591.79 ] -> Prediction: 24323.544921875\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Model 10 Predicting on:\n",
            "[24839.453 24450.666 24186.594 24141.316 24521.383 24591.79  24323.545] -> Prediction: 24817.1015625\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Model 10 Predicting on:\n",
            "[24450.666 24186.594 24141.316 24521.383 24591.79  24323.545 24817.102] -> Prediction: 24415.55859375\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Model 11 Predicting on:\n",
            "date\n",
            "2023-02-17    24573.505859\n",
            "2023-02-18    24631.441406\n",
            "2023-02-19    24302.927734\n",
            "2023-02-20    24839.453125\n",
            "2023-02-21    24450.666016\n",
            "2023-02-22    24186.593750\n",
            "2023-02-23    24141.316406\n",
            "Name: Price, dtype: float32 -> Prediction: 24662.2421875\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Model 11 Predicting on:\n",
            "[24631.441 24302.928 24839.453 24450.666 24186.594 24141.316 24662.242] -> Prediction: 24617.66015625\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "Model 11 Predicting on:\n",
            "[24302.928 24839.453 24450.666 24186.594 24141.316 24662.242 24617.66 ] -> Prediction: 24427.580078125\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "Model 11 Predicting on:\n",
            "[24839.453 24450.666 24186.594 24141.316 24662.242 24617.66  24427.58 ] -> Prediction: 24865.05859375\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "Model 11 Predicting on:\n",
            "[24450.666 24186.594 24141.316 24662.242 24617.66  24427.58  24865.059] -> Prediction: 24486.80078125\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Model 12 Predicting on:\n",
            "date\n",
            "2023-02-17    24573.505859\n",
            "2023-02-18    24631.441406\n",
            "2023-02-19    24302.927734\n",
            "2023-02-20    24839.453125\n",
            "2023-02-21    24450.666016\n",
            "2023-02-22    24186.593750\n",
            "2023-02-23    24141.316406\n",
            "Name: Price, dtype: float32 -> Prediction: 24598.373046875\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Model 12 Predicting on:\n",
            "[24631.441 24302.928 24839.453 24450.666 24186.594 24141.316 24598.373] -> Prediction: 24641.2734375\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Model 12 Predicting on:\n",
            "[24302.928 24839.453 24450.666 24186.594 24141.316 24598.373 24641.273] -> Prediction: 24401.6875\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Model 12 Predicting on:\n",
            "[24839.453 24450.666 24186.594 24141.316 24598.373 24641.273 24401.688] -> Prediction: 24821.740234375\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "Model 12 Predicting on:\n",
            "[24450.666 24186.594 24141.316 24598.373 24641.273 24401.688 24821.74 ] -> Prediction: 24471.123046875\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "Model 13 Predicting on:\n",
            "date\n",
            "2023-02-17    24573.505859\n",
            "2023-02-18    24631.441406\n",
            "2023-02-19    24302.927734\n",
            "2023-02-20    24839.453125\n",
            "2023-02-21    24450.666016\n",
            "2023-02-22    24186.593750\n",
            "2023-02-23    24141.316406\n",
            "Name: Price, dtype: float32 -> Prediction: 24503.4765625\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "Model 13 Predicting on:\n",
            "[24631.441 24302.928 24839.453 24450.666 24186.594 24141.316 24503.477] -> Prediction: 24558.275390625\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Model 13 Predicting on:\n",
            "[24302.928 24839.453 24450.666 24186.594 24141.316 24503.477 24558.275] -> Prediction: 24267.794921875\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Model 13 Predicting on:\n",
            "[24839.453 24450.666 24186.594 24141.316 24503.477 24558.275 24267.795] -> Prediction: 24763.927734375\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Model 13 Predicting on:\n",
            "[24450.666 24186.594 24141.316 24503.477 24558.275 24267.795 24763.928] -> Prediction: 24426.748046875\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Model 14 Predicting on:\n",
            "date\n",
            "2023-02-17    24573.505859\n",
            "2023-02-18    24631.441406\n",
            "2023-02-19    24302.927734\n",
            "2023-02-20    24839.453125\n",
            "2023-02-21    24450.666016\n",
            "2023-02-22    24186.593750\n",
            "2023-02-23    24141.316406\n",
            "Name: Price, dtype: float32 -> Prediction: 24411.900390625\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "Model 14 Predicting on:\n",
            "[24631.441 24302.928 24839.453 24450.666 24186.594 24141.316 24411.9  ] -> Prediction: 24440.626953125\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "Model 14 Predicting on:\n",
            "[24302.928 24839.453 24450.666 24186.594 24141.316 24411.9   24440.627] -> Prediction: 24160.83203125\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "Model 14 Predicting on:\n",
            "[24839.453 24450.666 24186.594 24141.316 24411.9   24440.627 24160.832] -> Prediction: 24662.96875\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "Model 14 Predicting on:\n",
            "[24450.666 24186.594 24141.316 24411.9   24440.627 24160.832 24662.969] -> Prediction: 24258.568359375\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Model 15 Predicting on:\n",
            "date\n",
            "2023-02-17    24573.505859\n",
            "2023-02-18    24631.441406\n",
            "2023-02-19    24302.927734\n",
            "2023-02-20    24839.453125\n",
            "2023-02-21    24450.666016\n",
            "2023-02-22    24186.593750\n",
            "2023-02-23    24141.316406\n",
            "Name: Price, dtype: float32 -> Prediction: 24576.326171875\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Model 15 Predicting on:\n",
            "[24631.441 24302.928 24839.453 24450.666 24186.594 24141.316 24576.326] -> Prediction: 24661.37109375\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Model 15 Predicting on:\n",
            "[24302.928 24839.453 24450.666 24186.594 24141.316 24576.326 24661.371] -> Prediction: 24366.271484375\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "Model 15 Predicting on:\n",
            "[24839.453 24450.666 24186.594 24141.316 24576.326 24661.371 24366.271] -> Prediction: 24860.38671875\n",
            "1/1 [==============================] - 0s 123ms/step\n",
            "Model 15 Predicting on:\n",
            "[24450.666 24186.594 24141.316 24576.326 24661.371 24366.271 24860.387] -> Prediction: 24488.7421875\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 45ms/step\n",
            "Model 16 Predicting on:\n",
            "date\n",
            "2023-02-17    24573.505859\n",
            "2023-02-18    24631.441406\n",
            "2023-02-19    24302.927734\n",
            "2023-02-20    24839.453125\n",
            "2023-02-21    24450.666016\n",
            "2023-02-22    24186.593750\n",
            "2023-02-23    24141.316406\n",
            "Name: Price, dtype: float32 -> Prediction: 24518.130859375\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Model 16 Predicting on:\n",
            "[24631.441 24302.928 24839.453 24450.666 24186.594 24141.316 24518.13 ] -> Prediction: 24542.607421875\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Model 16 Predicting on:\n",
            "[24302.928 24839.453 24450.666 24186.594 24141.316 24518.13  24542.607] -> Prediction: 24314.130859375\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Model 16 Predicting on:\n",
            "[24839.453 24450.666 24186.594 24141.316 24518.13  24542.607 24314.13 ] -> Prediction: 24757.580078125\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Model 16 Predicting on:\n",
            "[24450.666 24186.594 24141.316 24518.13  24542.607 24314.13  24757.58 ] -> Prediction: 24408.775390625\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Model 17 Predicting on:\n",
            "date\n",
            "2023-02-17    24573.505859\n",
            "2023-02-18    24631.441406\n",
            "2023-02-19    24302.927734\n",
            "2023-02-20    24839.453125\n",
            "2023-02-21    24450.666016\n",
            "2023-02-22    24186.593750\n",
            "2023-02-23    24141.316406\n",
            "Name: Price, dtype: float32 -> Prediction: 24545.037109375\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "Model 17 Predicting on:\n",
            "[24631.441 24302.928 24839.453 24450.666 24186.594 24141.316 24545.037] -> Prediction: 24648.99609375\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "Model 17 Predicting on:\n",
            "[24302.928 24839.453 24450.666 24186.594 24141.316 24545.037 24648.996] -> Prediction: 24301.375\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Model 17 Predicting on:\n",
            "[24839.453 24450.666 24186.594 24141.316 24545.037 24648.996 24301.375] -> Prediction: 24828.701171875\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Model 17 Predicting on:\n",
            "[24450.666 24186.594 24141.316 24545.037 24648.996 24301.375 24828.701] -> Prediction: 24426.630859375\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Model 18 Predicting on:\n",
            "date\n",
            "2023-02-17    24573.505859\n",
            "2023-02-18    24631.441406\n",
            "2023-02-19    24302.927734\n",
            "2023-02-20    24839.453125\n",
            "2023-02-21    24450.666016\n",
            "2023-02-22    24186.593750\n",
            "2023-02-23    24141.316406\n",
            "Name: Price, dtype: float32 -> Prediction: 24635.6171875\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Model 18 Predicting on:\n",
            "[24631.441 24302.928 24839.453 24450.666 24186.594 24141.316 24635.617] -> Prediction: 24667.0546875\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Model 18 Predicting on:\n",
            "[24302.928 24839.453 24450.666 24186.594 24141.316 24635.617 24667.055] -> Prediction: 24383.00390625\n",
            "1/1 [==============================] - 0s 160ms/step\n",
            "Model 18 Predicting on:\n",
            "[24839.453 24450.666 24186.594 24141.316 24635.617 24667.055 24383.004] -> Prediction: 24852.55078125\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "Model 18 Predicting on:\n",
            "[24450.666 24186.594 24141.316 24635.617 24667.055 24383.004 24852.55 ] -> Prediction: 24530.318359375\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Model 19 Predicting on:\n",
            "date\n",
            "2023-02-17    24573.505859\n",
            "2023-02-18    24631.441406\n",
            "2023-02-19    24302.927734\n",
            "2023-02-20    24839.453125\n",
            "2023-02-21    24450.666016\n",
            "2023-02-22    24186.593750\n",
            "2023-02-23    24141.316406\n",
            "Name: Price, dtype: float32 -> Prediction: 24553.390625\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Model 19 Predicting on:\n",
            "[24631.441 24302.928 24839.453 24450.666 24186.594 24141.316 24553.39 ] -> Prediction: 24604.458984375\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Model 19 Predicting on:\n",
            "[24302.928 24839.453 24450.666 24186.594 24141.316 24553.39  24604.459] -> Prediction: 24251.92578125\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Model 19 Predicting on:\n",
            "[24839.453 24450.666 24186.594 24141.316 24553.39  24604.459 24251.926] -> Prediction: 24833.306640625\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "Model 19 Predicting on:\n",
            "[24450.666 24186.594 24141.316 24553.39  24604.459 24251.926 24833.307] -> Prediction: 24418.111328125\n",
            "1/1 [==============================] - 0s 120ms/step\n",
            "Model 20 Predicting on:\n",
            "date\n",
            "2023-02-17    24573.505859\n",
            "2023-02-18    24631.441406\n",
            "2023-02-19    24302.927734\n",
            "2023-02-20    24839.453125\n",
            "2023-02-21    24450.666016\n",
            "2023-02-22    24186.593750\n",
            "2023-02-23    24141.316406\n",
            "Name: Price, dtype: float32 -> Prediction: 24604.248046875\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "Model 20 Predicting on:\n",
            "[24631.441 24302.928 24839.453 24450.666 24186.594 24141.316 24604.248] -> Prediction: 24639.171875\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Model 20 Predicting on:\n",
            "[24302.928 24839.453 24450.666 24186.594 24141.316 24604.248 24639.172] -> Prediction: 24373.60546875\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Model 20 Predicting on:\n",
            "[24839.453 24450.666 24186.594 24141.316 24604.248 24639.172 24373.605] -> Prediction: 24842.53515625\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Model 20 Predicting on:\n",
            "[24450.666 24186.594 24141.316 24604.248 24639.172 24373.605 24842.535] -> Prediction: 24455.0078125\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "Model 21 Predicting on:\n",
            "date\n",
            "2023-02-17    24573.505859\n",
            "2023-02-18    24631.441406\n",
            "2023-02-19    24302.927734\n",
            "2023-02-20    24839.453125\n",
            "2023-02-21    24450.666016\n",
            "2023-02-22    24186.593750\n",
            "2023-02-23    24141.316406\n",
            "Name: Price, dtype: float32 -> Prediction: 24463.46875\n",
            "1/1 [==============================] - 0s 116ms/step\n",
            "Model 21 Predicting on:\n",
            "[24631.441 24302.928 24839.453 24450.666 24186.594 24141.316 24463.469] -> Prediction: 24528.91796875\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Model 21 Predicting on:\n",
            "[24302.928 24839.453 24450.666 24186.594 24141.316 24463.469 24528.918] -> Prediction: 24298.701171875\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Model 21 Predicting on:\n",
            "[24839.453 24450.666 24186.594 24141.316 24463.469 24528.918 24298.701] -> Prediction: 24768.90234375\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Model 21 Predicting on:\n",
            "[24450.666 24186.594 24141.316 24463.469 24528.918 24298.701 24768.902] -> Prediction: 24382.40234375\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Model 22 Predicting on:\n",
            "date\n",
            "2023-02-17    24573.505859\n",
            "2023-02-18    24631.441406\n",
            "2023-02-19    24302.927734\n",
            "2023-02-20    24839.453125\n",
            "2023-02-21    24450.666016\n",
            "2023-02-22    24186.593750\n",
            "2023-02-23    24141.316406\n",
            "Name: Price, dtype: float32 -> Prediction: 24507.802734375\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "Model 22 Predicting on:\n",
            "[24631.441 24302.928 24839.453 24450.666 24186.594 24141.316 24507.803] -> Prediction: 24578.525390625\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "Model 22 Predicting on:\n",
            "[24302.928 24839.453 24450.666 24186.594 24141.316 24507.803 24578.525] -> Prediction: 24344.853515625\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "Model 22 Predicting on:\n",
            "[24839.453 24450.666 24186.594 24141.316 24507.803 24578.525 24344.854] -> Prediction: 24790.580078125\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Model 22 Predicting on:\n",
            "[24450.666 24186.594 24141.316 24507.803 24578.525 24344.854 24790.58 ] -> Prediction: 24421.65625\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Model 23 Predicting on:\n",
            "date\n",
            "2023-02-17    24573.505859\n",
            "2023-02-18    24631.441406\n",
            "2023-02-19    24302.927734\n",
            "2023-02-20    24839.453125\n",
            "2023-02-21    24450.666016\n",
            "2023-02-22    24186.593750\n",
            "2023-02-23    24141.316406\n",
            "Name: Price, dtype: float32 -> Prediction: 24561.94921875\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Model 23 Predicting on:\n",
            "[24631.441 24302.928 24839.453 24450.666 24186.594 24141.316 24561.95 ] -> Prediction: 24556.521484375\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "Model 23 Predicting on:\n",
            "[24302.928 24839.453 24450.666 24186.594 24141.316 24561.95  24556.521] -> Prediction: 24237.73828125\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "Model 23 Predicting on:\n",
            "[24839.453 24450.666 24186.594 24141.316 24561.95  24556.521 24237.738] -> Prediction: 24835.09375\n",
            "1/1 [==============================] - 0s 52ms/step\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model 23 Predicting on:\n",
            "[24450.666 24186.594 24141.316 24561.95  24556.521 24237.738 24835.094] -> Prediction: 24386.84765625\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "Model 24 Predicting on:\n",
            "date\n",
            "2023-02-17    24573.505859\n",
            "2023-02-18    24631.441406\n",
            "2023-02-19    24302.927734\n",
            "2023-02-20    24839.453125\n",
            "2023-02-21    24450.666016\n",
            "2023-02-22    24186.593750\n",
            "2023-02-23    24141.316406\n",
            "Name: Price, dtype: float32 -> Prediction: 24530.759765625\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Model 24 Predicting on:\n",
            "[24631.441 24302.928 24839.453 24450.666 24186.594 24141.316 24530.76 ] -> Prediction: 24636.66796875\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Model 24 Predicting on:\n",
            "[24302.928 24839.453 24450.666 24186.594 24141.316 24530.76  24636.668] -> Prediction: 24344.86328125\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Model 24 Predicting on:\n",
            "[24839.453 24450.666 24186.594 24141.316 24530.76  24636.668 24344.863] -> Prediction: 24833.482421875\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Model 24 Predicting on:\n",
            "[24450.666 24186.594 24141.316 24530.76  24636.668 24344.863 24833.482] -> Prediction: 24432.505859375\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "Model 25 Predicting on:\n",
            "date\n",
            "2023-02-17    24573.505859\n",
            "2023-02-18    24631.441406\n",
            "2023-02-19    24302.927734\n",
            "2023-02-20    24839.453125\n",
            "2023-02-21    24450.666016\n",
            "2023-02-22    24186.593750\n",
            "2023-02-23    24141.316406\n",
            "Name: Price, dtype: float32 -> Prediction: 24452.9609375\n",
            "1/1 [==============================] - 0s 105ms/step\n",
            "Model 25 Predicting on:\n",
            "[24631.441 24302.928 24839.453 24450.666 24186.594 24141.316 24452.96 ] -> Prediction: 24523.51171875\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "Model 25 Predicting on:\n",
            "[24302.928 24839.453 24450.666 24186.594 24141.316 24452.96  24523.512] -> Prediction: 24236.21484375\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "Model 25 Predicting on:\n",
            "[24839.453 24450.666 24186.594 24141.316 24452.96  24523.512 24236.215] -> Prediction: 24783.298828125\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Model 25 Predicting on:\n",
            "[24450.666 24186.594 24141.316 24452.96  24523.512 24236.215 24783.299] -> Prediction: 24321.619140625\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Model 26 Predicting on:\n",
            "date\n",
            "2023-02-17    24573.505859\n",
            "2023-02-18    24631.441406\n",
            "2023-02-19    24302.927734\n",
            "2023-02-20    24839.453125\n",
            "2023-02-21    24450.666016\n",
            "2023-02-22    24186.593750\n",
            "2023-02-23    24141.316406\n",
            "Name: Price, dtype: float32 -> Prediction: 24416.33984375\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Model 26 Predicting on:\n",
            "[24631.441 24302.928 24839.453 24450.666 24186.594 24141.316 24416.34 ] -> Prediction: 24462.287109375\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "Model 26 Predicting on:\n",
            "[24302.928 24839.453 24450.666 24186.594 24141.316 24416.34  24462.287] -> Prediction: 24173.185546875\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "Model 26 Predicting on:\n",
            "[24839.453 24450.666 24186.594 24141.316 24416.34  24462.287 24173.186] -> Prediction: 24632.275390625\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "Model 26 Predicting on:\n",
            "[24450.666 24186.594 24141.316 24416.34  24462.287 24173.186 24632.275] -> Prediction: 24298.8515625\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "Model 27 Predicting on:\n",
            "date\n",
            "2023-02-17    24573.505859\n",
            "2023-02-18    24631.441406\n",
            "2023-02-19    24302.927734\n",
            "2023-02-20    24839.453125\n",
            "2023-02-21    24450.666016\n",
            "2023-02-22    24186.593750\n",
            "2023-02-23    24141.316406\n",
            "Name: Price, dtype: float32 -> Prediction: 24549.248046875\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "Model 27 Predicting on:\n",
            "[24631.441 24302.928 24839.453 24450.666 24186.594 24141.316 24549.248] -> Prediction: 24545.90234375\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Model 27 Predicting on:\n",
            "[24302.928 24839.453 24450.666 24186.594 24141.316 24549.248 24545.902] -> Prediction: 24274.5625\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Model 27 Predicting on:\n",
            "[24839.453 24450.666 24186.594 24141.316 24549.248 24545.902 24274.562] -> Prediction: 24688.111328125\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Model 27 Predicting on:\n",
            "[24450.666 24186.594 24141.316 24549.248 24545.902 24274.562 24688.111] -> Prediction: 24425.59375\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "Model 28 Predicting on:\n",
            "date\n",
            "2023-02-17    24573.505859\n",
            "2023-02-18    24631.441406\n",
            "2023-02-19    24302.927734\n",
            "2023-02-20    24839.453125\n",
            "2023-02-21    24450.666016\n",
            "2023-02-22    24186.593750\n",
            "2023-02-23    24141.316406\n",
            "Name: Price, dtype: float32 -> Prediction: 24517.5078125\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "Model 28 Predicting on:\n",
            "[24631.441 24302.928 24839.453 24450.666 24186.594 24141.316 24517.508] -> Prediction: 24590.7890625\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "Model 28 Predicting on:\n",
            "[24302.928 24839.453 24450.666 24186.594 24141.316 24517.508 24590.79 ] -> Prediction: 24277.822265625\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "Model 28 Predicting on:\n",
            "[24839.453 24450.666 24186.594 24141.316 24517.508 24590.79  24277.822] -> Prediction: 24862.921875\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "Model 28 Predicting on:\n",
            "[24450.666 24186.594 24141.316 24517.508 24590.79  24277.822 24862.922] -> Prediction: 24416.578125\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Model 29 Predicting on:\n",
            "date\n",
            "2023-02-17    24573.505859\n",
            "2023-02-18    24631.441406\n",
            "2023-02-19    24302.927734\n",
            "2023-02-20    24839.453125\n",
            "2023-02-21    24450.666016\n",
            "2023-02-22    24186.593750\n",
            "2023-02-23    24141.316406\n",
            "Name: Price, dtype: float32 -> Prediction: 24447.056640625\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "Model 29 Predicting on:\n",
            "[24631.441 24302.928 24839.453 24450.666 24186.594 24141.316 24447.057] -> Prediction: 24477.025390625\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "Model 29 Predicting on:\n",
            "[24302.928 24839.453 24450.666 24186.594 24141.316 24447.057 24477.025] -> Prediction: 24277.806640625\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "Model 29 Predicting on:\n",
            "[24839.453 24450.666 24186.594 24141.316 24447.057 24477.025 24277.807] -> Prediction: 24679.70703125\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "Model 29 Predicting on:\n",
            "[24450.666 24186.594 24141.316 24447.057 24477.025 24277.807 24679.707] -> Prediction: 24312.916015625\n"
          ]
        }
      ],
      "source": [
        "# 5 Days in future\n",
        "INTO_FUTURE = 5\n",
        "data, y_all, _ = create_dataset()\n",
        "\n",
        "future_forecast = make_future_forecasts(\n",
        "    values=y_all,\n",
        "    ensemble=ensemble,\n",
        "    into_future=INTO_FUTURE,\n",
        "    window_size=WINDOW_SIZE\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "e3339964",
      "metadata": {
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[24577.93, 24508.72, 24282.88, 24763.787, 24377.096],\n",
              " [24456.56, 24546.1, 24192.94, 24913.428, 24440.213],\n",
              " [24525.12, 24457.162, 24189.408, 24654.68, 24298.39],\n",
              " [24593.355, 24654.139, 24389.27, 24798.9, 24488.129],\n",
              " [24488.83, 24610.64, 24297.002, 24806.053, 24407.896],\n",
              " [24602.96, 24641.32, 24343.398, 24876.717, 24448.91],\n",
              " [24525.068, 24561.39, 24392.61, 24783.639, 24405.941],\n",
              " [24631.748, 24471.656, 24323.73, 24760.027, 24379.4],\n",
              " [24703.521, 24717.682, 24504.016, 24903.812, 24561.37],\n",
              " [24515.639, 24548.793, 24317.234, 24778.25, 24426.943],\n",
              " [24521.383, 24591.79, 24323.545, 24817.102, 24415.559],\n",
              " [24662.242, 24617.66, 24427.58, 24865.059, 24486.8],\n",
              " [24598.373, 24641.273, 24401.688, 24821.74, 24471.123],\n",
              " [24503.477, 24558.275, 24267.795, 24763.928, 24426.748],\n",
              " [24411.9, 24440.627, 24160.832, 24662.969, 24258.568],\n",
              " [24576.326, 24661.371, 24366.271, 24860.387, 24488.742],\n",
              " [24518.13, 24542.607, 24314.13, 24757.58, 24408.775],\n",
              " [24545.037, 24648.996, 24301.375, 24828.701, 24426.63],\n",
              " [24635.617, 24667.055, 24383.004, 24852.55, 24530.318],\n",
              " [24553.39, 24604.459, 24251.926, 24833.307, 24418.111],\n",
              " [24604.248, 24639.172, 24373.605, 24842.535, 24455.008],\n",
              " [24463.469, 24528.918, 24298.701, 24768.902, 24382.402],\n",
              " [24507.803, 24578.525, 24344.854, 24790.58, 24421.656],\n",
              " [24561.95, 24556.521, 24237.738, 24835.094, 24386.848],\n",
              " [24530.76, 24636.668, 24344.863, 24833.482, 24432.506],\n",
              " [24452.96, 24523.512, 24236.215, 24783.299, 24321.62],\n",
              " [24416.34, 24462.287, 24173.186, 24632.275, 24298.852],\n",
              " [24549.248, 24545.902, 24274.562, 24688.111, 24425.594],\n",
              " [24517.508, 24590.79, 24277.822, 24862.922, 24416.578],\n",
              " [24447.057, 24477.025, 24277.807, 24679.707, 24312.916]]"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "future_forecast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "e75eff8b",
      "metadata": {
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(future_forecast)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "402faf01",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(Timestamp('2023-02-23 00:00:00'), 24141.31640625)"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "last_timestep = data.index[-1]\n",
        "last_price = data['Price'][-1]\n",
        "last_timestep, last_price"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "493ef1a6",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['2023-02-24', '2023-02-25', '2023-02-26', '2023-02-27',\n",
              "       '2023-02-28'], dtype='datetime64[D]')"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get {INTO_FUTURE} timestamps\n",
        "next_time_steps = get_future_dates(\n",
        "    start_date=data.index[-1], \n",
        "    into_future=INTO_FUTURE\n",
        ")\n",
        "\n",
        "next_time_steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "a700dd53",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([24527.94 , 24569.957, 24307.754, 24802.477, 24419.883],\n",
              "       dtype=float32),\n",
              " <tf.Tensor: shape=(5,), dtype=float32, numpy=\n",
              " array([24403.531, 24436.914, 24157.623, 24653.99 , 24283.248],\n",
              "       dtype=float32)>,\n",
              " <tf.Tensor: shape=(5,), dtype=float32, numpy=\n",
              " array([24676.336, 24711.824, 24460.377, 24933.975, 24544.736],\n",
              "       dtype=float32)>)"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "future_forecast_plot = np.median(future_forecast, axis=0)\n",
        "lower_future, upper_future = get_upper_lower(future_forecast)\n",
        "future_forecast_plot, lower_future, upper_future"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "06a15f6f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Insert latest data to join lines together\n",
        "next_time_steps = np.insert(next_time_steps, 0, last_timestep)\n",
        "future_forecast_plot = np.insert(future_forecast_plot, 0, last_price)\n",
        "lower_future = np.insert(lower_future, 0, last_price)\n",
        "upper_future = np.insert(upper_future, 0, last_price)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "6d877da0",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(10, 7))\n",
        "plot_time_series(\n",
        "    data.index,\n",
        "    data['Price'],\n",
        "    start=3280,\n",
        "    format='-',\n",
        "    label='Actual BTC Price'\n",
        ")\n",
        "\n",
        "plot_time_series(\n",
        "    next_time_steps,\n",
        "    future_forecast_plot,\n",
        "    format='-',\n",
        "    label='Predicted Point BTC Price'\n",
        ")\n",
        "\n",
        "plot_time_series(\n",
        "    next_time_steps,\n",
        "    lower_future,\n",
        "    format='-',\n",
        "    label='Predicted Lowerbound BTC Price'\n",
        ")\n",
        "\n",
        "plot_time_series(\n",
        "    next_time_steps,\n",
        "    upper_future,\n",
        "    format='-',\n",
        "    label='Predicted Upperbound BTC Price'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b65a0d8b",
      "metadata": {},
      "source": [
        "### Make server functions for API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7886a6c",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import datetime\n",
        "import os\n",
        "\n",
        "from lts import LTSCell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85267da9",
      "metadata": {},
      "outputs": [],
      "source": [
        "HORIZON = 1\n",
        "WINDOW_SIZE = 7\n",
        "BATCH_SIZE = 1024\n",
        "BTC_PRICES_DATA = 'D:/Uni/FYP/GitHub/BitForecast/ml/data/BTC_Prices.csv'\n",
        "ENSEMBLE_PATH = 'D:/Uni/FYP/GitHub/BitForecast/server/src/models/ensemble_univariate_complete'\n",
        "\n",
        "def get_future_dates(start_date, into_future, offset=1):\n",
        "    '''\n",
        "    Return dates from start_date to start_date + into_future\n",
        "    Creates the dates of which the forecast was made\n",
        "    '''\n",
        "    \n",
        "    start_date = start_date + np.timedelta64(offset, 'D')\n",
        "    end_date = start_date + np.timedelta64(into_future, 'D')\n",
        "    return np.arange(start_date, end_date, dtype='datetime64[D]')\n",
        "\n",
        "def create_dataset():\n",
        "    '''\n",
        "    Create the required dataset format (Windowing, Cleaning & Spitting)\n",
        "    '''\n",
        "    \n",
        "    # Import data\n",
        "    data = pd.read_csv(BTC_PRICES_DATA)\n",
        "\n",
        "    # Clean up data\n",
        "    data.drop(['volume', 'open', 'max', 'min', 'change_percent'], axis=1, inplace=True)\n",
        "    data['date'] = pd.to_datetime(data['date'])\n",
        "    data.set_index('date', inplace=True)\n",
        "    data.rename(columns={ 'close': 'Price' }, inplace=True)\n",
        "\n",
        "    # Create window datasets\n",
        "    data_windowed = data.copy()\n",
        "    for i in range(WINDOW_SIZE):\n",
        "        data_windowed[f'Price+{i+1}'] = data_windowed['Price'].shift(periods=i+1)\n",
        "\n",
        "    # Create X and y\n",
        "    X_all = data_windowed.dropna().drop('Price', axis=1).astype(np.float32)\n",
        "    y_all = data_windowed.dropna()['Price'].astype(np.float32)\n",
        "\n",
        "    # Convert tensorflow datasets\n",
        "    features_dataset_all = tf.data.Dataset.from_tensor_slices(X_all)\n",
        "    labels_dataset_all = tf.data.Dataset.from_tensor_slices(y_all)\n",
        "    dataset_all = tf.data.Dataset.zip((features_dataset_all, labels_dataset_all))\n",
        "    dataset_all = dataset_all.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "    return data, y_all, dataset_all\n",
        "\n",
        "def create_ensemble(\n",
        "    num_models=10,\n",
        "    num_epochs=5000,\n",
        "    horizon=HORIZON,\n",
        "    loss_fns=['mae', 'mse', 'mape']\n",
        "):\n",
        "    '''\n",
        "    Create the univariate ensemble model (for the case of retraining)\n",
        "    '''\n",
        "    \n",
        "    _, _, dataset_all = create_dataset()\n",
        "    ensemble = []\n",
        "\n",
        "    for i in range(num_models):\n",
        "        for loss_fn in loss_fns:\n",
        "            print(f'Model loss: {loss_fn} | model number: {i}')\n",
        "            model = tf.keras.Sequential([\n",
        "                tf.keras.layers.Input(\n",
        "                    shape=(WINDOW_SIZE)\n",
        "                ),\n",
        "                tf.keras.layers.Lambda(\n",
        "                    lambda x: tf.expand_dims(x, axis=1)\n",
        "                ),\n",
        "                tf.keras.layers.RNN(\n",
        "                    LTSCell(16),\n",
        "                    time_major=True,\n",
        "                    return_sequences=True\n",
        "                ),\n",
        "                tf.keras.layers.LSTM(\n",
        "                    16,\n",
        "                    activation='relu'\n",
        "                ),\n",
        "                tf.keras.layers.Dense(\n",
        "                    128,\n",
        "                    \n",
        "                    # This is required for the prediction intervals\n",
        "                    kernel_initializer='he_normal',\n",
        "                    activation='relu'\n",
        "                ),\n",
        "                tf.keras.layers.Dense(\n",
        "                    128,\n",
        "                    kernel_initializer='he_normal',\n",
        "                    activation='relu'\n",
        "                ),\n",
        "                tf.keras.layers.Dense(HORIZON)\n",
        "            ])\n",
        "\n",
        "            model.compile(\n",
        "                loss=loss_fn,\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['mae', 'mse']\n",
        "            )\n",
        "\n",
        "            model.fit(\n",
        "                dataset_all,\n",
        "                epochs=num_epochs,\n",
        "                verbose=0,\n",
        "            )\n",
        "\n",
        "            ensemble.append(model)\n",
        "\n",
        "    return ensemble\n",
        "\n",
        "def save_ensemble():\n",
        "    '''\n",
        "    Save ensemble\n",
        "    '''\n",
        "    \n",
        "    for i, model in enumerate(ensemble):\n",
        "        model.save(f'{ENSEMBLE_PATH}/model_{i}')\n",
        "        \n",
        "def load_ensemble():\n",
        "    '''\n",
        "    Load ensemble\n",
        "    '''\n",
        "    \n",
        "    ensemble = [tf.keras.models.load_model(f'{ENSEMBLE_PATH}/{model}') for model in os.listdir(ENSEMBLE_PATH)]\n",
        "    return ensemble\n",
        "\n",
        "def get_upper_lower(preds):\n",
        "    '''\n",
        "    Create prediction uncertainty estimates, for range prediction\n",
        "    '''\n",
        "    \n",
        "    std = tf.math.reduce_std(preds, axis=0)\n",
        "    # 1.96 is the 97.5th percentile point\n",
        "    interval = 1.96 * std\n",
        "    preds_mean = tf.reduce_mean(preds, axis=0)\n",
        "    lower, upper = preds_mean - interval, preds_mean + interval\n",
        "    return lower, upper\n",
        "\n",
        "def make_future_forecasts(\n",
        "    values,\n",
        "    ensemble,\n",
        "    into_future,\n",
        "    window_size=WINDOW_SIZE\n",
        "):\n",
        "    '''\n",
        "    Make future perdictions\n",
        "    '''\n",
        "    \n",
        "    future_forecast = []\n",
        "   \n",
        "    # Predict {into_future} times with all models in the ensemble\n",
        "    for i, model in enumerate(ensemble):\n",
        "        model_forecast = []\n",
        "        last_window = values[-window_size:] # last {WINDOW_SIZE} prices\n",
        "        for _ in range(into_future):\n",
        "            future_pred = tf.squeeze(\n",
        "                model.predict(tf.expand_dims(last_window, axis=0))\n",
        "            ).numpy()\n",
        "\n",
        "            print(f'Model {i} Predicting on:\\n{last_window} -> Prediction: {future_pred}')\n",
        "\n",
        "            # Update future forecast list\n",
        "            model_forecast.append(future_pred)\n",
        "\n",
        "            # Update last window: append latest and take last {WINDOW_SIZE} values\n",
        "            last_window = np.append(last_window, future_pred)[-window_size:]\n",
        "        \n",
        "        future_forecast.append(model_forecast)\n",
        "        \n",
        "    return future_forecast\n",
        "\n",
        "def forecast(\n",
        "    INTO_FUTURE=5\n",
        "):\n",
        "    '''\n",
        "    Create the forecast\n",
        "    '''\n",
        "    \n",
        "    raw_data, y_all, _ = create_dataset()\n",
        "    ensemble = load_ensemble()\n",
        "\n",
        "    future_forecast = make_future_forecasts(\n",
        "        values=y_all,\n",
        "        ensemble=ensemble,\n",
        "        into_future=INTO_FUTURE,\n",
        "        window_size=WINDOW_SIZE\n",
        "    )\n",
        "    \n",
        "    last_timestep = raw_data.index[-1]\n",
        "    last_price = raw_data['Price'][-1]\n",
        "    \n",
        "    next_time_steps = get_future_dates(\n",
        "        start_date=raw_data.index[-1], \n",
        "        into_future=INTO_FUTURE\n",
        "    )\n",
        "    \n",
        "    point_future = np.median(future_forecast, axis=0)\n",
        "    lower_future, upper_future = get_upper_lower(future_forecast)\n",
        "    \n",
        "    next_time_steps = np.insert(next_time_steps, 0, last_timestep)\n",
        "    point_future = np.insert(point_future, 0, last_price)\n",
        "    lower_future = np.insert(lower_future, 0, last_price)\n",
        "    upper_future = np.insert(upper_future, 0, last_price)\n",
        "    \n",
        "    return {\n",
        "        \"Predicted For\": next_time_steps,\n",
        "        \"Point Forecast\": point_future,\n",
        "        \"Lowerbound Forecast\": lower_future,\n",
        "        \"Upperbound Forecast\": upper_future,\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39a05707",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}